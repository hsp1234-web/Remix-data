# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 1: å°ˆæ¡ˆåˆå§‹åŒ–èˆ‡å…¨å±€è¨­å®š (åˆå§‹åŒ–å°ˆç”¨)
# --------------------------------------------------
# åŠŸèƒ½: åˆå§‹åŒ–å°ˆæ¡ˆï¼Œå®‰è£ä¸¦å°å…¥å¿…è¦å‡½å¼åº«ï¼Œå®šç¾©å…¨å±€é…ç½®å’Œè¿½è¹¤å™¨ã€‚å¿…é ˆæ˜¯ç¬¬ä¸€å€‹åŸ·è¡Œçš„å„²å­˜æ ¼ã€‚
# ç‰ˆæœ¬: 3.4.3-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¸­æ–‡è¨»è§£ç‰ˆï¼Œä¿®æ­£ userdata æª¢æŸ¥èˆ‡ finally logger)
# æ—¥æœŸ: 2025-05-07
# ä¾è³´: None (åƒ…ä¾è³´ Colab ç’°å¢ƒèˆ‡å¯èƒ½è¨­å®šçš„ Secrets)
# è¼¸å…¥: ['Colab Secrets: YOUR_API_KEY_NAME_1', 'Colab Secrets: YOUR_API_KEY_NAME_2'] (ç¯„ä¾‹ï¼Œè«‹æ ¹æ“šå¯¦éš›ä½¿ç”¨çš„ API Key ä¿®æ”¹)
# è¼¸å‡º: ['global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger',
#        'global:libs_loaded', 'global:target_tz', 'global:pd', 'global:np', ...] (è‹¥å°å…¥æˆåŠŸ)
# --------------------------------------------------
# ==================================================
"""
åˆå§‹åŒ– Google Colab ç’°å¢ƒä»¥é€²è¡Œå°ˆæ¡ˆã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  å°å…¥æ¨™æº–å‡½å¼åº«ã€‚
2.  æª¢æŸ¥ logging æ¨¡çµ„ï¼Œç²å– logger å¯¦ä¾‹ã€‚
3.  å®‰è£å¿…è¦çš„ç¬¬ä¸‰æ–¹å‡½å¼åº«ã€‚
4.  å˜—è©¦å°å…¥æ ¸å¿ƒå‡½å¼åº«ï¼Œä¸¦è¨˜éŒ„ç‹€æ…‹åˆ° `libs_loaded`ï¼š
    - ç‰¹åˆ¥è™•ç† `google.colab`ï¼Œå˜—è©¦å°å…¥ `userdata` ä¸¦è¨˜éŒ„å…¶ç‹€æ…‹ã€‚
5.  å®šç¾©ä¸¦åˆå§‹åŒ– `PROJECT_CONFIG` å’Œ `EXECUTION_TRACKER`ã€‚
6.  é…ç½® loggerã€‚
7.  è¨­å®šæ™‚å€ï¼Œä¸¦å°‡æ™‚å€ç‰©ä»¶å­˜å„²åˆ° `target_tz` å’Œ `PROJECT_CONFIG`ã€‚
8.  å˜—è©¦å¾ Colab Secrets è®€å– API é‡‘é‘°ï¼ˆå¦‚æœ `userdata` å¯ç”¨ï¼‰ã€‚
9.  æ‰“å°æœ€çµ‚åˆå§‹åŒ–ä¿¡æ¯ã€‚
10. `finally` å€å¡Šå ±å‘ŠåŸ·è¡Œç‹€æ…‹ä¸¦æ›´æ–° `EXECUTION_TRACKER`ï¼Œå¢å¼· logger ä½¿ç”¨çš„ç©©å¥æ€§ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* éµå¾ª v3.4 è¨­è¨ˆæº–å‰‡ã€‚
* `libs_loaded` æ›´æ˜ç¢ºå€åˆ† `google.colab.userdata` çš„å°å…¥ç‹€æ…‹ã€‚
* `finally` å€å¡Šä¸­å° logger çš„ä½¿ç”¨å¢åŠ äº†æ›´åš´æ ¼çš„æª¢æŸ¥ã€‚

ä¸»è¦è¼¸å‡º / ç‹€æ…‹è®Šæ›´ï¼š
* `global:PROJECT_CONFIG`, `global:EXECUTION_TRACKER`, `global:logger`
* `global:libs_loaded` (dict): åŒ…å«å¦‚ `yfinance`, `pandas`, `google.colab.userdata` ç­‰çš„å°å…¥ç‹€æ…‹ã€‚
* `global:target_tz` (datetime.tzinfo): å°ˆæ¡ˆæ™‚å€ç‰©ä»¶ã€‚
* `global:colab_userdata` (module or None): è‹¥å°å…¥æˆåŠŸï¼Œå‰‡ç‚º userdata æ¨¡çµ„ã€‚
* å…¶ä»–å°å…¥å‡½å¼åº«çš„åˆ¥åã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import sys
import os
import subprocess
from datetime import datetime, timezone, timedelta
import importlib
import logging

# --- 1. æª¢æŸ¥ logging å°å…¥èˆ‡ logger åˆå§‹åŒ– ---
_logging_ok = False
logger = None # ç¢ºä¿ logger åœ¨ä»»ä½•æƒ…æ³ä¸‹éƒ½æœ‰å®šç¾©
try:
    _ = logging.INFO
    logger = logging.getLogger(__name__)
    _logging_ok = True
    print("[åˆå§‹åŒ–æª¢æŸ¥] logging æ¨¡çµ„å·²æˆåŠŸå°å…¥ï¼Œlogger å·²ç²å–ã€‚")
except NameError:
    print("âŒ åš´é‡éŒ¯èª¤ï¼šlogging æ¨¡çµ„æœªèƒ½æ­£ç¢ºå°å…¥ï¼å¾ŒçºŒæ—¥èªŒåŠŸèƒ½å¯èƒ½å—å½±éŸ¿ã€‚")
except Exception as e_log_check:
    print(f"âŒ åš´é‡éŒ¯èª¤ï¼šåˆå§‹åŒ– logging æˆ–ç²å– logger æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e_log_check}")

# --- 2. å…¨å±€è®Šæ•¸æ—©æœŸåˆå§‹åŒ– ---
libs_loaded = {}
target_tz = None
PROJECT_CONFIG = {}
EXECUTION_TRACKER = {}
colab_userdata = None # ç”¨æ–¼å­˜å„²å¯¼å…¥çš„ userdata æ¨¡å¡Š
ALPHA_VANTAGE_API_KEY_VALUE = None
FRED_API_KEY_VALUE = None

# --- 3. å„²å­˜æ ¼æ¨™è­˜ç¬¦ ---
_cell_identifier = "Cell 1: å°ˆæ¡ˆåˆå§‹åŒ–èˆ‡å…¨å±€è¨­å®š (v3.4.3)" # æ›´æ–°ç‰ˆæœ¬è™Ÿ

# --- 4. ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_error = None
_cell_traceback = None
_cell_notes = []
_cell_warnings = []
_cell_inputs = {'secrets_to_try': ['ALPHA_VANTAGE_API_KEY', 'FRED_API_KEY']}
_cell_outputs = {}
_cell_generated_files = []

# --- 5. ä¸»è¦åŸ·è¡Œé‚è¼¯ ---
try:
    # --- 5.1. å®‰è£å¿…è¦çš„ç¬¬ä¸‰æ–¹å‡½å¼åº« ---
    print(f"\n--- {_cell_identifier}: é–‹å§‹æª¢æŸ¥/å®‰è£å¿…è¦çš„ç¬¬ä¸‰æ–¹å‡½å¼åº« ---")
    _cell_notes.append("é–‹å§‹å‡½å¼åº«å®‰è£æµç¨‹ã€‚")
    _required_libs_install = [
        "pandas", "numpy", "requests", "requests-cache", "yfinance",
        "fredapi", "tenacity", "plotly", "ipywidgets", "pytz", "openpyxl"
    ]
    _install_command = [sys.executable, "-m", "pip", "install", "-q"] + _required_libs_install
    _install_log_details = []
    _pip_install_success = False
    try:
        print(f"åŸ·è¡Œå®‰è£å‘½ä»¤: {' '.join(_install_command)}")
        result = subprocess.run(
            _install_command, check=False, capture_output=True, text=True, encoding='utf-8'
        )
        if result.returncode == 0:
            _install_log_details.append(f"pip install å‘½ä»¤æˆåŠŸåŸ·è¡Œã€‚\næ¨™æº–è¼¸å‡º:\n{result.stdout[:1000]}...")
            print("å¿…è¦çš„ç¬¬ä¸‰æ–¹å‡½å¼åº«å·²å®‰è£æˆ–å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ã€‚")
            _pip_install_success = True
        else:
            _install_error_msg = f"pip install å‘½ä»¤å¤±æ•—ã€‚è¿”å›ç¢¼: {result.returncode}"
            _install_log_details.append(f"éŒ¯èª¤: {_install_error_msg}\næ¨™æº–éŒ¯èª¤è¼¸å‡º:\n{result.stderr}")
            print(f"\nâŒ éŒ¯èª¤ï¼šå®‰è£å‡½å¼åº«æ™‚å¤±æ•—ï¼\n{_install_error_msg}\néŒ¯èª¤è©³æƒ…:\n{result.stderr}")
            _cell_warnings.append(f"éƒ¨åˆ†æˆ–å…¨éƒ¨å‡½å¼åº«å®‰è£å¯èƒ½å¤±æ•—: {_install_error_msg}")
    except FileNotFoundError:
        _install_error_msg = f"æ‰¾ä¸åˆ° pip å‘½ä»¤ ({sys.executable} -m pip)ã€‚è«‹æª¢æŸ¥ Python ç’°å¢ƒã€‚"
        _install_log_details.append(f"éŒ¯èª¤: {_install_error_msg}")
        print(f"\nâŒ éŒ¯èª¤ï¼š{_install_error_msg}")
        _cell_warnings.append(f"å‡½å¼åº«å®‰è£å¤±æ•—: {_install_error_msg}")
    except Exception as e_install:
        _install_error_msg = f"å®‰è£å‡½å¼åº«æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e_install.__class__.__name__}: {e_install}"
        _install_log_details.append(f"éŒ¯èª¤: {_install_error_msg}")
        print(f"\nâŒ éŒ¯èª¤ï¼š{_install_error_msg}")
        _cell_warnings.append(f"å‡½å¼åº«å®‰è£å¤±æ•—: {_install_error_msg}")
    _cell_notes.extend(_install_log_details)
    _cell_outputs['pip_install_successful'] = _pip_install_success
    print(f"--- {_cell_identifier}: å‡½å¼åº«å®‰è£å˜—è©¦çµæŸ ---")

    # --- 5.2. å˜—è©¦å°å…¥å°ˆæ¡ˆæ ¸å¿ƒå‡½å¼åº«ä¸¦è¨˜éŒ„ç‹€æ…‹ ---
    print(f"\n--- {_cell_identifier}: é–‹å§‹å°å…¥å°ˆæ¡ˆæ ¸å¿ƒå‡½å¼åº«ä¸¦è¨˜éŒ„ç‹€æ…‹ ---")
    _cell_notes.append("é–‹å§‹æ ¸å¿ƒå‡½å¼åº«å°å…¥æµç¨‹ã€‚")
    _libs_to_import = {
        "pandas": "pd", "numpy": "np", "requests": "requests",
        "requests_cache": "requests_cache", "yfinance": "yf", "fredapi": "fredapi",
        "tenacity": "tenacity", "plotly": "plotly", "plotly.graph_objects": "go",
        "ipywidgets": "widgets", "pytz": "pytz", "openpyxl": "openpyxl",
        "google.colab": "colab" # å˜—è©¦å°å…¥ google.colab æ¨¡çµ„æœ¬èº«
    }

    # é¦–å…ˆå–®ç¨è™•ç† userdata çš„å°å…¥ï¼Œå› ç‚ºå®ƒæ›´é—œéµ
    try:
        from google.colab import userdata as colab_userdata_module
        colab_userdata = colab_userdata_module # è³¦å€¼çµ¦å…¨å±€è®Šæ•¸
        print(f"æˆåŠŸå°å…¥ google.colab.userdataã€‚")
        libs_loaded['google.colab.userdata'] = True
    except ImportError:
        print("è­¦å‘Šï¼šå°å…¥ google.colab.userdata å¤±æ•—ã€‚Secrets åŠŸèƒ½å°‡ä¸å¯ç”¨ã€‚")
        libs_loaded['google.colab.userdata'] = False
        _cell_warnings.append("å°å…¥ google.colab.userdata å¤±æ•—ã€‚")
    except Exception as e_userdata_other:
        print(f"è­¦å‘Šï¼šå°å…¥ google.colab.userdata æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤ï¼š{e_userdata_other}ã€‚")
        libs_loaded['google.colab.userdata'] = False
        _cell_warnings.append(f"å°å…¥ google.colab.userdata æ™‚æ„å¤–éŒ¯èª¤: {e_userdata_other}")


    for lib_name, alias in _libs_to_import.items():
        if lib_name == "google.colab" and libs_loaded.get('google.colab.userdata'):
            # å¦‚æœ userdata å·²æˆåŠŸå°å…¥ï¼Œæˆ‘å€‘å¯èƒ½ä»æƒ³å˜—è©¦å°å…¥ google.colab æœ¬èº«ä½œç‚ºä¸€å€‹æ¨¡çµ„
            # ä½†è¦é¿å…è¦†è“‹å·²ç¶“æˆåŠŸçš„ userdata ç‹€æ…‹
            pass # ä¸‹é¢çš„é€šç”¨é‚è¼¯æœƒè™•ç† google.colab æ¨¡çµ„çš„å°å…¥

        try:
            if '.' in lib_name:
                module_parts = lib_name.split('.')
                imported_module = importlib.import_module(module_parts[0])
                for part in module_parts[1:]:
                    imported_module = getattr(imported_module, part)
                globals()[alias] = imported_module
            else:
                globals()[alias] = importlib.import_module(lib_name)

            print(f"æˆåŠŸå°å…¥ {lib_name} ä¸¦å‘½åç‚º {alias}ã€‚")
            libs_loaded[lib_name] = True # è¨˜éŒ„æ¨¡çµ„æœ¬èº«çš„å°å…¥ç‹€æ…‹
            if hasattr(globals()[alias], '__version__'):
                _cell_notes.append(f"å‡½å¼åº« {alias} (ä¾†è‡ª {lib_name}) ç‰ˆæœ¬: {globals()[alias].__version__}")
        except ImportError as e_import:
            print(f"è­¦å‘Šï¼šå°å…¥å‡½å¼åº« {lib_name} (åˆ¥å {alias}) å¤±æ•—ï¼š{e_import}ã€‚")
            globals()[alias] = None
            libs_loaded[lib_name] = False # æ¨™è¨˜æ¨¡çµ„å°å…¥å¤±æ•—
            _cell_warnings.append(f"å°å…¥å‡½å¼åº« {lib_name} å¤±æ•—ã€‚")
        except Exception as e_import_other:
            print(f"è­¦å‘Šï¼šå°å…¥å‡½å¼åº« {lib_name} (åˆ¥å {alias}) æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤ï¼š{e_import_other}ã€‚")
            globals()[alias] = None
            libs_loaded[lib_name] = False
            _cell_warnings.append(f"å°å…¥å‡½å¼åº« {lib_name} æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e_import_other}")

    _cell_outputs['libs_loaded_status'] = libs_loaded.copy()
    print(f"\n[é™¤éŒ¯] {_cell_identifier}: libs_loaded ç‹€æ…‹: {libs_loaded}")
    _cell_notes.append(f"æ ¸å¿ƒå‡½å¼åº«å°å…¥å˜—è©¦çµæŸã€‚ç‹€æ…‹: {libs_loaded}")
    print(f"--- {_cell_identifier}: æ ¸å¿ƒå‡½å¼åº«å°å…¥å˜—è©¦çµæŸ ---")

    # --- 5.3. åˆå§‹åŒ–æ—¥èªŒè¨˜éŒ„å™¨ (å¦‚æœä¹‹å‰å¤±æ•—å‰‡é‡è©¦) ---
    if not _logging_ok and logger is not None: # åªæœ‰åœ¨ logger å¯¦ä¾‹å­˜åœ¨ä½†æœªé…ç½®æ™‚æ‰é‡è©¦
        print(f"\n--- {_cell_identifier}: å˜—è©¦é‡æ–°é…ç½®æ—¥èªŒè¨˜éŒ„å™¨ ---")
        try: # é‡æ–°é…ç½®
            default_log_level_config_retry = logging.INFO
            logger.setLevel(default_log_level_config_retry)
            if logger.hasHandlers(): logger.handlers.clear()
            log_handler_retry = logging.StreamHandler(sys.stdout)
            log_formatter_retry = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
            log_handler_retry.setFormatter(log_formatter_retry)
            logger.addHandler(log_handler_retry)
            _logging_ok = True # æ¨™è¨˜ç‚ºå·²é…ç½®
            _log_level_name_retry = logging.getLevelName(logger.level)
            print(f"æ—¥èªŒè¨˜éŒ„å™¨å·²é‡æ–°é…ç½®ã€‚ç´šåˆ¥ï¼š{_log_level_name_retry}ã€‚")
            logger.info(f"{_cell_identifier} - æ—¥èªŒè¨˜éŒ„å™¨é‡æ–°é…ç½®å®Œæˆã€‚")
            _cell_notes.append(f"è¨˜éŒ„å™¨å·²é‡æ–°é…ç½®ï¼Œç´šåˆ¥ç‚º {_log_level_name_retry}ã€‚")
        except Exception as e_log_reconfig:
            print(f"âŒ éŒ¯èª¤ï¼šé‡æ–°é…ç½® logger å¤±æ•—: {e_log_reconfig}")
            _cell_warnings.append("Logger é‡æ–°é…ç½®å¤±æ•—ã€‚")
    elif _logging_ok and logger is not None: # åˆæ¬¡æˆåŠŸ
        default_log_level_config = PROJECT_CONFIG.get('log_level', logging.INFO) # å¾ PROJECT_CONFIG ç²å–
        logger.setLevel(default_log_level_config)
        if logger.hasHandlers(): logger.handlers.clear(); print("å·²æ¸…é™¤èˆŠçš„æ—¥èªŒ handlers (è‹¥æœ‰)ã€‚")
        log_handler = logging.StreamHandler(sys.stdout)
        log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        log_handler.setFormatter(log_formatter)
        logger.addHandler(log_handler)
        _log_level_name = logging.getLevelName(logger.level)
        print(f"æ—¥èªŒè¨˜éŒ„å™¨å·²é…ç½®ã€‚ç´šåˆ¥ï¼š{_log_level_name}ã€‚")
        logger.info(f"{_cell_identifier} - æ—¥èªŒè¨˜éŒ„å™¨é…ç½®å®Œæˆã€‚")
        _cell_notes.append(f"è¨˜éŒ„å™¨å·²é…ç½®ï¼Œç´šåˆ¥ç‚º {_log_level_name}ã€‚")
    else: # logger is None or _logging_ok is False from the start
        print("è­¦å‘Š: Logger æœªèƒ½æˆåŠŸåˆå§‹åŒ–æˆ–é…ç½®ï¼Œæ—¥èªŒè¼¸å‡ºå¯èƒ½ä¸å®Œæ•´ã€‚")
        _cell_notes.append("Logger æœªèƒ½æˆåŠŸåˆå§‹åŒ–æˆ–é…ç½®ã€‚")


    # --- 5.4. å®šç¾©å…¨å±€é…ç½® PROJECT_CONFIG ---
    print(f"\n--- {_cell_identifier}: å®šç¾©å…¨å±€é…ç½® PROJECT_CONFIG ---")
    PROJECT_CONFIG.update({
      'project_name': 'é€šç”¨å°ˆæ¡ˆç¯„æœ¬', 'project_version': '1.0.0', 'guideline_version': '3.4.3-zh-fc',
      'log_level': logger.level if _logging_ok and logger else logging.WARNING,
      'timezone': 'Asia/Taipei', 'output_dir': '/content/project_output',
      'cache_dir': '/content/project_cache', 'cache_name': 'api_request_cache',
      'cache_expire_after': timedelta(hours=1),
      'api_keys_info': {
          'alpha_vantage': {'secret_name': 'ALPHA_VANTAGE_API_KEY', 'description': 'Alpha Vantage API Key'},
          'fred': {'secret_name': 'FRED_API_KEY', 'description': 'FRED API Key'}
      },
      'api_access_status': {},
      'rate_limit_handler': {
            'wait_fixed_seconds': 10, 'stop_after_attempt': 3,
            'wait_fixed_seconds_yfinance': 30, 'stop_after_attempt_yfinance': 3
      },
      'user_agent': 'MyProject/1.0 (Colab; contact@example.com)',
    })
    _cell_notes.append("PROJECT_CONFIG å·²å®šç¾© (ä¸å«æ•æ„Ÿå€¼)ã€‚")
    print("PROJECT_CONFIG å®šç¾©å®Œæˆã€‚")

    # --- 5.5. åˆå§‹åŒ–å…¨å±€åŸ·è¡Œè¿½è¹¤å™¨ ---
    print(f"\n--- {_cell_identifier}: åˆå§‹åŒ–å…¨å±€åŸ·è¡Œè¿½è¹¤å™¨ EXECUTION_TRACKER ---")
    EXECUTION_TRACKER.clear()
    print("EXECUTION_TRACKER åˆå§‹åŒ–ç‚ºç©ºå­—å…¸ã€‚")
    if _logging_ok and logger: logger.info(f"{_cell_identifier} - EXECUTION_TRACKER åˆå§‹åŒ–å®Œæˆã€‚")
    _cell_notes.append("EXECUTION_TRACKER åˆå§‹åŒ–ç‚ºç©ºå­—å…¸ã€‚")

    # --- 5.6. è¨­å®šæ™‚å€ ---
    print(f"\n--- {_cell_identifier}: è¨­å®šæ™‚å€ ---")
    _tz_name_config = PROJECT_CONFIG.get('timezone', 'Asia/Taipei')
    _tz_info_obj = None; _tz_source_log = "æœªçŸ¥"
    try:
        from zoneinfo import ZoneInfo, ZoneInfoNotFoundError
        try: _tz_info_obj = ZoneInfo(_tz_name_config); _tz_source_log = "zoneinfo"; print(f"æˆåŠŸä½¿ç”¨ zoneinfo åŠ è¼‰æ™‚å€ '{_tz_name_config}'ã€‚")
        except ZoneInfoNotFoundError: print(f"zoneinfo æ‰¾ä¸åˆ°æ™‚å€ '{_tz_name_config}'ã€‚å˜—è©¦ pytz..."); raise ImportError
    except ImportError:
        if libs_loaded.get('pytz') and 'pytz' in globals() and globals()['pytz']:
            pytz_module = globals()['pytz']
            try: _tz_info_obj = pytz_module.timezone(_tz_name_config); _tz_source_log = "pytz"; print(f"æˆåŠŸä½¿ç”¨ pytz åŠ è¼‰æ™‚å€ '{_tz_name_config}'ã€‚")
            except pytz_module.UnknownTimeZoneError: _warn_msg_tz = f"pytz æ‰¾ä¸åˆ°æ™‚å€ '{_tz_name_config}'ã€‚å›é€€åˆ° UTC+8ã€‚"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (å›é€€)"; _tz_source_log = "å›ºå®šåç§»"
            except Exception as e_pytz: _warn_msg_tz = f"ä½¿ç”¨ pytz åŠ è¼‰æ™‚å€ '{_tz_name_config}' æ™‚å‡ºéŒ¯ï¼š{e_pytz}ã€‚å›é€€åˆ° UTC+8ã€‚"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (å›é€€)"; _tz_source_log = "éŒ¯èª¤æ™‚å›ºå®šåç§»"
        else: _warn_msg_tz = "æœªæ‰¾åˆ° zoneinfo ä¸” pytz æœªæˆåŠŸå°å…¥ã€‚å›é€€åˆ° UTC+8ã€‚"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (å›é€€)"; _tz_source_log = "å›ºå®šåç§» (pytzç¼ºå¤±)"
    target_tz = _tz_info_obj
    PROJECT_CONFIG['_tz_info_obj'] = target_tz; PROJECT_CONFIG['_tz_name'] = _tz_name_config; PROJECT_CONFIG['_tz_source'] = _tz_source_log
    if _logging_ok and logger: logger.info(f"æœ€çµ‚ä½¿ç”¨çš„æ™‚å€ï¼š{_tz_name_config} (ä¾†æºï¼š{_tz_source_log})")
    _cell_notes.append(f"æ™‚å€è¨­å®šç‚º {_tz_name_config} (é€é {_tz_source_log})ã€‚")
    print(f"[é™¤éŒ¯] {_cell_identifier}: target_tz ç‹€æ…‹: {target_tz} (é¡å‹: {type(target_tz)})")
    print(f"--- {_cell_identifier}: æ™‚å€è™•ç†å®Œæˆ ---")

    # --- 5.7. å˜—è©¦å¾ Colab Secrets è®€å– API é‡‘é‘° ---
    print(f"\n--- {_cell_identifier}: å˜—è©¦å¾ Colab Secrets è®€å– API é‡‘é‘° (åƒ…è¨˜éŒ„ç‹€æ…‹) ---")
    _api_keys_info_config = PROJECT_CONFIG.get('api_keys_info', {})
    _api_access_status_log = {}
    if 'colab_userdata' in globals() and colab_userdata is not None: # ä¸»è¦æª¢æŸ¥ colab_userdata æ˜¯å¦æœ‰æ•ˆ
        _cell_notes.append("æ­£åœ¨å˜—è©¦è®€å– Colab Secrets (åƒ…æ›´æ–°ç‹€æ…‹)...")
        for api_name, key_info in _api_keys_info_config.items():
            secret_name_config = key_info.get('secret_name')
            if not secret_name_config: _warn_msg_secret = f"è­¦å‘Šï¼šPROJECT_CONFIG ä¸­ API '{api_name}' çš„ 'secret_name' æœªå®šç¾©ã€‚"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "å¤±æ•— (ç¼ºå°‘é…ç½®)"; continue
            try:
                key_value_temp = colab_userdata.get(secret_name_config)
                if key_value_temp:
                    _api_access_status_log[api_name] = "å·²ç²å– (æ¨¡æ“¬)"
                    if api_name == 'alpha_vantage': ALPHA_VANTAGE_API_KEY_VALUE = key_value_temp
                    elif api_name == 'fred': FRED_API_KEY_VALUE = key_value_temp
                    print(f"æ¨¡æ“¬å¾ Colab Secrets è®€å– '{secret_name_config}' (ç”¨æ–¼ {api_name})ã€‚")
                    if _logging_ok and logger: logger.info(f"æ¨¡æ“¬è®€å– {api_name} çš„ API é‡‘é‘°ã€‚")
                else: _warn_msg_secret = f"è­¦å‘Šï¼šåœ¨ Colab Secrets ä¸­æ‰¾åˆ° '{secret_name_config}' ä½†å…¶å€¼ç‚ºç©ºã€‚"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "å€¼ç‚ºç©º"
            except colab_userdata.SecretNotFoundError: _warn_msg_secret = f"è­¦å‘Šï¼šæœªæ‰¾åˆ° Secret '{secret_name_config}' (ç”¨æ–¼ {api_name})ã€‚"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "å¤±æ•— (æœªæ‰¾åˆ°)"
            except Exception as e_secret: _warn_msg_secret = f"è®€å– Secret '{secret_name_config}' æ™‚å‡ºéŒ¯ï¼š{e_secret}"; print(f"éŒ¯èª¤ï¼š{_warn_msg_secret}"); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = f"è®€å–éŒ¯èª¤ ({e_secret.__class__.__name__})"
        _cell_notes.append("Colab Secrets è®€å–å˜—è©¦å®Œæˆã€‚")
    else:
        _warn_msg_secret = "è­¦å‘Šï¼šgoogle.colab.userdata ç„¡æ³•ä½¿ç”¨ã€‚ç„¡æ³•è®€å– API é‡‘é‘°ã€‚"
        print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret)
        if _logging_ok and logger: logger.warning(_warn_msg_secret)
        for api_name_cfg in _api_keys_info_config.keys(): _api_access_status_log[api_name_cfg] = "æœªå˜—è©¦ (userdataä¸å¯ç”¨)"
    PROJECT_CONFIG['api_access_status'] = _api_access_status_log
    print(f"--- {_cell_identifier}: API é‡‘é‘°è®€å–å˜—è©¦çµæŸ ---")

    # --- 5.8. æ‰“å°æœ€çµ‚åˆå§‹åŒ–ä¿¡æ¯ ---
    print("\n" + "="*80); _project_name_log = PROJECT_CONFIG.get('project_name', 'æœªçŸ¥å°ˆæ¡ˆ'); _project_version_log = PROJECT_CONFIG.get('project_version', 'æœªçŸ¥ç‰ˆæœ¬')
    print(f"** å°ˆæ¡ˆ '{_project_name_log}' (v{_project_version_log}) åˆå§‹åŒ– ({_cell_identifier}) å®Œæˆ **")
    if _logging_ok and logger: print(f"æ—¥èªŒç´šåˆ¥ï¼š{logging.getLevelName(logger.level)}")
    else: print("æ—¥èªŒç´šåˆ¥ï¼šæœªçŸ¥ (Logger æœªåˆå§‹åŒ–/é…ç½®)")
    print(f"æ™‚å€ï¼š{PROJECT_CONFIG.get('_tz_name', 'æœªçŸ¥')} (ä¾†æºï¼š{PROJECT_CONFIG.get('_tz_source', 'æœªçŸ¥')})")
    print("\n** å‡½å¼åº«å°å…¥ç‹€æ…‹ (libs_loaded)ï¼š**"); pprint.pprint(libs_loaded, indent=2, width=70)
    print("\n** API é‡‘é‘°è®€å–ç‹€æ…‹ (PROJECT_CONFIG['api_access_status'])ï¼š**"); pprint.pprint(PROJECT_CONFIG.get('api_access_status', {}), indent=2, width=70)
    _config_for_print_final = {k: v for k, v in PROJECT_CONFIG.items() if k != '_tz_info_obj'}; print("\n** æœ€çµ‚å…¨å±€é…ç½® (PROJECT_CONFIG) æ¦‚è¦½ (ä¸å«æ•æ„Ÿå€¼)ï¼š**"); pprint.pprint(_config_for_print_final, indent=2, width=70, sort_dicts=False)
    print("\n** åŸ·è¡Œè¿½è¹¤å™¨ (EXECUTION_TRACKER) ç›®å‰ç‚ºç©ºã€‚ **")
    _failed_libs_final = [lib for lib, loaded_status in libs_loaded.items() if not loaded_status and lib not in ['google.colab', 'google.colab.userdata']]
    if _failed_libs_final: _warn_msg_libs = f"** è­¦å‘Šï¼š** ä»¥ä¸‹æ ¸å¿ƒå‡½å¼åº«æœªèƒ½æˆåŠŸå°å…¥ï¼š{', '.join(_failed_libs_final)}ã€‚"; print(f"\n{_warn_msg_libs}"); _cell_warnings.append(_warn_msg_libs)
    _key_issues_final = [f"{api} ({status})" for api, status in PROJECT_CONFIG.get('api_access_status', {}).items() if "å·²ç²å–" not in status and "æ¨¡æ“¬" not in status];
    if _key_issues_final: _warn_msg_keys = f"** è­¦å‘Šï¼š** ä»¥ä¸‹ API çš„é‡‘é‘°å­˜åœ¨å•é¡Œæˆ–æœªé…ç½®ï¼š{', '.join(_key_issues_final)}ã€‚"; print(f"\n{_warn_msg_keys}"); _cell_warnings.append(_warn_msg_keys)
    print("="*80)

    if _cell_status == "è™•ç†ä¸­": _cell_status = "æˆåŠŸ"; _cell_notes.append("åˆå§‹åŒ–æˆåŠŸã€‚")
    if _logging_ok and logger: logger.info(f"{_cell_identifier} åˆå§‹åŒ–éç¨‹æˆåŠŸå®Œæˆã€‚æœ€çµ‚ç‹€æ…‹: {_cell_status}")

except Exception as e_outer:
    if _cell_status != "å¤±æ•—": _cell_status = "å¤±æ•—"; _cell_error = f"åš´é‡éŒ¯èª¤ï¼š{_cell_identifier} åˆå§‹åŒ–é ‚å±¤éŒ¯èª¤ï¼š{e_outer.__class__.__name__}: {e_outer}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try:
        if _logging_ok and logger: logger.critical(_cell_error, exc_info=True)
        else: print(f"åš´é‡éŒ¯èª¤ï¼ˆLogger {_logging_ok}, {logger}ï¼‰ï¼š{_cell_identifier} åˆå§‹åŒ–ï¼š{_cell_error}\n{_cell_traceback}")
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤ã€‚åŸå§‹éŒ¯èª¤ï¼š{_cell_error}\nåŸå§‹ Tracebackï¼š{_cell_traceback}")
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict): PROJECT_CONFIG = {}
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER = {}
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict): libs_loaded = {}
    if 'target_tz' not in globals() or target_tz is None : target_tz = timezone(timedelta(hours=8))

finally:
    _cell_end_time = time.time(); _cell_duration = _cell_end_time - _cell_start_time
    _final_status_text_report = _cell_status
    if _cell_status == "å¤±æ•—": _final_status_icon_report = "âŒ"
    elif _cell_status == "è™•ç†ä¸­": _final_status_icon_report = "â³"; _final_status_text_report = "æœªå®Œæˆ"
    elif _cell_warnings: _final_status_icon_report = "âš ï¸"; _final_status_text_report = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰" if _cell_status == "æˆåŠŸ" else _cell_status
    elif _cell_status == "æˆåŠŸ": _final_status_icon_report = "âœ…"
    else: _final_status_icon_report = "â“"
    _current_time_str_report = "ç„¡æ³•ç²å–"
    try:
        _report_tz_info_final = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8)))
        _current_time_str_report = datetime.now(_report_tz_info_final).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception: _current_time_str_report = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
    _cell_outputs['final_libs_loaded_summary'] = {k: ("æˆåŠŸ" if v else "å¤±æ•—") for k,v in libs_loaded.items()}
    _cell_outputs['final_target_tz_repr'] = repr(target_tz)
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon_report, 'status_text': _final_status_text_report,
        'timestamp': _current_time_str_report, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if isinstance(_cell_traceback, str) else "".join(_cell_traceback) if isinstance(_cell_traceback, list) else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs, 'generated_files': _cell_generated_files }
    try:
        if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER = {}
        EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err_final: print(f"éŒ¯èª¤ï¼šæ›´æ–° EXECUTION_TRACKER æ™‚ç•°å¸¸ï¼š{tracker_update_err_final}")
    print("\n" + "="*80)
    _guideline_version_report = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥')
    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_report}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon_report} {_final_status_text_report}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’"); print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str_report}")
    print("\n** \U0001F527 é—œéµé…ç½®æ‘˜è¦ï¼š**")
    try:
        print(f"  - å°ˆæ¡ˆåç¨±ï¼š{PROJECT_CONFIG.get('project_name', 'N/A')}")
        print(f"  - æ—¥èªŒç´šåˆ¥ï¼š{logging.getLevelName(PROJECT_CONFIG.get('log_level', logging.WARNING))}")
        print(f"  - æ™‚å€ï¼š{PROJECT_CONFIG.get('_tz_name', 'N/A')} (ä¾†æºï¼š{PROJECT_CONFIG.get('_tz_source', 'N/A')})")
        _api_status_summary_report = ", ".join([f"{api} ({status})" for api, status in PROJECT_CONFIG.get('api_access_status', {}).items()])
        print(f"  - API é‡‘é‘°ç‹€æ…‹ï¼š{_api_status_summary_report or 'N/A'}")
    except Exception as config_print_err_final: print(f"  - (æ‰“å°é…ç½®æ‘˜è¦æ™‚å‡ºéŒ¯ï¼š{config_print_err_final})")
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**"); pprint.pprint(_tracking_record['warnings'], indent=2, width=70)
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**\n{_tracking_record['error']}")
    if _tracking_record.get('traceback'): _tb_content = _tracking_record.get('traceback'); print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20 + f"\n<pre>{_tb_content}</pre>\n" + "-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))
    print("\n** \U0001F4CA è¼¸å‡º / ç‹€æ…‹è®Šæ›´ï¼š**"); pprint.pprint(_tracking_record.get('outputs', {}), indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")
    _vars_to_clean_final = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status', '_cell_error', '_cell_traceback',
        '_cell_notes', '_cell_warnings', '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon_report', '_final_status_text_report', '_current_time_str_report', '_tracking_record',
        '_report_tz_info_final', '_required_libs_install', '_install_command', '_install_log_details',
        '_pip_install_success', '_install_error_msg', 'result', '_libs_to_import', 'lib_name', 'alias',
        'module_parts', 'imported_module', 'part', 'e_import', 'e_import_other', '_logging_ok',
        'default_log_level_config', 'log_handler', 'log_formatter', '_log_level_name', '_tz_name_config',
        '_tz_info_obj', '_tz_source_log', 'pytz_module', 'ZoneInfo', 'ZoneInfoNotFoundError', '_warn_msg_tz',
        'e_pytz', '_api_keys_info_config', '_api_access_status_log', 'api_name', 'key_info',
        'secret_name_config', 'key_value_temp', '_warn_msg_secret', 'e_secret', '_project_name_log',
        '_project_version_log', '_config_for_print_final', '_failed_libs_final', '_warn_msg_libs',
        '_key_issues_final', '_warn_msg_keys', 'e_outer', 'e_log_check', 'e_log_retry', 'e_install',
        'time_err_report', 'time_err_local_report', '_warn_msg_tracker', 'tracker_update_err_final',
        '_err_msg_tracker', '_guideline_version_report', '_api_status_summary_report', 'config_print_err_final',
        '_tb_content', 'ALPHA_VANTAGE_API_KEY_VALUE', 'FRED_API_KEY_VALUE', 'colab_userdata_module'
    ]
    # ä¿ç•™æ ¸å¿ƒå…¨å±€è®Šæ•¸ï¼Œå…¶é¤˜å˜—è©¦æ¸…ç†
    _core_globals_to_keep = ['PROJECT_CONFIG', 'EXECUTION_TRACKER', 'logger', 'libs_loaded', 'target_tz', 'pd', 'yf', 'requests', 'requests_cache', 'fredapi', 'tenacity', 'go', 'widgets', 'pytz', 'openpyxl', 'np', 'colab_userdata']
    for _var_final in _vars_to_clean_final:
        if _var_final in locals():
            try: del locals()[_var_final]
            except KeyError: pass
        elif _var_final in globals() and _var_final not in _core_globals_to_keep:
            try: del globals()[_var_final]
            except KeyError: pass
    try:
        if _logging_ok and logger and logger.hasHandlers(): logger.info(f"{_cell_identifier} finally å€å¡Šå®Œæˆã€‚")
        else: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (Logger æœªå®Œå…¨é…ç½®æˆ–ä¸å¯ç”¨)ã€‚")
    except Exception as e_final_log_print: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„æœ€çµ‚æ—¥èªŒæ™‚ç™¼ç”ŸéŒ¯èª¤: {e_final_log_print})ã€‚")

# ==================================================
# é å°¾è¨»è§£ (v3.4.3-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 1: å°ˆæ¡ˆåˆå§‹åŒ–èˆ‡å…¨å±€è¨­å®š (åˆå§‹åŒ–å°ˆç”¨)
# åŠŸèƒ½: åˆå§‹åŒ–å°ˆæ¡ˆï¼Œå®‰è£ä¸¦å°å…¥å¿…è¦å‡½å¼åº«ï¼Œå®šç¾©å…¨å±€é…ç½®å’Œè¿½è¹¤å™¨ã€‚
# ç‰ˆæœ¬: 3.4.3-zh-fc
# æ—¥æœŸ: 2025-05-07
# ä¾è³´: None
# è¼¸å…¥: (å¯é¸ Colab Secrets)
# è¼¸å‡º: ['global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', ...]
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 2: ç’°å¢ƒæª¢æŸ¥ã€ç›®éŒ„èˆ‡å¿«å–è¨­å®š (å·¥ä½œæµç¨‹å¾æ­¤é–‹å§‹)
# --------------------------------------------------
# åŠŸèƒ½: æª¢æŸ¥ Cell 1 åˆå§‹åŒ–ç‹€æ…‹ï¼Œå‰µå»ºè¼¸å‡º/å¿«å–ç›®éŒ„ï¼Œä¸¦è¨­å®šè«‹æ±‚å¿«å–ã€‚
# ç‰ˆæœ¬: 3.4-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¸­æ–‡è¨»è§£ç‰ˆï¼Œå«é å°¾è¨»è§£)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger']
# è¼¸å…¥: ['global:PROJECT_CONFIG']
# è¼¸å‡º: ['Directory:PROJECT_CONFIG["output_dir"]', 'Directory:PROJECT_CONFIG["cache_dir"]', 'global:EXECUTION_TRACKER (updated)']
# --------------------------------------------------
# ==================================================
"""
åŸ·è¡Œç’°å¢ƒæº–å‚™å·¥ä½œï¼Œä½œç‚ºæ•¸æ“šè™•ç†æµç¨‹çš„ç¬¬ä¸€æ­¥ã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  æª¢æŸ¥æ ¸å¿ƒå‡½å¼åº« (`os`, `requests_cache` - å¦‚æœéœ€è¦) æ˜¯å¦å¯ç”¨ã€‚
3.  å¾ `PROJECT_CONFIG` æª¢ç´¢è¼¸å‡ºç›®éŒ„ (`output_dir`) å’Œå¿«å–ç›®éŒ„ (`cache_dir`) è·¯å¾‘ã€‚
4.  ä½¿ç”¨ `os.makedirs` å‰µå»ºæŒ‡å®šçš„ç›®éŒ„ (å¦‚æœå®ƒå€‘ä¸å­˜åœ¨)ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†ã€‚
5.  å¦‚æœ `requests_cache` å‡½å¼åº«å¯ç”¨ä¸”åœ¨ `PROJECT_CONFIG` ä¸­é…ç½®äº†å¿«å–åç¨±å’Œè·¯å¾‘ï¼Œ
    å‰‡ä½¿ç”¨ `requests_cache.install_cache` è¨­å®šå…¨åŸŸè«‹æ±‚å¿«å–ã€‚
6.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* ä½œç‚ºå·¥ä½œæµç¨‹çš„ç¬¬ä¸€å€‹å„²å­˜æ ¼ï¼Œç¢ºä¿åŸºç¤è¨­æ–½ï¼ˆç›®éŒ„ã€å¿«å–ï¼‰æº–å‚™å°±ç·’ã€‚
* ä¾è³´ Cell 1 é€²è¡Œé…ç½®å’Œè¿½è¹¤å™¨åˆå§‹åŒ–ã€‚
* ä½¿ç”¨ `PROJECT_CONFIG` é€²è¡Œåƒæ•¸åŒ–ã€‚
* åŒ…å«é‡å°ç›®éŒ„å‰µå»ºå’Œå¿«å–è¨­å®šéŒ¯èª¤çš„ç‰¹å®š `try-except` å€å¡Šã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´ä¾†è‡ª Cell 1 çš„å…¨å±€è®Šæ•¸ `PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºç›®éŒ„ï¼Œå¯èƒ½è¨­å®šå¿«å–ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) æœªå®šç¾©ã€‚
    ValueError: å¦‚æœ `PROJECT_CONFIG` ä¸­ç¼ºå°‘å¿…è¦çš„è·¯å¾‘éµã€‚
    ImportError: å¦‚æœ `requests_cache` éœ€è¦ä½†æœªæˆåŠŸå°å…¥ã€‚
    OSError: å¦‚æœç„¡æ³•å‰µå»ºæˆ–è¨ªå•æŒ‡å®šçš„ç›®éŒ„ã€‚
    Exception: æ•ç²åŸ·è¡ŒæœŸé–“ä»»ä½•å…¶ä»–æ„å¤–éŒ¯èª¤ï¼Œä¾‹å¦‚å¿«å–è¨­å®šå¤±æ•—ã€‚

å‡è¨­ï¼š
* Cell 1 å·²æˆåŠŸåŸ·è¡Œã€‚
* `PROJECT_CONFIG` åŒ…å« 'output_dir' å’Œ 'cache_dir' éµã€‚
* ç’°å¢ƒå…·æœ‰å‰µå»ºç›®éŒ„çš„æ¬Šé™ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* å¦‚æœå¿«å–è¨­å®šå¤±æ•—ï¼Œå¾ŒçºŒ API è«‹æ±‚å°‡ä¸æœƒè¢«å¿«å–ï¼Œå¯èƒ½å½±éŸ¿æ•ˆèƒ½å’Œ API ä½¿ç”¨é™åˆ¶ã€‚
* ç›®éŒ„æ¬Šé™å•é¡Œå¯èƒ½å°è‡´ `OSError`ã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 3 é–‹å§‹å…·é«”çš„æ•¸æ“šç²å–ä»»å‹™ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
import os
from datetime import datetime, timezone, timedelta # ç¢ºä¿ datetime çµ„ä»¶å¯ç”¨

# --- 1. ç²å–è¨˜éŒ„å™¨ ---
# ä½¿ç”¨ __name__ æœ‰åŠ©æ–¼å€åˆ†ä¾†è‡ªä¸åŒå„²å­˜æ ¼/æ¨¡çµ„çš„æ—¥èªŒè¨Šæ¯
logger = logging.getLogger(__name__)

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 2: ç’°å¢ƒæª¢æŸ¥ã€ç›®éŒ„èˆ‡å¿«å–è¨­å®š" # æ¨™è­˜ç¬¦æœ¬èº«å»ºè­° ASCII

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­" # åˆå§‹ç‹€æ…‹
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„è¼¸å…¥åƒæ•¸
_cell_outputs = {} # è¨˜éŒ„é—œéµè¼¸å‡ºä¿¡æ¯/æ‘˜è¦
_cell_generated_files = [] # Cell 2 ä¸»è¦å‰µå»ºç›®éŒ„

# --- 4. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 4.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")
    print(f"--- {_cell_identifier} (v3.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    # æª¢æŸ¥ä¾†è‡ª Cell 1 çš„åŸºæœ¬å…¨å±€è®Šæ•¸
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ PROJECT_CONFIG æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ EXECUTION_TRACKER æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        # å˜—è©¦é‡æ–°ç²å– loggerï¼Œä»¥é˜²è¬ä¸€
        logger = logging.getLogger(__name__)
        if not isinstance(logger, logging.Logger):
             raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ logger æœªå®šç¾©æˆ–ä¸æ˜¯ Logger å¯¦ä¾‹ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
        else:
             logger.warning(f"{_cell_identifier}: Logger åœ¨ Cell 1 å¯èƒ½æœªæ­£ç¢ºè¨­ç½®ï¼Œå·²é‡æ–°ç²å–ã€‚")
             _cell_warnings.append("Logger åœ¨ Cell 1 å¯èƒ½æœªæ­£ç¢ºè¨­ç½®ï¼Œå·²é‡æ–°ç²å–ã€‚")

    # æª¢æŸ¥ os æ¨¡çµ„ (ç†è«–ä¸Šæ¨™æº–åº«ç¸½æ˜¯åœ¨)
    if 'os' not in globals() or not hasattr(os, 'makedirs'):
         raise ImportError("åš´é‡éŒ¯èª¤ï¼šPython æ¨™æº–åº« 'os' æ¨¡çµ„ä¸å¯ç”¨ã€‚")

    logger.info("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéï¼šPROJECT_CONFIG, EXECUTION_TRACKER, logger, os å‡å¯ç”¨ã€‚")
    _cell_notes.append("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")

    # --- 4.2. ç²å–ç›®éŒ„è·¯å¾‘ ---
    logger.info("æ­¥é©Ÿ 1ï¼šå¾ PROJECT_CONFIG æª¢ç´¢ç›®éŒ„è·¯å¾‘...")
    _output_dir = PROJECT_CONFIG.get('output_dir')
    _cache_dir = PROJECT_CONFIG.get('cache_dir')

    _cell_inputs['è¼¸å‡ºç›®éŒ„è·¯å¾‘ (ä¾†è‡ªé…ç½®)'] = _output_dir
    _cell_inputs['å¿«å–ç›®éŒ„è·¯å¾‘ (ä¾†è‡ªé…ç½®)'] = _cache_dir

    # é©—è­‰è·¯å¾‘æ˜¯å¦ç‚ºæœ‰æ•ˆå­—ç¬¦ä¸²
    if not isinstance(_output_dir, str) or not _output_dir:
        raise ValueError("åš´é‡éŒ¯èª¤ï¼šPROJECT_CONFIG ä¸­çš„ 'output_dir' ç„¡æ•ˆæˆ–ç¼ºå¤±ã€‚")
    if not isinstance(_cache_dir, str) or not _cache_dir:
        raise ValueError("åš´é‡éŒ¯èª¤ï¼šPROJECT_CONFIG ä¸­çš„ 'cache_dir' ç„¡æ•ˆæˆ–ç¼ºå¤±ã€‚")

    logger.info(f"ç›®éŒ„è·¯å¾‘å·²æª¢ç´¢ï¼šoutput='{_output_dir}', cache='{_cache_dir}'")
    print(f"ç›®æ¨™ç›®éŒ„ï¼šè¼¸å‡º='{_output_dir}', å¿«å–='{_cache_dir}'")
    _cell_notes.append(f"ç›®æ¨™è¼¸å‡ºç›®éŒ„ï¼š{_output_dir}")
    _cell_notes.append(f"ç›®æ¨™å¿«å–ç›®éŒ„ï¼š{_cache_dir}")

    # --- 4.3. å‰µå»ºç›®éŒ„ ---
    logger.info("æ­¥é©Ÿ 2ï¼šå‰µå»ºè¼¸å‡ºå’Œå¿«å–ç›®éŒ„ (å¦‚æœä¸å­˜åœ¨)...")
    print("æ­¥é©Ÿ 2ï¼šå‰µå»ºè¼¸å‡ºå’Œå¿«å–ç›®éŒ„ (å¦‚æœä¸å­˜åœ¨)...")
    _dirs_to_create = {'è¼¸å‡ºç›®éŒ„': _output_dir, 'å¿«å–ç›®éŒ„': _cache_dir}
    _dirs_created_status = {}

    for dir_desc, dir_path in _dirs_to_create.items():
        try:
            os.makedirs(dir_path, exist_ok=True)
            # å¯é¸ï¼šæ·»åŠ æª¢æŸ¥ä»¥ç¢ºèªç›®éŒ„ç¾åœ¨ç¢ºå¯¦å­˜åœ¨
            if os.path.isdir(dir_path):
                create_note = f"å·²ç¢ºä¿ {dir_desc} '{dir_path}' å­˜åœ¨ã€‚"
                _cell_notes.append(create_note)
                logger.info(create_note)
                print(f" - {create_note}")
                _dirs_created_status[dir_desc] = "å·²å­˜åœ¨æˆ–å·²å‰µå»º"
            else:
                # é›–ç„¶ makedirs æ²’å ±éŒ¯ï¼Œä½†ç›®éŒ„ä»ä¸å­˜åœ¨ï¼Œé€™å¾ˆå¥‡æ€ª
                err_msg = f"å‰µå»º {dir_desc} '{dir_path}' å¾Œæœªèƒ½ç¢ºèªå…¶å­˜åœ¨ã€‚"
                raise OSError(err_msg)
        except OSError as e:
            err_msg = f"ç„¡æ³•å‰µå»ºæˆ–è¨ªå• {dir_desc} '{dir_path}'ï¼š{e}"
            logger.error(err_msg, exc_info=True)
            # æ±ºå®šæ˜¯å¦è¦å› ç‚ºç›®éŒ„å‰µå»ºå¤±æ•—è€Œåœæ­¢
            # å°æ–¼è¼¸å‡ºå’Œå¿«å–ç›®éŒ„ï¼Œé€šå¸¸æ˜¯é—œéµçš„ï¼Œæ‰€ä»¥å¼•ç™¼éŒ¯èª¤
            raise OSError(err_msg) from e
        except Exception as e:
            # æ•ç²å…¶ä»–æ½›åœ¨éŒ¯èª¤
            err_msg = f"å‰µå»º {dir_desc} '{dir_path}' æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤ï¼š{e}"
            logger.error(err_msg, exc_info=True)
            raise Exception(err_msg) from e

    _cell_outputs['ç›®éŒ„å‰µå»ºç‹€æ…‹'] = _dirs_created_status
    logger.info("ç›®éŒ„å‰µå»ºæ­¥é©Ÿå®Œæˆã€‚")
    _cell_notes.append("ç›®éŒ„å‰µå»ºæª¢æŸ¥å®Œæˆã€‚")

    # --- 4.4. è¨­å®šè«‹æ±‚å¿«å– ---
    logger.info("æ­¥é©Ÿ 3ï¼šè¨­å®šè«‹æ±‚å¿«å– (requests-cache)...")
    print("æ­¥é©Ÿ 3ï¼šè¨­å®šè«‹æ±‚å¿«å– (requests-cache)...")
    _cache_status = "æœªå˜—è©¦ (å‡½å¼åº«ä¸å¯ç”¨)"
    # æª¢æŸ¥ requests_cache æ˜¯å¦åœ¨ Cell 1 æˆåŠŸå°å…¥
    if 'requests_cache' in globals() and requests_cache:
        _cache_name = PROJECT_CONFIG.get('cache_name')
        _cache_expire_after = PROJECT_CONFIG.get('cache_expire_after')
        _cache_backend = 'sqlite' # å¸¸ç”¨å¾Œç«¯

        _cell_inputs['å¿«å–åç¨± (ä¾†è‡ªé…ç½®)'] = _cache_name
        _cell_inputs['å¿«å–æœ‰æ•ˆæœŸ (ä¾†è‡ªé…ç½®)'] = str(_cache_expire_after) # è¨˜éŒ„ç‚ºå­—ä¸²
        _cell_inputs['å¿«å–å¾Œç«¯'] = _cache_backend

        if not _cache_name:
            warn_msg = "è­¦å‘Šï¼šPROJECT_CONFIG ä¸­ç¼ºå°‘ 'cache_name'ã€‚è·³éå¿«å–è¨­å®šã€‚"
            _cell_warnings.append(warn_msg)
            logger.warning(warn_msg)
            print(f" - {warn_msg}")
            _cache_status = "å·²è·³é (ç¼ºå°‘é…ç½®)"
        else:
            try:
                # æ§‹å»ºå¿«å–æ–‡ä»¶çš„å®Œæ•´è·¯å¾‘
                _cache_path = os.path.join(_cache_dir, f"{_cache_name}.{_cache_backend}")
                _cell_inputs['å®Œæ•´å¿«å–è·¯å¾‘'] = _cache_path

                logger.info(f"å˜—è©¦å®‰è£å¿«å–ï¼šåç¨±='{_cache_name}', è·¯å¾‘='{_cache_path}', å¾Œç«¯='{_cache_backend}', æœ‰æ•ˆæœŸ={_cache_expire_after}")
                requests_cache.install_cache(
                    cache_name=_cache_path, # æä¾›å®Œæ•´è·¯å¾‘
                    backend=_cache_backend,
                    expire_after=_cache_expire_after,
                    # å¯é¸ï¼šæ·»åŠ å…¶ä»– requests-cache é¸é …
                    # allowable_methods=('GET', 'POST'), # æ ¹æ“šéœ€è¦å…è¨±çš„æ–¹æ³•
                    # filter_fn=lambda r: r.request.url.startswith('https://api.example.com') # éæ¿¾ç‰¹å®š URL
                )
                # æª¢æŸ¥å¿«å–æ˜¯å¦çœŸçš„è¢«å•Ÿç”¨
                if requests_cache.is_installed():
                    cache_note = f"å·²æˆåŠŸå®‰è£è«‹æ±‚å¿«å–ï¼šè·¯å¾‘='{_cache_path}', æœ‰æ•ˆæœŸ={_cache_expire_after}ã€‚"
                    _cell_notes.append(cache_note)
                    logger.info(cache_note)
                    print(f" - {cache_note}")
                    _cache_status = "å·²å•Ÿç”¨"
                else:
                    err_msg = "å®‰è£è«‹æ±‚å¿«å–å¾Œæœªèƒ½ç¢ºèªå…¶å·²å•Ÿç”¨ã€‚"
                    _cell_error = err_msg # è¨˜éŒ„ç‚ºéŒ¯èª¤
                    logger.error(err_msg)
                    print(f" - \u274C {err_msg}")
                    _cache_status = "å¤±æ•— (æœªå•Ÿç”¨)"

            except Exception as cache_err:
                err_msg = f"è¨­å®šè«‹æ±‚å¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{cache_err.__class__.__name__}: {cache_err}"
                _cell_error = err_msg # è¨˜éŒ„ç‚ºéŒ¯èª¤
                logger.error(err_msg, exc_info=True)
                print(f" - \u274C {err_msg}")
                _cache_status = f"å¤±æ•— ({cache_err.__class__.__name__})"
    else:
        warn_msg = "è­¦å‘Šï¼šrequests-cache å‡½å¼åº«æœªåœ¨ Cell 1 æˆåŠŸå°å…¥ã€‚è·³éå¿«å–è¨­å®šã€‚"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(f" - {warn_msg}")
        # _cache_status ä¿æŒ "æœªå˜—è©¦ (å‡½å¼åº«ä¸å¯ç”¨)"

    _cell_outputs['è«‹æ±‚å¿«å–ç‹€æ…‹'] = _cache_status
    logger.info("è«‹æ±‚å¿«å–è¨­å®šæ­¥é©Ÿå®Œæˆã€‚")
    _cell_notes.append("è«‹æ±‚å¿«å–è¨­å®šæª¢æŸ¥å®Œæˆã€‚")

    # --- æ¨™è¨˜æˆåŠŸ ---
    # åƒ…ç•¶æ‰€æœ‰æ­¥é©Ÿéƒ½ç„¡è‡´å‘½éŒ¯èª¤å®Œæˆæ™‚æ‰æ¨™è¨˜ç‚ºæˆåŠŸ
    if _cell_status == "è™•ç†ä¸­" and not _cell_error: # æª¢æŸ¥æ˜¯å¦å·²æœ‰éŒ¯èª¤è¢«è¨˜éŒ„
        _cell_status = "æˆåŠŸ"
        logger.info(f"{_cell_identifier} åŸ·è¡ŒæˆåŠŸã€‚")
        print(f"--- {_cell_identifier} åŸ·è¡ŒæˆåŠŸ ---")
        _cell_notes.append("å„²å­˜æ ¼åŸ·è¡ŒæˆåŠŸã€‚")
    elif _cell_error: # å¦‚æœä¹‹å‰æ­¥é©Ÿè¨˜éŒ„äº†éè‡´å‘½éŒ¯èª¤ï¼Œä½†æµç¨‹ç¹¼çºŒäº†
         _cell_status = "å¤±æ•—" # å°‡æœ€çµ‚ç‹€æ…‹æ¨™è¨˜ç‚ºå¤±æ•—
         logger.warning(f"{_cell_identifier} åŸ·è¡ŒæœŸé–“é‡åˆ°éè‡´å‘½éŒ¯èª¤ï¼Œæœ€çµ‚ç‹€æ…‹æ¨™è¨˜ç‚ºå¤±æ•—ã€‚")
         print(f"--- {_cell_identifier} åŸ·è¡Œå®Œæˆä½†æœ‰éŒ¯èª¤è¨˜éŒ„ ---")
         _cell_notes.append("å„²å­˜æ ¼åŸ·è¡Œå®Œæˆä½†æœ‰éŒ¯èª¤è¨˜éŒ„ï¼Œç‹€æ…‹æ¨™è¨˜ç‚ºå¤±æ•—ã€‚")


# --- 5. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError) as prereq_err:
    _cell_status = "å¤±æ•—"
    _cell_error = f"é…ç½®æˆ–å…ˆæ±ºæ¢ä»¶éŒ¯èª¤ï¼š{prereq_err.__class__.__name__}ï¼š{prereq_err}"
    _cell_traceback = traceback.format_exc()
    # å˜—è©¦è¨˜éŒ„éŒ¯èª¤ï¼Œå³ä½¿ logger å¯èƒ½æœ‰å•é¡Œ
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
except OSError as os_err:
    _cell_status = "å¤±æ•—"
    # _cell_error å¯èƒ½å·²åœ¨ try å¡Šä¸­è¨­ç½®ï¼Œå¦‚æœæ²’æœ‰å‰‡è¨­ç½®
    if not _cell_error: _cell_error = f"æ–‡ä»¶ç³»çµ±éŒ¯èª¤ï¼š{os_err.__class__.__name__}ï¼š{os_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.error(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
except Exception as e: # æ•ç²æ‰€æœ‰å…¶ä»–æ„å¤–éŒ¯èª¤
    # åƒ…ç•¶ç‹€æ…‹ä»ç‚ºâ€œè™•ç†ä¸­â€æ™‚æ‰æ›´æ–°ç‚ºå¤±æ•—ï¼Œä»¥é¿å…è¦†è“‹æ›´å…·é«”çš„éŒ¯èª¤
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—"
        _cell_error = f"æ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}ï¼š{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} å› æ„å¤–éŒ¯èª¤è€Œå¤±æ•—ï¼š{_cell_error}", exc_info=True)
        except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
        print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    # å¦‚æœå·²è¨˜éŒ„éŒ¯èª¤ä½†æœªè¨˜éŒ„ tracebackï¼Œå‰‡æ•ç²å®ƒ
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} ç‚ºéŒ¯èª¤æ•ç²äº†å›é€€ tracebackï¼š{_cell_error}", exc_info=True)
         except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")


finally:
    # --- 6. å¼·åˆ¶æ€§çš„åŸ·è¡Œç¸½çµå ±å‘Šå’Œè¿½è¹¤å™¨æ›´æ–° ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # æ ¹æ“šç‹€æ…‹å’Œè­¦å‘Šç¢ºå®šæœ€çµ‚ç‹€æ…‹åœ–æ¨™å’Œæ–‡æœ¬
    _final_status_text = _cell_status
    if _cell_status == "å¤±æ•—":
        _final_status_icon = "âŒ"
    elif _cell_status == "å·²è·³é": # å¦‚æœæœªä¾†æ·»åŠ è·³éé‚è¼¯
        _final_status_icon = "ğŸš«"
    elif _cell_status == "è™•ç†ä¸­": # ä¸æ‡‰ç™¼ç”Ÿï¼Œè¡¨ç¤ºç•°å¸¸çµ‚æ­¢
        _final_status_icon = "â³"
        _final_status_text = "æœªå®Œæˆ"
        if not _cell_error: _cell_error = "å„²å­˜æ ¼åœ¨å®Œæˆå‰æ„å¤–çµ‚æ­¢ã€‚"
        _cell_notes.append("è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ 'è™•ç†ä¸­' ç‹€æ…‹çµæŸã€‚")
    elif _cell_warnings: # æˆåŠŸæˆ–å…¶ä»–å¸¶æœ‰è­¦å‘Šçš„ç‹€æ…‹
        _final_status_icon = "âš ï¸"
        if _cell_status == "æˆåŠŸ":
             _final_status_text = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰"
    elif _cell_status == "æˆåŠŸ": # æˆåŠŸä¸”ç„¡è­¦å‘Š
        _final_status_icon = "âœ…"
    else: # æœªçŸ¥ç‹€æ…‹çš„é»˜èªå€¼
        _final_status_icon = "â“"
        _cell_notes.append(f"è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ç„¡æ³•è­˜åˆ¥çš„ç‹€æ…‹ '{_cell_status}' çµæŸã€‚")

    # å®‰å…¨åœ°ç²å–ç•¶å‰æ™‚é–“æˆ³
    _current_time_str = "ç„¡æ³•ç²å–"
    try:
        _report_tz_info = PROJECT_CONFIG.get('_tz_info', timezone(timedelta(hours=8)))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"

    # å»ºæ§‹è¿½è¹¤è¨˜éŒ„
    _tracking_record = {
        'cell_id': _cell_identifier,
        'status_icon': _final_status_icon,
        'status_text': _final_status_text,
        'timestamp': _current_time_str,
        'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), # å»é‡ä¸¦æ’åºè­¦å‘Š
        'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes,
        'inputs': _cell_inputs, # åŒ…æ‹¬è¨˜éŒ„çš„è¼¸å…¥
        'outputs': _cell_outputs, # åŒ…æ‹¬è¨˜éŒ„çš„è¼¸å‡º/æ‘˜è¦
        'generated_files': [] # ä¸»è¦å‰µå»ºç›®éŒ„ï¼Œä¸ç”Ÿæˆå¸¸è¦æ–‡ä»¶
    }

    # å®‰å…¨åœ°æ›´æ–°å…¨å±€è¿½è¹¤å™¨
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict):
            EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else:
            # å¦‚æœ EXECUTION_TRACKER ç„¡æ•ˆï¼Œè¨˜éŒ„éŒ¯èª¤
            err_msg = f"éŒ¯èª¤ï¼šEXECUTION_TRACKER ä¸æ˜¯å­—å…¸æˆ–æœªå®šç¾©ã€‚ç„¡æ³•æ›´æ–° {_cell_identifier} çš„è¿½è¹¤è¨˜éŒ„ã€‚"
            print(err_msg)
            try: logger.error(err_msg)
            except: pass # logger å¯èƒ½ä¹Ÿç„¡æ•ˆ
    except Exception as tracker_update_err:
        err_msg = f"éŒ¯èª¤ï¼šæ›´æ–° EXECUTION_TRACKER æ™‚ç™¼ç”Ÿç•°å¸¸ï¼š{tracker_update_err}"
        print(err_msg)
        try: logger.error(err_msg, exc_info=True)
        except: pass

    # --- æ‰“å°åŸ·è¡Œç¸½çµå ±å‘Š (å¼·åˆ¶æ€§) ---
    print("\n" + "="*80)
    # å˜—è©¦å¾ PROJECT_CONFIG ç²å–æº–å‰‡ç‰ˆæœ¬ï¼Œå¦‚æœå¤±æ•—å‰‡å›é€€
    _guideline_version_str = "æœªçŸ¥æº–å‰‡ç‰ˆæœ¬"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬')
    except Exception:
        pass # ä¿æŒé»˜èªå€¼

    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon} {_final_status_text}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str}")

    # æ‰“å°è¼¸å…¥åƒæ•¸
    if _cell_inputs:
        print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ï¼š**") # é½’è¼ªè¡¨æƒ…ç¬¦è™Ÿ
        pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)

    # æ‰“å°åŸ·è¡Œè¨»è¨˜
    if _cell_notes:
      print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜ï¼š**") # å‚™å¿˜éŒ„è¡¨æƒ…ç¬¦è™Ÿ
      for note in _cell_notes: print(f"- {note}")

    # æ‰“å°è­¦å‘Šï¼ˆå¾è¿½è¹¤è¨˜éŒ„è®€å–ä»¥ç¢ºä¿ä¸€è‡´ï¼‰
    if _tracking_record.get('warnings'):
        print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**") # è­¦å‘Šæ¨™èªŒè¡¨æƒ…ç¬¦è™Ÿ
        for warning in _tracking_record['warnings']: print(f"- {warning}")

    # æ‰“å°éŒ¯èª¤ï¼ˆå¾è¿½è¹¤è¨˜éŒ„è®€å–ï¼‰
    if _tracking_record.get('error'):
        print("\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**") # å‰è™Ÿè¡¨æƒ…ç¬¦è™Ÿ
        print(f"** {_tracking_record['error']} **")

    # æ‰“å° Tracebackï¼ˆå¾è¿½è¹¤è¨˜éŒ„è®€å–ï¼‰
    if _tracking_record.get('traceback'):
        print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20)
        print(f"<pre>{_tracking_record['traceback']}</pre>")
        print("-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))

    # æ‰“å°è¼¸å‡ºæ‘˜è¦ï¼ˆå¾è¿½è¹¤è¨˜éŒ„è®€å–ï¼‰
    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦ï¼š**") # æ¢å½¢åœ–è¡¨æƒ…ç¬¦è™Ÿ
    tracked_outputs = _tracking_record.get('outputs')
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]:
         print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs:
         info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚",
                      "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚",
                      "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚")
         print(f"- {info_text}")
    else:
     pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)

    # Cell 2 ä¸ç”Ÿæˆå¸¸è¦æ–‡ä»¶ï¼Œç„¡éœ€æ‰“å° 'ç”Ÿæˆ/ç›¸é—œæ–‡ä»¶è·¯å¾‘'

    print("="*80 + "\n")

    # --- 7. æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_output_dir', '_cache_dir',
        '_dirs_to_create', '_dirs_created_status', 'dir_desc', 'dir_path',
        '_cache_status', '_cache_name', '_cache_expire_after', '_cache_backend',
        '_cache_path', 'create_note', 'cache_note', 'warn_msg', 'err_msg',
        'info_text', 'prereq_err', 'os_err', 'cache_err', 'e', 'time_err',
        'time_err_local', 'tracker_update_err', '_guideline_version_str'
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try:
                del locals()[_var]
            except KeyError:
                pass
    try:
        logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: # å¦‚æœ logger åˆå§‹åŒ–å¤±æ•—
        print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 2: ç’°å¢ƒæª¢æŸ¥ã€ç›®éŒ„èˆ‡å¿«å–è¨­å®š (å·¥ä½œæµç¨‹å¾æ­¤é–‹å§‹)
# åŠŸèƒ½: æª¢æŸ¥ Cell 1 åˆå§‹åŒ–ç‹€æ…‹ï¼Œå‰µå»ºè¼¸å‡º/å¿«å–ç›®éŒ„ï¼Œä¸¦è¨­å®šè«‹æ±‚å¿«å–ã€‚
# ç‰ˆæœ¬: 3.4-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger']
# è¼¸å…¥: ['global:PROJECT_CONFIG']
# è¼¸å‡º: ['Directory:PROJECT_CONFIG["output_dir"]', 'Directory:PROJECT_CONFIG["cache_dir"]', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 3: yfinance æ•¸æ“šç²å– (TWD/USD, VIX) (å«é‡è©¦æ©Ÿåˆ¶)
# --------------------------------------------------
# åŠŸèƒ½: ä½¿ç”¨ yfinance ç²å– TWD/USD å³æœŸåŒ¯ç‡å’Œ VIX æŒ‡æ•¸çš„æ—¥é »æ­·å²æ•¸æ“šï¼Œå¢åŠ å° YFRateLimitError çš„é‡è©¦æ©Ÿåˆ¶ã€‚
# ç‰ˆæœ¬: 3.4.2-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¸­æ–‡è¨»è§£ç‰ˆï¼Œå¢å¼·é‡è©¦å’ŒéŒ¯èª¤æ•ç²)
# æ—¥æœŸ: 2025-05-07
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:yf', 'global:pd', 'global:tenacity', 'global:requests']
# è¼¸å…¥: ['global:PROJECT_CONFIG'] (é–“æ¥ç²å–æ™‚å€å’Œé‡è©¦é…ç½®ç­‰ä¿¡æ¯)
# è¼¸å‡º: ['global:df_twdusd', 'global:df_vix', 'global:EXECUTION_TRACKER (updated)'] # å°‡æ•¸æ“šå­˜ç‚ºå…¨å±€è®Šæ•¸
# --------------------------------------------------
# ==================================================
"""
ä½¿ç”¨ yfinance å‡½å¼åº«ç²å–åŸºç¤å¸‚å ´æ•¸æ“šï¼Œä¸¦å¢åŠ å° API é€Ÿç‡é™åˆ¶éŒ¯èª¤çš„è‡ªå‹•é‡è©¦åŠŸèƒ½ã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) å’Œå‡½å¼åº« (`yf`, `pd`, `tenacity`, `requests`) çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  å®šç¾©éœ€è¦ç²å–çš„é‡‘èä»£ç¢¼ (tickers)ï¼š'TWD=X' (æ–°å°å¹£å…Œç¾å…ƒ) å’Œ '^VIX' (æ³¢å‹•ç‡æŒ‡æ•¸)ã€‚
3.  è¨­å®šæ•¸æ“šç²å–çš„æ™‚é–“ç¯„åœã€‚
4.  å¾ `PROJECT_CONFIG` ç²å–é‡è©¦åƒæ•¸ (ç­‰å¾…æ™‚é–“ã€å˜—è©¦æ¬¡æ•¸)ã€‚
5.  å®šç¾©ä¸€å€‹å…§éƒ¨å‡½æ•¸ `_fetch_yfinance_with_retry`ï¼Œä½¿ç”¨ `@tenacity.retry` è£é£¾å™¨ï¼š
    a. è©²å‡½æ•¸å˜—è©¦ä½¿ç”¨ `yf.Ticker(ticker_symbol).history()` ç²å–æ•¸æ“šã€‚
    b. é‡è©¦æ¢ä»¶åŒ…æ‹¬ `yfinance.errors.YFRateLimitError` (å¦‚æœèƒ½å°å…¥) æˆ–åŸºæ–¼éŒ¯èª¤è¨Šæ¯åˆ¤æ–·çš„é€Ÿç‡é™åˆ¶éŒ¯èª¤ï¼Œä»¥åŠå…¶ä»–å¯èƒ½çš„ç¶²è·¯ç›¸é—œç•°å¸¸ (å¦‚ `requests.exceptions.RequestException`, `requests.exceptions.HTTPError` ç‹€æ…‹ç¢¼ 429)ã€‚
    c. åœ¨é‡è©¦å‰è¨˜éŒ„æ—¥èªŒã€‚
6.  è¿­ä»£è™•ç†æ¯å€‹ tickerï¼Œèª¿ç”¨å¸¶æœ‰é‡è©¦é‚è¼¯çš„ç²å–å‡½æ•¸ã€‚
7.  å°‡æˆåŠŸç²å–çš„æ•¸æ“šå„²å­˜åˆ°å°æ‡‰çš„å…¨å±€ Pandas DataFrame è®Šæ•¸ä¸­ (`df_twdusd`, `df_vix`)ã€‚
8.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ï¼ˆä¾‹å¦‚ç²å–åˆ°çš„æ•¸æ“šè¡Œæ•¸ï¼‰ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* å¼•å…¥ `tenacity` å¯¦ç¾å° yfinance API è«‹æ±‚çš„è‡ªå‹•é‡è©¦ï¼Œä»¥æ‡‰å°æš«æ™‚çš„é€Ÿç‡é™åˆ¶ã€‚
* é‡è©¦åƒæ•¸å¯é€šé `PROJECT_CONFIG` é…ç½®ã€‚
* å¢å¼·äº†å° yfinance éŒ¯èª¤é¡å‹çš„åˆ¤æ–·ï¼Œå³ä½¿ `yfinance.errors` æ¨¡å¡Šä¸æ˜“ç›´æ¥å°å…¥ã€‚
* å…¶ä»–é‚è¼¯èˆ‡å…ˆå‰ç‰ˆæœ¬ç›¸ä¼¼ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´ä¾†è‡ª Cell 1 çš„å…¨å±€è®Šæ•¸å’Œå‡½å¼åº«)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ DataFrame è®Šæ•¸ `df_twdusd`, `df_vix`ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸æˆ–å‡½å¼åº«æœªå®šç¾©ã€‚
    AttributeError: å¦‚æœ `yf` å°è±¡æ²’æœ‰é æœŸçš„æ–¹æ³•ã€‚
    tenacity.RetryError: å¦‚æœé‡è©¦å¾Œä»ç„¶é”åˆ°é€Ÿç‡é™åˆ¶æˆ–ç™¼ç”Ÿå…¶ä»–æŒçºŒæ€§éŒ¯èª¤ã€‚
    Exception: æ•ç² `yfinance` åœ¨æ•¸æ“šç²å–éç¨‹ä¸­å¯èƒ½å¼•ç™¼çš„å…¶ä»–éŒ¯èª¤ã€‚

å‡è¨­ï¼š
* Cell 1 å·²æˆåŠŸåŸ·è¡Œï¼Œä¸” `yfinance` (yf), `pandas` (pd), `tenacity`, `requests` å·²æˆåŠŸå°å…¥ã€‚
* Colab ç’°å¢ƒå¯ä»¥è¨ªå• Yahoo Finance çš„æ•¸æ“šã€‚
* `PROJECT_CONFIG` ä¸­å¯ä»¥é…ç½® `rate_limit_handler`ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* å³ä½¿æœ‰é‡è©¦ï¼Œå¦‚æœé€Ÿç‡é™åˆ¶éå¸¸åš´æ ¼æˆ– Yahoo Finance API æœå‹™æœ¬èº«æœ‰å•é¡Œï¼Œè«‹æ±‚ä»å¯èƒ½æœ€çµ‚å¤±æ•—ã€‚
* `yfinance` å…§éƒ¨éŒ¯èª¤çš„å¤šæ¨£æ€§ï¼Œå¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›é‡åˆ°çš„éŒ¯èª¤èª¿æ•´é‡è©¦çš„ç•°å¸¸é¡å‹ã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 4 (Alpha Vantage æ•¸æ“šç²å–)ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timedelta # ç”¨æ–¼è¨­å®šæ—¥æœŸç¯„åœ

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)
_YFINANCE_ERRORS_MODULE_AVAILABLE = False
try:
    # å˜—è©¦å°å…¥ yfinance å¯èƒ½æ‹‹å‡ºçš„ç‰¹å®šéŒ¯èª¤é¡å‹ï¼Œä»¥ä¾¿æ›´ç²¾ç¢ºåœ°æ•ç²
    import yfinance.errors
    _YFINANCE_ERRORS_MODULE_AVAILABLE = True
except ImportError:
    logger.warning("ç„¡æ³•ç›´æ¥å°å…¥ yfinance.errors æ¨¡å¡Šï¼Œå°‡ä¸»è¦ä¾è³´éŒ¯èª¤è¨Šæ¯å­—ç¬¦ä¸²å’Œ requests ç•°å¸¸é€²è¡Œé‡è©¦åˆ¤æ–·ã€‚")

try:
    import pandas as pd
    import yfinance as yf
    import tenacity
    import requests # yfinance åº•å±¤ä½¿ç”¨ requestsï¼Œæ•ç²å…¶ç•°å¸¸æœ‰åŠ©æ–¼ç¶²è·¯å•é¡Œé‡è©¦
    if 'libs_loaded' in globals():
        if not libs_loaded.get('tenacity', False):
            logger.warning("æ ¹æ“š libs_loadedï¼Œtenacity å¯èƒ½æœªåœ¨ Cell 1 æ­£ç¢ºåŠ è¼‰ã€‚")
        if not libs_loaded.get('requests', False):
            logger.warning("æ ¹æ“š libs_loadedï¼Œrequests å¯èƒ½æœªåœ¨ Cell 1 æ­£ç¢ºåŠ è¼‰ã€‚")
except ImportError as e:
    logger.critical(f"Cell 3 åŸ·è¡Œæ‰€éœ€çš„é—œéµå‡½å¼åº«å°å…¥å¤±æ•—: {e}")
    raise # å¦‚æœé€™äº›æ ¸å¿ƒåº«éƒ½ç„¡æ³•å°å…¥ï¼Œå¾ŒçºŒç„¡æ³•åŸ·è¡Œ

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 3: yfinance æ•¸æ“šç²å– (TWD/USD, VIX) (å«é‡è©¦æ©Ÿåˆ¶)"

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. å…¨å±€ DataFrame è®Šæ•¸åˆå§‹åŒ– ---
df_twdusd = None
df_vix = None
_tickers_to_fetch = {} # åˆå§‹åŒ–ï¼Œä»¥é˜² try å¡Šæ—©æœŸå‡ºéŒ¯

# --- 5. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 5.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4.2-zh-fc) é–‹å§‹åŸ·è¡Œ ---")
    print(f"--- {_cell_identifier} (v3.4.2-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ PROJECT_CONFIG æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ EXECUTION_TRACKER æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ logger æœªå®šç¾©æˆ–ä¸æ˜¯ Logger å¯¦ä¾‹ã€‚")
    if 'yf' not in globals() or not hasattr(yf, 'Ticker'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šyfinance å‡½å¼åº« (yf) æœªæˆåŠŸå°å…¥ã€‚")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼špandas å‡½å¼åº« (pd) æœªæˆåŠŸå°å…¥ã€‚")
    if 'tenacity' not in globals() or not hasattr(tenacity, 'retry'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼štenacity å‡½å¼åº«æœªæˆåŠŸå°å…¥ï¼ˆç”¨æ–¼é‡è©¦æ©Ÿåˆ¶ï¼‰ã€‚")
    if 'requests' not in globals() or not hasattr(requests, 'exceptions'): # æª¢æŸ¥ requests.exceptions æ˜¯å¦å­˜åœ¨
        raise NameError("åš´é‡éŒ¯èª¤ï¼šrequests å‡½å¼åº«æœªæˆåŠŸå°å…¥ï¼ˆç”¨æ–¼ç¶²è·¯éŒ¯èª¤åˆ¤æ–·ï¼‰ã€‚")


    logger.info("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")
    _cell_notes.append("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")

    # --- 5.2. å®šç¾© Tickers å’Œç²å–åƒæ•¸ ---
    _tickers_to_fetch = {
        'TWD=X': 'df_twdusd',
        '^VIX': 'df_vix'
    }
    _start_date = (datetime.now() - timedelta(days=15*365)).strftime('%Y-%m-%d')
    _interval = '1d'

    _cell_inputs['Tickers'] = list(_tickers_to_fetch.keys())
    _cell_inputs['é–‹å§‹æ—¥æœŸ'] = _start_date
    _cell_inputs['æ™‚é–“é–“éš”'] = _interval
    logger.info(f"æº–å‚™ç²å– Tickers: {list(_tickers_to_fetch.keys())}ï¼Œå¾ {_start_date} é–‹å§‹ï¼Œé–“éš” {_interval}ã€‚")
    print(f"æº–å‚™ç²å– Tickers: {list(_tickers_to_fetch.keys())}")

    # --- 5.3. è¨­å®šé‡è©¦åƒæ•¸ ---
    _retry_config = PROJECT_CONFIG.get('rate_limit_handler', {})
    _wait_seconds = _retry_config.get('wait_fixed_seconds_yfinance', _retry_config.get('wait_fixed_seconds', 30)) # é»˜èªç­‰å¾…30ç§’
    _stop_attempts = _retry_config.get('stop_after_attempt_yfinance', _retry_config.get('stop_after_attempt', 3)) # é»˜èªå˜—è©¦3æ¬¡

    _cell_inputs['é‡è©¦ç­‰å¾…ç§’æ•¸'] = _wait_seconds
    _cell_inputs['æœ€å¤§é‡è©¦æ¬¡æ•¸'] = _stop_attempts
    logger.info(f"yfinance è«‹æ±‚é‡è©¦è¨­å®šï¼šç­‰å¾… {_wait_seconds} ç§’ï¼Œæœ€å¤šå˜—è©¦ {_stop_attempts} æ¬¡ã€‚")

    # --- 5.4. å®šç¾©å¸¶é‡è©¦çš„ç²å–å‡½æ•¸ ---
    def _is_yfinance_specific_rate_limit_error(e):
        """æª¢æŸ¥æ˜¯å¦ç‚º yfinance.errors.YFRateLimitError (å¦‚æœæ¨¡å¡Šå¯ç”¨)"""
        if _YFINANCE_ERRORS_MODULE_AVAILABLE and isinstance(e, yfinance.errors.YFRateLimitError):
            return True
        # æœ‰äº›æƒ…æ³ä¸‹ yfinance æœƒæ‹‹å‡º yf.libs.yfinance.shared.YFinanceException
        if isinstance(e, yf.libs.yfinance.shared.YFinanceException):
            err_str = str(e).lower()
            if "rate limit" in err_str or "too many requests" in err_str:
                return True
        return False

    def _should_retry_yfinance_error(retry_state: tenacity.RetryCallState):
        """æ±ºå®šæ˜¯å¦é‡è©¦ yfinance çš„ç‰¹å®šéŒ¯èª¤ã€‚"""
        exc = retry_state.outcome.exception()
        attempt_number_str = f"(å˜—è©¦ {retry_state.attempt_number}/{_stop_attempts})"

        if _is_yfinance_specific_rate_limit_error(exc):
            logger.warning(f"yfinance è«‹æ±‚é‡åˆ° API é€Ÿç‡é™åˆ¶ {attempt_number_str}ï¼Œå°‡åœ¨ {_wait_seconds} ç§’å¾Œé‡è©¦ï¼š{exc}")
            return True
        # æª¢æŸ¥ requests å±¤ç´šçš„ HTTP éŒ¯èª¤ï¼Œç‰¹åˆ¥æ˜¯ 429
        if isinstance(exc, requests.exceptions.HTTPError):
            if exc.response is not None and exc.response.status_code == 429: # HTTP 429 Too Many Requests
                logger.warning(f"yfinance è«‹æ±‚è¿”å› HTTP 429 (Too Many Requests) {attempt_number_str}ï¼Œå°‡åœ¨ {_wait_seconds} ç§’å¾Œé‡è©¦ã€‚")
                return True
            # å¯ä»¥è€ƒæ…®é‡è©¦å…¶ä»–å¦‚ 5xx çš„æœå‹™å™¨éŒ¯èª¤
            # if exc.response is not None and 500 <= exc.response.status_code < 600:
            #     logger.warning(f"yfinance è«‹æ±‚è¿”å› HTTP {exc.response.status_code} (æœå‹™å™¨éŒ¯èª¤) {attempt_number_str}ï¼Œå°‡é‡è©¦ã€‚")
            #     return True

        # æª¢æŸ¥å¸¸è¦‹çš„ç¶²è·¯é€£ç·šéŒ¯èª¤
        if isinstance(exc, (requests.exceptions.ConnectionError, requests.exceptions.Timeout, requests.exceptions.ChunkedEncodingError)):
            logger.warning(f"yfinance è«‹æ±‚é‡åˆ°ç¶²è·¯é€£ç·šå•é¡Œ {attempt_number_str}ï¼Œå°‡åœ¨ {_wait_seconds} ç§’å¾Œé‡è©¦ï¼š{exc}")
            return True

        # å°æ–¼å…¶ä»–é¡å‹çš„ yfinance å…§éƒ¨éŒ¯èª¤ï¼Œæˆ–è€…éŒ¯èª¤è¨Šæ¯ä¸­æ˜ç¢ºæåˆ°é€Ÿç‡é™åˆ¶çš„
        err_str_lower = str(exc).lower()
        if "too many requests" in err_str_lower or "rate limited" in err_str_lower:
            logger.warning(f"yfinance è«‹æ±‚é‡åˆ°ç–‘ä¼¼é€Ÿç‡é™åˆ¶çš„éŒ¯èª¤ {attempt_number_str} (åŸºæ–¼éŒ¯èª¤è¨Šæ¯)ï¼Œå°‡åœ¨ {_wait_seconds} ç§’å¾Œé‡è©¦ï¼š{exc}")
            return True

        logger.error(f"yfinance è«‹æ±‚é‡åˆ°ä¸å¯é‡è©¦çš„éŒ¯èª¤ {attempt_number_str}ï¼š{exc.__class__.__name__}: {exc}")
        return False # å°æ–¼å…¶ä»–æœªçŸ¥éŒ¯èª¤ï¼Œä¸é‡è©¦

    @tenacity.retry(
        wait=tenacity.wait_fixed(_wait_seconds),
        stop=tenacity.stop_after_attempt(_stop_attempts),
        retry=_should_retry_yfinance_error,
        reraise=True
    )
    def _fetch_yfinance_with_retry(ticker_symbol: str, start_date: str, interval: str) -> pd.DataFrame:
        logger.debug(f"èª¿ç”¨ yf.Ticker('{ticker_symbol}').history(start='{start_date}', interval='{interval}')")
        ticker_obj = yf.Ticker(ticker_symbol)
        # å¢åŠ  timeout åƒæ•¸çµ¦ yfinance çš„è«‹æ±‚ (å¦‚æœ yfinance æ”¯æŒç›´æ¥å‚³é)
        # yfinance çš„ history æ–¹æ³•æœ¬èº«ä¸ç›´æ¥æ¥å— timeoutï¼Œå®ƒåº•å±¤çš„ requests æœƒæœ‰é»˜èªå€¼
        # ä½†æˆ‘å€‘å¯ä»¥é€šé yf.set_proxy æˆ–å…¶ä»–æ–¹å¼é–“æ¥å½±éŸ¿
        # ç›®å‰ä¿æŒåŸæ¨£ï¼Œä¸»è¦ä¾è³´ tenacity è™•ç†è¶…æ™‚ (requests.exceptions.Timeout)
        history_df = ticker_obj.history(start=start_date, interval=interval)

        if history_df.empty:
            try:
                info = ticker_obj.info # å˜—è©¦ç²å–infoåˆ¤æ–·tickeræ˜¯å¦æœ‰æ•ˆ
                # ç°¡é™‹æª¢æŸ¥ info æ˜¯å¦çœŸçš„æœ‰æ•ˆï¼Œä»¥åŠæ˜¯å¦æœ‰åƒ¹æ ¼æ•¸æ“š
                if not info or (isinstance(info, dict) and info.get('regularMarketPrice') is None and info.get('previousClose') is None and not info.get('shortName')):
                    logger.warning(f"yf.Ticker('{ticker_symbol}').history è¿”å›ç©º DataFrameï¼Œä¸” .info çœ‹ä¼¼ç„¡æ•ˆã€‚å¯èƒ½ Ticker '{ticker_symbol}' ä¸å­˜åœ¨æˆ–ç„¡æ­¤æ™‚æ®µæ•¸æ“šã€‚")
                else: # Info æœ‰å…§å®¹ï¼Œä½† history ç‚ºç©º
                    logger.info(f"yf.Ticker('{ticker_symbol}').history è¿”å›ç©º DataFrameï¼Œä½† .info æœ‰æ•¸æ“šã€‚å¯èƒ½åœ¨æŒ‡å®šæ™‚æ®µ '{start_date}' ä¹‹å¾Œç„¡äº¤æ˜“æ•¸æ“šã€‚")
            except Exception as e_info:
                logger.warning(f"yf.Ticker('{ticker_symbol}').history è¿”å›ç©º DataFrameï¼Œå˜—è©¦ç²å– .info ä¹Ÿå¤±æ•—: {e_info}ã€‚å¯èƒ½ Ticker '{ticker_symbol}' ç„¡æ•ˆã€‚")
        return history_df

    # --- 5.5. è¿­ä»£ç²å–æ•¸æ“š ---
    _fetch_success_count = 0
    _fetch_error_count = 0

    for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
        logger.info(f"æ­£åœ¨ç²å– {ticker_symbol} çš„æ•¸æ“š (å«é‡è©¦)...")
        print(f" - æ­£åœ¨ç²å– {ticker_symbol} (å«é‡è©¦)...")
        try:
            history_df = _fetch_yfinance_with_retry(ticker_symbol, _start_date, _interval)

            if history_df.empty:
                warn_msg = f"è­¦å‘Šï¼šç²å– {ticker_symbol} çš„æ•¸æ“šç‚ºç©º DataFrame (é‡è©¦å¾Œ)ã€‚å¯èƒ½ Ticker ç„¡æ•ˆã€è©²æ™‚æ®µç„¡æ•¸æ“šæˆ–æŒçºŒçš„ API å•é¡Œã€‚"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f"   - {warn_msg}")
                _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
                globals()[df_variable_name] = history_df.copy() # è³¦å€¼ç©º DataFrame çš„å‰¯æœ¬
                _fetch_success_count += 1
            else:
                globals()[df_variable_name] = history_df.copy() # è³¦å€¼å‰¯æœ¬
                success_note = f"æˆåŠŸç²å– {ticker_symbol} çš„æ•¸æ“š ({len(history_df):,} è¡Œï¼Œé‡è©¦å¾Œ)ã€‚å·²å­˜å„²è‡³å…¨å±€è®Šæ•¸ {df_variable_name}ã€‚"
                _cell_notes.append(success_note)
                logger.info(success_note)
                print(f"   - {success_note}")
                _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ'
                _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(history_df)
                _cell_outputs[f'{df_variable_name}_åˆ—å'] = history_df.columns.tolist()
                _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = history_df.index.min().strftime('%Y-%m-%d') if not history_df.empty else 'N/A'
                _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = history_df.index.max().strftime('%Y-%m-%d') if not history_df.empty else 'N/A'
                _fetch_success_count += 1

        except tenacity.RetryError as e_retry:
            _fetch_error_count += 1
            original_exception = e_retry.last_attempt.exception()
            err_msg = f"ç²å– {ticker_symbol} æ•¸æ“šå¤±æ•— (é‡è©¦ {_stop_attempts} æ¬¡å¾Œ)ï¼š{original_exception.__class__.__name__}: {original_exception}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = f'ç²å–å¤±æ•— (é‡è©¦è€—ç›¡: {original_exception.__class__.__name__})'
            globals()[df_variable_name] = None
            if not _cell_error: _cell_error = err_msg # è¨˜éŒ„ç¬¬ä¸€å€‹ä¸»è¦éŒ¯èª¤
            if not _cell_traceback: _cell_traceback = traceback.format_exception(type(original_exception), original_exception, original_exception.__traceback__) # ç²å–åŸå§‹ç•°å¸¸çš„traceback

        except Exception as e:
            _fetch_error_count += 1
            err_msg = f"ç²å– {ticker_symbol} æ•¸æ“šæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼š{e.__class__.__name__}: {e}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = f'ç²å–å¤±æ•— ({e.__class__.__name__})'
            globals()[df_variable_name] = None
            if not _cell_error: _cell_error = err_msg
            if not _cell_traceback: _cell_traceback = traceback.format_exc()

    logger.info(f"yfinance æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")
    _cell_notes.append(f"yfinance æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")

    if _fetch_error_count == len(_tickers_to_fetch) and _fetch_success_count == 0 : # åªæœ‰åœ¨æ‰€æœ‰éƒ½å¤±æ•—æ™‚æ‰è¨­å®šcell error
        _cell_status = "å¤±æ•—"
        if not _cell_error: _cell_error = "æ‰€æœ‰ yfinance Tickers æ•¸æ“šç²å–å‡å¤±æ•— (é‡è©¦å¾Œ)ã€‚" # æ›´æ–°éŒ¯èª¤ä¿¡æ¯
        logger.error(_cell_error)
    elif _fetch_success_count > 0 : # åªè¦æœ‰ä»»ä½•ä¸€å€‹æˆåŠŸï¼ŒCell å°±è¦–ç‚ºéƒ¨åˆ†æˆåŠŸæˆ–å®Œå…¨æˆåŠŸ
        _cell_status = "æˆåŠŸ"
        if _fetch_error_count > 0: # å¦‚æœéƒ¨åˆ†æˆåŠŸéƒ¨åˆ†å¤±æ•—
            _cell_notes.append("éƒ¨åˆ† Tickers æ•¸æ“šç²å–å¤±æ•—æˆ–è¿”å›ç©ºã€‚")
            _cell_warnings.append("éƒ¨åˆ† Tickers æ•¸æ“šç²å–å¤±æ•—ã€‚") # æ·»åŠ ä¸€å€‹ç¸½é«”è­¦å‘Š
        logger.info(f"{_cell_identifier} åŸ·è¡ŒæˆåŠŸï¼ˆå¯èƒ½åŒ…å«éƒ¨åˆ†å¤±æ•—æˆ–è­¦å‘Šï¼‰ã€‚")
        print(f"--- {_cell_identifier} åŸ·è¡ŒæˆåŠŸ ---")
        _cell_notes.append("å„²å­˜æ ¼åŸ·è¡ŒæˆåŠŸã€‚")
    elif _fetch_success_count == 0 and _fetch_error_count > 0: # æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—äº†
        _cell_status = "å¤±æ•—"
        if not _cell_error: _cell_error = "æœªèƒ½æˆåŠŸç²å–ä»»ä½• yfinance Ticker çš„æ•¸æ“š (é‡è©¦å¾Œ)ã€‚"
        logger.error(_cell_error)
    # å¦‚æœ _cell_status ä»ç„¶æ˜¯ "è™•ç†ä¸­"ï¼Œèªªæ˜é‚è¼¯æœ‰å•é¡Œ
    elif _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—" # å…œåº•
        _cell_error = "å„²å­˜æ ¼ç‹€æ…‹æœªçŸ¥ï¼Œæ¨™è¨˜ç‚ºå¤±æ•—ã€‚"
        logger.error(_cell_error)


# --- 6. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ImportError, AttributeError) as prereq_err:
    _cell_status = "å¤±æ•—"
    _cell_error = f"é…ç½®æˆ–å…ˆæ±ºæ¢ä»¶éŒ¯èª¤ï¼š{prereq_err.__class__.__name__}ï¼š{prereq_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False) # exc_info=False å› ç‚ºtracebackå·²æ•ç²
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
except Exception as e:
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—"
        _cell_error = f"æ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}ï¼š{e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å› æ„å¤–éŒ¯èª¤è€Œå¤±æ•—ï¼š{_cell_error}", exc_info=True)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")


finally:
    # --- 7. å¼·åˆ¶æ€§çš„åŸ·è¡Œç¸½çµå ±å‘Šå’Œè¿½è¹¤å™¨æ›´æ–° ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    _final_status_text = _cell_status
    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "å·²è·³é": _final_status_icon = "ğŸš«"
    elif _cell_status == "è™•ç†ä¸­": _final_status_icon = "â³"; _final_status_text = "æœªå®Œæˆ"; _cell_notes.append("è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ 'è™•ç†ä¸­' ç‹€æ…‹çµæŸã€‚")
    elif _cell_warnings and _cell_status == "æˆåŠŸ": _final_status_icon = "âš ï¸"; _final_status_text = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰"
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"
    else: _final_status_icon = "â“"; _cell_notes.append(f"è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ç„¡æ³•è­˜åˆ¥çš„ç‹€æ…‹ '{_cell_status}' çµæŸã€‚")

    _current_time_str = "ç„¡æ³•ç²å–"
    try:
        _report_tz_info = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8))) if ('PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict)) else timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—": _cell_warnings.append(f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}")

    if '_tickers_to_fetch' in locals() and isinstance(_tickers_to_fetch, dict):
        for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df_val = globals()[df_variable_name] # ä½¿ç”¨ df_val é¿å…èˆ‡å¤–éƒ¨ df è¡çª
                  if not df_val.empty:
                       if f'{df_variable_name}_è¡Œæ•¸' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(df_val)
                       if f'{df_variable_name}_åˆ—å' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_åˆ—å'] = df_val.columns.tolist()
                       if f'{df_variable_name}_èµ·å§‹æ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = df_val.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_çµæŸæ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = df_val.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_æœ€æ–°æ•¸æ“š ({df_val.index.max().strftime("%Y-%m-%d")})'] = df_val.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
             elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–å¤±æ•— (è®Šæ•¸æœªå‰µå»º)'
    else: _cell_notes.append("ç„¡æ³•æ›´æ–°è¼¸å‡ºæ‘˜è¦ (_tickers_to_fetch æœªå®šç¾©)ã€‚")

    # ç¢ºä¿ traceback æ˜¯å­—ç¬¦ä¸²
    _final_traceback_str = None
    if isinstance(_cell_traceback, list): # traceback.format_exception è¿”å›åˆ—è¡¨
        _final_traceback_str = "".join(_cell_traceback)
    elif isinstance(_cell_traceback, str):
        _final_traceback_str = _cell_traceback

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _final_traceback_str.strip() if _final_traceback_str else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"éŒ¯èª¤ï¼šEXECUTION_TRACKER ç„¡æ•ˆã€‚"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"éŒ¯èª¤ï¼šæ›´æ–° EXECUTION_TRACKER æ™‚ç•°å¸¸ï¼š{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥') if ('PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict)) else 'æœªçŸ¥'
    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon} {_final_status_text}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ï¼š**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜ï¼š**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))
    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦ï¼š**")
    tracked_outputs_display = _tracking_record.get('outputs', {})
    if not tracked_outputs_display and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs_display: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ã€‚", "å·²è·³é": "å·²è·³éã€‚", "æœªå®Œæˆ": "æœªå®Œæˆã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else:
     filtered_outputs_display = {k: v for k, v in tracked_outputs_display.items() if 'åˆ—å' not in k and 'æœ€æ–°æ•¸æ“š' not in k}
     pprint.pprint(filtered_outputs_display, indent=2, width=70, sort_dicts=False)
     for k_disp, v_disp in tracked_outputs_display.items(): # ä½¿ç”¨ä¸åŒè®Šæ•¸åé¿å…è¡çª
         if 'æœ€æ–°æ•¸æ“š' in k_disp: print(f"- {k_disp}:"); pprint.pprint(v_disp, indent=4, width=65)
    print("="*80 + "\n")

    # --- 8. æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_tickers_to_fetch', '_start_date',
        '_interval', '_fetch_success_count', '_fetch_error_count', 'ticker_symbol',
        'df_variable_name', 'ticker_obj', 'history_df', 'warn_msg', 'err_msg', # history_df å·²åœ¨å¾ªç’°ä¸­è³¦å€¼çµ¦å…¨å±€è®Šæ•¸æˆ–None
        'success_note', 'prereq_err', 'e', 'time_err', 'time_err_local',
        'tracker_update_err', '_guideline_version_str', 'info_text',
        '_retry_config', '_wait_seconds', '_stop_attempts', '_fetch_yfinance_with_retry',
        '_is_yfinance_specific_rate_limit_error', '_should_retry_yfinance_error', 'e_retry', 'original_exception',
        '_YFINANCE_ERRORS_MODULE_AVAILABLE', 'e_info', 'attempt_number_str', 'exc', 'err_str_lower',
        'df_val', 'filtered_outputs_display', 'tracked_outputs_display', 'k_disp', 'v_disp', '_final_traceback_str'
    ]
    # å…¨å±€è®Šæ•¸ df_twdusd, df_vix ä¸åœ¨æ­¤è™•æ¸…ç†ï¼Œå®ƒå€‘æ˜¯æ­¤å„²å­˜æ ¼çš„é æœŸè¼¸å‡º
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")

# ==================================================
# é å°¾è¨»è§£ (v3.4.2-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 3: yfinance æ•¸æ“šç²å– (TWD/USD, VIX) (å«é‡è©¦æ©Ÿåˆ¶)
# åŠŸèƒ½: ä½¿ç”¨ yfinance ç²å– TWD/USD å³æœŸåŒ¯ç‡å’Œ VIX æŒ‡æ•¸çš„æ—¥é »æ­·å²æ•¸æ“šï¼Œå¢åŠ å° YFRateLimitError çš„é‡è©¦æ©Ÿåˆ¶ã€‚
# ç‰ˆæœ¬: 3.4.2-zh-fc
# æ—¥æœŸ: 2025-05-07
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:yf', 'global:pd', 'global:tenacity', 'global:requests']
# è¼¸å…¥: ['global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:df_twdusd', 'global:df_vix', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 4: Alpha Vantage æ•¸æ“šç²å– (SPY, HYG, LQD)
# --------------------------------------------------
# åŠŸèƒ½: ä½¿ç”¨ Alpha Vantage API (å…è²» TIME_SERIES_DAILY åŠŸèƒ½) ç²å– SPY, HYG, LQD çš„æ—¥é »æ­·å²åƒ¹æ ¼èˆ‡æˆäº¤é‡æ•¸æ“šã€‚
# ç‰ˆæœ¬: 3.4-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¸­æ–‡è¨»è§£ç‰ˆï¼Œå«é å°¾è¨»è§£) - æ”¹ç”¨å…è²» API
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 2', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:requests', 'global:pd', 'global:tenacity', 'global:colab_userdata']
# è¼¸å…¥: ['Secret:ALPHA_VANTAGE_API_KEY', 'global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:df_spy', 'global:df_hyg', 'global:df_lqd', 'global:EXECUTION_TRACKER (updated)'] # å°‡æ•¸æ“šå­˜ç‚ºå…¨å±€è®Šæ•¸
# --------------------------------------------------
# ==================================================
"""
ä½¿ç”¨ Alpha Vantage API (å…è²» TIME_SERIES_DAILY åŠŸèƒ½) ç²å–è‚¡ç¥¨/ETF å¸‚å ´æ•¸æ“šã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) å’Œå‡½å¼åº« (`requests`, `pd`, `tenacity`, `colab_userdata`) çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  å®‰å…¨åœ°å¾ Colab Secrets è¼‰å…¥ Alpha Vantage API Key (`ALPHA_VANTAGE_API_KEY`)ï¼Œä¸¦å­˜å„²åˆ°å¤§å¯«è®Šæ•¸ `ALPHA_VANTAGE_API_KEY_VALUE` ä¸­ã€‚
3.  å®šç¾©éœ€è¦ç²å–çš„é‡‘èä»£ç¢¼ (tickers)ï¼š'SPY', 'HYG', 'LQD'ã€‚
4.  å®šç¾©ä¸€å€‹å¸¶æœ‰éŒ¯èª¤è™•ç†å’Œé‡è©¦é‚è¼¯çš„å‡½æ•¸ (`fetch_alpha_vantage_data`)ï¼Œç”¨æ–¼ï¼š
    a. æ§‹å»º Alpha Vantage API URL (ä½¿ç”¨ **TIME_SERIES_DAILY** function)ã€‚
    b. ä½¿ç”¨ `requests.get` ç™¼é€ API è«‹æ±‚ï¼ŒåŒ…å« User-Agentã€‚
    c. ä½¿ç”¨ `@tenacity.retry` è£é£¾å™¨è™•ç†ç¶²è·¯é€£ç·šéŒ¯èª¤å’Œå¯èƒ½çš„è¶…æ™‚ã€‚
    d. æª¢æŸ¥ HTTP å›æ‡‰ç‹€æ…‹ç¢¼ã€‚
    e. è§£æ JSON å›æ‡‰ï¼Œä¸¦æª¢æŸ¥ Alpha Vantage è¿”å›çš„éŒ¯èª¤è¨Šæ¯æˆ–è³‡è¨Šè¨Šæ¯ (ä¾‹å¦‚ï¼Œé”åˆ°è«‹æ±‚é™åˆ¶)ã€‚
    f. å¦‚æœæˆåŠŸï¼Œå°‡ JSON æ•¸æ“šè½‰æ›ç‚ºçµæ§‹åŒ–çš„ Pandas DataFrameï¼ŒåŒ…å«æ¨™æº–åŒ–çš„åˆ—å (Date, Open, High, Low, Close, Volume)ã€‚**æ³¨æ„ï¼šä¸åŒ…å«èª¿æ•´å¾Œæ”¶ç›¤åƒ¹ã€‚**
    g. è¿”å›è™•ç†å¾Œçš„ DataFrame æˆ–åœ¨å¤±æ•—æ™‚è¿”å› Noneã€‚
5.  è¿­ä»£è™•ç†æ¯å€‹ tickerï¼Œèª¿ç”¨ `fetch_alpha_vantage_data` å‡½æ•¸ã€‚
6.  å°‡æˆåŠŸç²å–çš„æ•¸æ“šå„²å­˜åˆ°å°æ‡‰çš„å…¨å±€ Pandas DataFrame è®Šæ•¸ä¸­ (`df_spy`, `df_hyg`, `df_lqd`)ã€‚
7.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ï¼ˆä¾‹å¦‚ API Key ç‹€æ…‹ã€ç²å–åˆ°çš„æ•¸æ“šè¡Œæ•¸ï¼‰ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚ **ç‰¹åˆ¥æ³¨æ„ï¼šåœ¨ finally å€å¡Šä¸­æ¸…ç† API Key è®Šæ•¸ã€‚**

è¨­è¨ˆèªªæ˜ï¼š
* **ä¿®æ”¹:** æ”¹ç”¨å…è²»çš„ `TIME_SERIES_DAILY` API åŠŸèƒ½ã€‚
* å°è£ API è«‹æ±‚é‚è¼¯åˆ°ä¸€å€‹å¯é‡ç”¨çš„å‡½æ•¸ä¸­ï¼Œä¸¦æ‡‰ç”¨ `tenacity` é€²è¡Œé‡è©¦ã€‚
* åš´æ ¼éµå®ˆ v3.4 çš„ API Key å‘½åå’Œå®‰å…¨è™•ç†è¦ç¯„ã€‚
* å° Alpha Vantage çš„ JSON å›æ‡‰é€²è¡Œä»”ç´°çš„éŒ¯èª¤æª¢æŸ¥å’Œè§£æã€‚
* å°‡æ•¸æ“šç›´æ¥å­˜å„²ç‚ºå…¨å±€è®Šæ•¸ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´å…¨å±€è®Šæ•¸ã€å‡½å¼åº«å’Œ Colab Secrets)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ DataFrame è®Šæ•¸ `df_spy`, `df_hyg`, `df_lqd`ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸æˆ–å‡½å¼åº«æœªå®šç¾©ã€‚
    userdata.SecretNotFoundError: å¦‚æœåœ¨ Colab Secrets ä¸­æ‰¾ä¸åˆ° `ALPHA_VANTAGE_API_KEY`ã€‚
    ValueError: å¦‚æœ API Key ç‚ºç©ºæˆ– PROJECT_CONFIG é…ç½®ä¸å®Œæ•´ã€‚
    requests.exceptions.RequestException: å¦‚æœç™¼ç”Ÿç¶²è·¯é€£ç·šéŒ¯èª¤ä¸”é‡è©¦å¤±æ•—ã€‚
    KeyError/TypeError: å¦‚æœ API JSON å›æ‡‰çµæ§‹ä¸ç¬¦åˆé æœŸã€‚
    Exception: æ•ç²å…¶ä»–æ„å¤–éŒ¯èª¤ã€‚

å‡è¨­ï¼š
* Cell 1 å’Œ Cell 2 å·²æˆåŠŸåŸ·è¡Œã€‚
* `requests`, `pandas`, `tenacity`, `colab_userdata` å·²æˆåŠŸå°å…¥ã€‚
* åç‚º 'ALPHA_VANTAGE_API_KEY' çš„ Secret å·²åœ¨ Colab ä¸­è¨­å®šä¸”å€¼æœ‰æ•ˆã€‚
* `PROJECT_CONFIG` åŒ…å« 'user_agent' å’Œ 'rate_limit_handler' é…ç½®ã€‚
* Colab ç’°å¢ƒå¯ä»¥è¨ªå• Alpha Vantage APIã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* Alpha Vantage çš„ API è«‹æ±‚é™åˆ¶ï¼ˆå…è²»æ–¹æ¡ˆé€šå¸¸æœ‰é™åˆ¶ï¼‰ã€‚`tenacity` é‡è©¦æœ‰åŠ©æ–¼ç·©è§£ç¬æ™‚å•é¡Œï¼Œä½†ç„¡æ³•è§£æ±ºæŒçºŒçš„é™åˆ¶ã€‚
* API å›æ‡‰çµæ§‹å¯èƒ½è®Šæ›´ã€‚
* æ•¸æ“šè³ªé‡å’Œå»¶é²ã€‚
* **æ³¨æ„ï¼š** ä½¿ç”¨ `TIME_SERIES_DAILY` ç„¡æ³•ç²å–èª¿æ•´å¾Œæ”¶ç›¤åƒ¹ï¼Œå°æ–¼éœ€è¦è€ƒæ…®è‚¡æ¯å’Œæ‹†åˆ†çš„åˆ†æå¯èƒ½ä¸å¤ ç²¾ç¢ºã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 5 (FRED æ•¸æ“šç²å–)ã€‚
* åŸ·è¡Œ Cell 6 æˆ–ä¹‹å¾Œçš„å„²å­˜æ ¼é€²è¡Œæ•¸æ“šæ¸…æ´—èˆ‡æ•´åˆã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # ç¢ºä¿ datetime çµ„ä»¶å¯ç”¨
import json # ç”¨æ–¼è§£æ JSON

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 4: Alpha Vantage æ•¸æ“šç²å– (SPY, HYG, LQD)" # æ¨™è­˜ç¬¦æœ¬èº«å»ºè­° ASCII

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­" # åˆå§‹ç‹€æ…‹
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„è¼¸å…¥åƒæ•¸
_cell_outputs = {} # è¨˜éŒ„é—œéµè¼¸å‡ºä¿¡æ¯/æ‘˜è¦
_cell_generated_files = [] # æ­¤ Cell ä¸ç”Ÿæˆæ–‡ä»¶

# --- 4. API Key è®Šæ•¸ (éµå¾ªå¤§å¯«è¦å‰‡) ---
ALPHA_VANTAGE_API_KEY_VALUE = None # åˆå§‹åŒ–ç‚º None

# --- 5. å…¨å±€ DataFrame è®Šæ•¸åˆå§‹åŒ– ---
df_spy = None
df_hyg = None
df_lqd = None
_tickers_to_fetch = {} # åˆå§‹åŒ–ç‚ºç©ºå­—å…¸

# --- 6. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 6.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")
    print(f"--- {_cell_identifier} (v3.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    # æª¢æŸ¥ä¾†è‡ª Cell 1 çš„åŸºæœ¬å…¨å±€è®Šæ•¸å’Œå‡½å¼åº«
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ PROJECT_CONFIG æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ EXECUTION_TRACKER æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ logger æœªå®šç¾©æˆ–ä¸æ˜¯ Logger å¯¦ä¾‹ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'requests' not in globals() or not hasattr(requests, 'get'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šrequests å‡½å¼åº«æœªæˆåŠŸå°å…¥ã€‚è«‹æª¢æŸ¥ Cell 1ã€‚")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼špandas å‡½å¼åº« (pd) æœªæˆåŠŸå°å…¥ã€‚è«‹æª¢æŸ¥ Cell 1ã€‚")
    if 'tenacity' not in globals() or not hasattr(tenacity, 'retry'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼štenacity å‡½å¼åº«æœªæˆåŠŸå°å…¥ã€‚è«‹æª¢æŸ¥ Cell 1ã€‚")
    try:
        from google.colab import userdata
        _COLAB_USERDATA_AVAILABLE = True
    except ImportError:
        _COLAB_USERDATA_AVAILABLE = False
        userdata = None # è¨­ç½®ç‚º None ä»¥ä¾¿å¾ŒçºŒæª¢æŸ¥
        warn_msg = "è­¦å‘Šï¼šç„¡æ³•å°å…¥ google.colab.userdataã€‚å°‡ç„¡æ³•å¾ Secrets è¼‰å…¥ API Keyã€‚"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(warn_msg)
        # å¦‚æœ API Key æ˜¯å¿…éœ€çš„ï¼Œé€™è£¡æ‡‰è©²å¼•ç™¼éŒ¯èª¤
        # raise EnvironmentError("ç„¡æ³•è¨ªå• Colab Secretsï¼Œç„¡æ³•ç¹¼çºŒç²å– Alpha Vantage æ•¸æ“šã€‚")

    logger.info("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")
    _cell_notes.append("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")

    # --- 6.2. å®‰å…¨è¼‰å…¥ Alpha Vantage API Key ---
    logger.info("æ­¥é©Ÿ 1ï¼šå®‰å…¨è¼‰å…¥ Alpha Vantage API Key...")
    print("æ­¥é©Ÿ 1ï¼šå®‰å…¨è¼‰å…¥ Alpha Vantage API Key...")
    _api_key_name = 'ALPHA_VANTAGE_API_KEY' # Secrets ä¸­çš„åç¨± (ç¬¦åˆè¦ç¯„)
    _cell_inputs['è«‹æ±‚çš„ Secret åç¨±'] = _api_key_name
    _api_key_load_status = "æœªå˜—è©¦ (userdata ä¸å¯ç”¨)"

    if _COLAB_USERDATA_AVAILABLE:
        try:
            ALPHA_VANTAGE_API_KEY_VALUE = userdata.get(_api_key_name)
            if ALPHA_VANTAGE_API_KEY_VALUE:
                load_key_note = f"æˆåŠŸå¾ Colab Secrets è¼‰å…¥ '{_api_key_name}'ã€‚"
                _cell_notes.append(load_key_note)
                logger.info(load_key_note)
                print(f" - {load_key_note}")
                _api_key_load_status = 'æˆåŠŸ'
            else:
                # Key å­˜åœ¨ä½†å€¼ç‚ºç©º
                warn_msg = f"è­¦å‘Šï¼šå¾ Colab Secrets è¼‰å…¥çš„ '{_api_key_name}' å€¼ç‚ºç©ºã€‚Alpha Vantage API å°‡ç„¡æ³•ä½¿ç”¨ã€‚"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f" - {warn_msg}")
                _api_key_load_status = 'æˆåŠŸ (å€¼ç‚ºç©º)'
                # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºç©º Key ç„¡æ³•ä½¿ç”¨
                raise ValueError(f"Alpha Vantage API Key '{_api_key_name}' çš„å€¼ç‚ºç©ºã€‚")
        except userdata.SecretNotFoundError:
            err_msg = f"éŒ¯èª¤ï¼šåœ¨ Colab Secrets ä¸­æœªæ‰¾åˆ°åç‚º '{_api_key_name}' çš„ Secretã€‚è«‹æª¢æŸ¥æ˜¯å¦å·²è¨­å®šã€‚"
            _cell_error = err_msg
            logger.error(err_msg)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = 'å¤±æ•— (æœªæ‰¾åˆ°)'
            # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºæ²’æœ‰ Key ç„¡æ³•ç¹¼çºŒ
            raise userdata.SecretNotFoundError(err_msg)
        except Exception as secret_err:
            err_msg = f"è®€å– Colab Secret '{_api_key_name}' æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤ï¼š{secret_err.__class__.__name__}: {secret_err}"
            _cell_error = err_msg
            logger.error(err_msg, exc_info=True)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = f'å¤±æ•— ({secret_err.__class__.__name__})'
            # å¼•ç™¼éŒ¯èª¤
            raise Exception(err_msg) from secret_err
    else:
        # userdata ä¸å¯ç”¨ï¼Œç„¡æ³•ç²å– Key
        _api_key_load_status = "å¤±æ•— (userdata ä¸å¯ç”¨)"
        # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºæ²’æœ‰ Key ç„¡æ³•ç¹¼çºŒ
        raise EnvironmentError("ç„¡æ³•è¨ªå• Colab Secretsï¼Œç„¡æ³•ç²å– Alpha Vantage API Keyã€‚")

    _cell_outputs['API Key è¼‰å…¥ç‹€æ…‹'] = _api_key_load_status
    logger.info("Alpha Vantage API Key è¼‰å…¥æª¢æŸ¥å®Œæˆã€‚")

    # --- 6.3. å®šç¾©æ•¸æ“šç²å–å‡½æ•¸ (å«é‡è©¦) ---
    logger.info("æ­¥é©Ÿ 2ï¼šå®šç¾© Alpha Vantage æ•¸æ“šç²å–å‡½æ•¸...")

    # å¾é…ç½®ç²å–é‡è©¦åƒæ•¸
    _retry_wait = tenacity.wait_fixed(PROJECT_CONFIG.get('rate_limit_handler', {}).get('wait_fixed_seconds', 2))
    _retry_stop = tenacity.stop_after_attempt(PROJECT_CONFIG.get('rate_limit_handler', {}).get('stop_after_attempt', 5))
    _user_agent = PROJECT_CONFIG.get('user_agent', 'python-requests/unknown')

    # å®šç¾©å“ªäº›ç•°å¸¸è§¸ç™¼é‡è©¦
    @tenacity.retry(
        wait=_retry_wait,
        stop=_retry_stop,
        retry=tenacity.retry_if_exception_type((requests.exceptions.ConnectionError, requests.exceptions.Timeout)),
        before_sleep=tenacity.before_sleep_log(logger, logging.WARNING), # é‡è©¦å‰è¨˜éŒ„æ—¥èªŒ
        reraise=True # å¦‚æœé‡è©¦è€—ç›¡ï¼Œé‡æ–°å¼•ç™¼åŸå§‹ç•°å¸¸
    )
    def fetch_alpha_vantage_data(ticker_symbol: str, api_key: str) -> pd.DataFrame | None:
        """
        å¾ Alpha Vantage API (ä½¿ç”¨å…è²» TIME_SERIES_DAILY åŠŸèƒ½) ç²å–æŒ‡å®š ticker çš„æ—¥é »æ•¸æ“šã€‚

        Args:
            ticker_symbol: è¦ç²å–çš„è‚¡ç¥¨/ETF ä»£ç¢¼ã€‚
            api_key: Alpha Vantage API é‡‘é‘°ã€‚

        Returns:
            åŒ…å«æ­·å²æ•¸æ“šçš„ Pandas DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› Noneã€‚
            DataFrame ç´¢å¼•ç‚ºæ—¥æœŸ (DatetimeIndex)ï¼Œåˆ—åç‚ºæ¨™æº–åŒ–åç¨± (Open, High, Low, Close, Volume)ã€‚
        """
        # **ä¿®æ”¹:** æ”¹ç”¨å…è²»çš„ TIME_SERIES_DAILY åŠŸèƒ½
        function = "TIME_SERIES_DAILY"
        outputsize = "full" # ç²å–å®Œæ•´æ­·å²æ•¸æ“š
        datatype = "json"
        base_url = "https://www.alphavantage.co/query"

        params = {
            "function": function,
            "symbol": ticker_symbol,
            "outputsize": outputsize,
            "datatype": datatype,
            "apikey": api_key
        }
        headers = {'User-Agent': _user_agent}

        logger.debug(f"å‘ Alpha Vantage ç™¼é€è«‹æ±‚ ({function})ï¼š{ticker_symbol}")
        try:
            response = requests.get(base_url, params=params, headers=headers, timeout=30) # è¨­ç½®è¶…æ™‚
            response.raise_for_status() # æª¢æŸ¥ HTTP éŒ¯èª¤ (ä¾‹å¦‚ 4xx, 5xx)

            data = response.json()

            # æª¢æŸ¥ Alpha Vantage è¿”å›çš„ç‰¹å®šéŒ¯èª¤æˆ–ä¿¡æ¯
            if "Error Message" in data:
                error_message = data["Error Message"]
                logger.error(f"Alpha Vantage API éŒ¯èª¤ ({ticker_symbol}): {error_message}")
                return None
            if "Information" in data:
                # è™•ç†é€Ÿç‡é™åˆ¶ä¿¡æ¯
                info_message = data["Information"]
                logger.warning(f"Alpha Vantage API ä¿¡æ¯ ({ticker_symbol}): {info_message}")
                if "call frequency" in info_message.lower():
                     # è¨˜éŒ„è­¦å‘Šä¸¦è¿”å› Noneï¼Œè®“å¤–å±¤å¾ªç’°è™•ç†ã€‚
                    pass
                return None

            # æª¢æŸ¥æ ¸å¿ƒæ•¸æ“šæ˜¯å¦å­˜åœ¨
            if "Time Series (Daily)" not in data:
                logger.error(f"Alpha Vantage API å›æ‡‰ç¼ºå°‘ 'Time Series (Daily)' éµ ({ticker_symbol})ã€‚å›æ‡‰: {str(data)[:500]}...") # è¨˜éŒ„éƒ¨åˆ†å›æ‡‰
                return None

            # è§£ææ™‚é–“åºåˆ—æ•¸æ“š
            time_series = data["Time Series (Daily)"]
            df = pd.DataFrame.from_dict(time_series, orient='index')

            # è½‰æ›ç´¢å¼•ç‚ºæ—¥æœŸæ™‚é–“å°è±¡
            df.index = pd.to_datetime(df.index)

            # **ä¿®æ”¹:** é‡å‘½ååˆ—ä»¥åŒ¹é… TIME_SERIES_DAILY çš„è¼¸å‡º
            df.rename(columns={
                '1. open': 'Open',
                '2. high': 'High',
                '3. low': 'Low',
                '4. close': 'Close',
                '5. volume': 'Volume'
                # ä¸å†æœ‰ adjusted close, dividend, split
            }, inplace=True)

            # è½‰æ›æ•¸æ“šé¡å‹ç‚ºæ•¸å€¼å‹
            numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce') # ç„¡æ³•è½‰æ›çš„è¨­ç‚º NaT

            # æŒ‰æ—¥æœŸå‡åºæ’åº
            df.sort_index(ascending=True, inplace=True)

            # **æ–°å¢:** æª¢æŸ¥æ˜¯å¦åªè¿”å›äº†å°‘é‡æ•¸æ“šé» (å¯èƒ½è¡¨ç¤º API å•é¡Œæˆ– Ticker å•é¡Œ)
            if len(df) < 20: # è¨­ç½®ä¸€å€‹é–¾å€¼ï¼Œä¾‹å¦‚å°‘æ–¼ 20 å€‹æ•¸æ“šé»å°±ç™¼å‡ºè­¦å‘Š
                logger.warning(f"Alpha Vantage ç‚º {ticker_symbol} è¿”å›çš„æ•¸æ“šé»éå°‘ ({len(df)} è¡Œ)ï¼Œè«‹æª¢æŸ¥æ•¸æ“šæ˜¯å¦å®Œæ•´ã€‚")
                _cell_warnings.append(f"è­¦å‘Šï¼š{ticker_symbol} è¿”å›çš„æ•¸æ“šé»éå°‘ ({len(df)} è¡Œ)ã€‚")


            logger.debug(f"æˆåŠŸè§£æ {ticker_symbol} çš„æ•¸æ“šã€‚")
            return df

        except requests.exceptions.HTTPError as http_err:
            logger.error(f"HTTP éŒ¯èª¤ ({ticker_symbol}): {http_err}ã€‚å›æ‡‰: {response.text[:500]}...")
            return None
        except requests.exceptions.RequestException as req_err:
            logger.error(f"è«‹æ±‚éŒ¯èª¤ ({ticker_symbol})ï¼Œé‡è©¦å¾Œå¤±æ•—: {req_err}")
            raise
        except json.JSONDecodeError as json_err:
            logger.error(f"JSON è§£æéŒ¯èª¤ ({ticker_symbol}): {json_err}ã€‚å›æ‡‰: {response.text[:500]}...")
            return None
        except (KeyError, TypeError, ValueError) as parse_err:
            logger.error(f"è§£æ Alpha Vantage å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤ ({ticker_symbol}): {parse_err}", exc_info=True)
            return None
        except Exception as e:
            logger.error(f"ç²å–æˆ–è™•ç† {ticker_symbol} æ•¸æ“šæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            raise

    logger.info("Alpha Vantage æ•¸æ“šç²å–å‡½æ•¸å®šç¾©å®Œæˆã€‚")
    _cell_notes.append("å·²å®šç¾© Alpha Vantage æ•¸æ“šç²å–å‡½æ•¸ (ä½¿ç”¨å…è²» APIï¼Œå«é‡è©¦)ã€‚")

    # --- 6.4. å®šç¾© Tickers ä¸¦è¿­ä»£ç²å–æ•¸æ“š ---
    _tickers_to_fetch = {
        'SPY': 'df_spy',
        'HYG': 'df_hyg',
        'LQD': 'df_lqd'
    }
    _fetch_success_count = 0
    _fetch_error_count = 0

    _cell_inputs['Tickers'] = list(_tickers_to_fetch.keys())
    logger.info(f"æ­¥é©Ÿ 3ï¼šé–‹å§‹ç²å– Alpha Vantage Tickers: {list(_tickers_to_fetch.keys())}...")
    print(f"æ­¥é©Ÿ 3ï¼šé–‹å§‹ç²å– Alpha Vantage Tickers: {list(_tickers_to_fetch.keys())}")

    # æª¢æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆ
    if not ALPHA_VANTAGE_API_KEY_VALUE:
         raise ValueError("Alpha Vantage API Key ç„¡æ•ˆæˆ–æœªè¼‰å…¥ã€‚")

    for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
        logger.info(f"æ­£åœ¨ç²å– {ticker_symbol} çš„æ•¸æ“š...")
        print(f" - æ­£åœ¨ç²å– {ticker_symbol}...")
        try:
            # èª¿ç”¨ç²å–å‡½æ•¸
            fetched_df = fetch_alpha_vantage_data(ticker_symbol, ALPHA_VANTAGE_API_KEY_VALUE)

            if fetched_df is not None and isinstance(fetched_df, pd.DataFrame):
                if fetched_df.empty:
                    warn_msg = f"è­¦å‘Šï¼šç²å– {ticker_symbol} çš„æ•¸æ“šç‚ºç©º DataFrame (å¯èƒ½ API è¿”å›ç©º)ã€‚"
                    _cell_warnings.append(warn_msg)
                    logger.warning(warn_msg)
                    print(f"   - {warn_msg}")
                    _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
                    globals()[df_variable_name] = fetched_df # å­˜å„²ç©º DataFrame
                    _fetch_success_count += 1
                else:
                    # æˆåŠŸç²å–æ•¸æ“š
                    globals()[df_variable_name] = fetched_df
                    success_note = f"æˆåŠŸç²å– {ticker_symbol} çš„æ•¸æ“š ({len(fetched_df):,} è¡Œ)ã€‚å·²å­˜å„²è‡³å…¨å±€è®Šæ•¸ {df_variable_name}ã€‚"
                    _cell_notes.append(success_note)
                    logger.info(success_note)
                    print(f"   - {success_note}")
                    _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ'
                    _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(fetched_df)
                    _cell_outputs[f'{df_variable_name}_åˆ—å'] = fetched_df.columns.tolist()
                    _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = fetched_df.index.min().strftime('%Y-%m-%d')
                    _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = fetched_df.index.max().strftime('%Y-%m-%d')
                    _fetch_success_count += 1
            else:
                # ç²å–å‡½æ•¸è¿”å› Noneï¼Œè¡¨ç¤ºå¤±æ•—
                _fetch_error_count += 1
                err_msg = f"ç²å– {ticker_symbol} æ•¸æ“šå¤±æ•— (è©³è¦‹å…ˆå‰æ—¥èªŒ)ã€‚"
                _cell_warnings.append(err_msg)
                logger.error(err_msg)
                print(f"   - \u274C {err_msg}")
                _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–å¤±æ•—'
                globals()[df_variable_name] = None # ç¢ºä¿è®Šæ•¸ç‚º None

        except Exception as fetch_err:
            # æ•ç² fetch_alpha_vantage_data ä¸­å¯èƒ½é‡æ–°å¼•ç™¼çš„éŒ¯èª¤
            _fetch_error_count += 1
            err_msg = f"è™•ç† {ticker_symbol} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤ï¼š{fetch_err.__class__.__name__}: {fetch_err}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = f'è™•ç†å¤±æ•— ({fetch_err.__class__.__name__})'
            globals()[df_variable_name] = None

    logger.info(f"Alpha Vantage æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")
    _cell_notes.append(f"Alpha Vantage æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")

    # --- æ¨™è¨˜æˆåŠŸ/å¤±æ•— ---
    if _fetch_error_count == len(_tickers_to_fetch):
        _cell_status = "å¤±æ•—"
        if not _cell_error: _cell_error = "æ‰€æœ‰ Alpha Vantage Tickers æ•¸æ“šç²å–å‡å¤±æ•—ã€‚"
        logger.error(_cell_error)
    elif _fetch_success_count == 0 and _fetch_error_count > 0:
         _cell_status = "å¤±æ•—"
         if not _cell_error: _cell_error = "æœªèƒ½æˆåŠŸç²å–ä»»ä½• Alpha Vantage Ticker çš„æ•¸æ“šã€‚"
         logger.error(_cell_error)
    elif _cell_status == "è™•ç†ä¸­":
        _cell_status = "æˆåŠŸ"
        logger.info(f"{_cell_identifier} åŸ·è¡ŒæˆåŠŸï¼ˆå¯èƒ½åŒ…å«éƒ¨åˆ†å¤±æ•—æˆ–è­¦å‘Šï¼‰ã€‚")
        print(f"--- {_cell_identifier} åŸ·è¡ŒæˆåŠŸ ---")
        _cell_notes.append("å„²å­˜æ ¼åŸ·è¡ŒæˆåŠŸã€‚")

# --- 7. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError, EnvironmentError, userdata.SecretNotFoundError) as prereq_err:
    _cell_status = "å¤±æ•—"
    if not _cell_error: _cell_error = f"é…ç½®ã€ç’°å¢ƒæˆ–å…ˆæ±ºæ¢ä»¶éŒ¯èª¤ï¼š{prereq_err.__class__.__name__}ï¼š{prereq_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
except Exception as e: # æ•ç²æ‰€æœ‰å…¶ä»–æ„å¤–éŒ¯èª¤
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—"
        _cell_error = f"æ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}ï¼š{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} å› æ„å¤–éŒ¯èª¤è€Œå¤±æ•—ï¼š{_cell_error}", exc_info=True)
        except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
        print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} ç‚ºéŒ¯èª¤æ•ç²äº†å›é€€ tracebackï¼š{_cell_error}", exc_info=True)
         except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")


finally:
    # --- 8. å¼·åˆ¶æ€§çš„åŸ·è¡Œç¸½çµå ±å‘Šå’Œè¿½è¹¤å™¨æ›´æ–° ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # æ ¹æ“šç‹€æ…‹å’Œè­¦å‘Šç¢ºå®šæœ€çµ‚ç‹€æ…‹åœ–æ¨™å’Œæ–‡æœ¬
    _final_status_text = _cell_status
    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "å·²è·³é": _final_status_icon = "ğŸš«"
    elif _cell_status == "è™•ç†ä¸­": _final_status_icon = "â³"; _final_status_text = "æœªå®Œæˆ"; _cell_notes.append("è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ 'è™•ç†ä¸­' ç‹€æ…‹çµæŸã€‚")
    elif _cell_warnings: _final_status_icon = "âš ï¸"; _final_status_text = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰" if _cell_status == "æˆåŠŸ" else _cell_status
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"
    else: _final_status_icon = "â“"; _cell_notes.append(f"è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ç„¡æ³•è­˜åˆ¥çš„ç‹€æ…‹ '{_cell_status}' çµæŸã€‚")

    # å®‰å…¨åœ°ç²å–ç•¶å‰æ™‚é–“æˆ³
    _current_time_str = "ç„¡æ³•ç²å–"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict): _report_tz_info = PROJECT_CONFIG.get('_tz_info', timezone(timedelta(hours=8)))
        else: _report_tz_info = timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"

    # æ›´æ–°è¼¸å‡ºæ‘˜è¦
    if '_tickers_to_fetch' in locals() and isinstance(_tickers_to_fetch, dict):
        for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df = globals()[df_variable_name]
                  if not df.empty:
                       if f'{df_variable_name}_è¡Œæ•¸' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(df)
                       if f'{df_variable_name}_åˆ—å' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_åˆ—å'] = df.columns.tolist()
                       if f'{df_variable_name}_èµ·å§‹æ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = df.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_çµæŸæ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = df.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_æœ€æ–°æ•¸æ“š ({df.index.max().strftime("%Y-%m-%d")})'] = df.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
             elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–å¤±æ•— (è®Šæ•¸æœªå‰µå»º)'
    else: _cell_notes.append("ç„¡æ³•æ›´æ–°è¼¸å‡ºæ‘˜è¦ï¼Œå› ç‚º _tickers_to_fetch æœªå®šç¾©ã€‚")

    # å»ºæ§‹è¿½è¹¤è¨˜éŒ„
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }

    # å®‰å…¨åœ°æ›´æ–°å…¨å±€è¿½è¹¤å™¨
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"éŒ¯èª¤ï¼šEXECUTION_TRACKER ç„¡æ•ˆã€‚ç„¡æ³•æ›´æ–° {_cell_identifier} çš„è¿½è¹¤è¨˜éŒ„ã€‚"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"éŒ¯èª¤ï¼šæ›´æ–° EXECUTION_TRACKER æ™‚ç•°å¸¸ï¼š{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    # --- æ‰“å°åŸ·è¡Œç¸½çµå ±å‘Š ---
    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon} {_final_status_text}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ï¼š**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜ï¼š**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))
    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦ï¼š**")
    tracked_outputs = _tracking_record.get('outputs')
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else:
        filtered_outputs = {k: v for k, v in tracked_outputs.items() if 'åˆ—å' not in k and 'æœ€æ–°æ•¸æ“š' not in k}; pprint.pprint(filtered_outputs, indent=2, width=70, sort_dicts=False)
        for k, v in tracked_outputs.items():
             if 'æœ€æ–°æ•¸æ“š' in k: print(f"- {k}:"); pprint.pprint(v, indent=4, width=65)
    print("="*80 + "\n")

    # --- 9. æ¸…ç†å±€éƒ¨è®Šæ•¸ (åŒ…æ‹¬ API Keyï¼) ---
    logger.info(f"æ¸…ç† {_cell_identifier} çš„å±€éƒ¨è®Šæ•¸...")
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_api_key_name', '_api_key_load_status',
        '_tickers_to_fetch', '_fetch_success_count', '_fetch_error_count',
        'ticker_symbol', 'df_variable_name', 'fetched_df', 'warn_msg', 'err_msg',
        'success_note', 'load_key_note', 'prereq_err', 'secret_err', 'fetch_err', 'e',
        'time_err', 'time_err_local', 'tracker_update_err', '_guideline_version_str',
        'filtered_outputs', 'info_text', 'df', 'k', 'v', '_COLAB_USERDATA_AVAILABLE',
        '_retry_wait', '_retry_stop', '_user_agent', 'fetch_alpha_vantage_data',
        'function', 'outputsize', 'datatype', 'base_url', 'params', 'headers',
        'response', 'data', 'error_message', 'info_message', 'time_series',
        'numeric_cols', 'col', 'http_err', 'req_err', 'json_err', 'parse_err'
    ]
    # æ¸…ç†å¤§å¯«çš„ API Key è®Šæ•¸ (éå¸¸é‡è¦ï¼)
    _vars_to_clean.append('ALPHA_VANTAGE_API_KEY_VALUE')

    # æ¸…ç†å¯èƒ½å¾å¤–éƒ¨å°å…¥çš„ userdata
    if '_COLAB_USERDATA_AVAILABLE' in locals() and _COLAB_USERDATA_AVAILABLE:
        _vars_to_clean.append('userdata')

    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals(): # ä¹Ÿæª¢æŸ¥å…¨å±€ï¼Œä»¥é˜²è¬ä¸€
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 4: Alpha Vantage æ•¸æ“šç²å– (SPY, HYG, LQD)
# åŠŸèƒ½: ä½¿ç”¨ Alpha Vantage API (å…è²» TIME_SERIES_DAILY åŠŸèƒ½) ç²å– SPY, HYG, LQD çš„æ—¥é »æ­·å²åƒ¹æ ¼èˆ‡æˆäº¤é‡æ•¸æ“šã€‚
# ç‰ˆæœ¬: 3.4-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 2', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:requests', 'global:pd', 'global:tenacity', 'global:colab_userdata']
# è¼¸å…¥: ['Secret:ALPHA_VANTAGE_API_KEY', 'global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:df_spy', 'global:df_hyg', 'global:df_lqd', 'global:EXECUTION_TRACKER (updated)']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 5: FRED æ•¸æ“šç²å– (æ ¸å¿ƒæŒ‡æ¨™)
# --------------------------------------------------
# åŠŸèƒ½: ä½¿ç”¨ fredapi å‡½å¼åº«ç²å– FRED ç¶“æ¿Ÿæ•¸æ“š (FEDFUNDS, INDPRO, SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD)ã€‚
# ç‰ˆæœ¬: 3.4.1-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œæ“´å……ç²å–åºåˆ—)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:pd', 'global:fredapi', 'global:colab_userdata']
# è¼¸å…¥: ['Secret:FRED_API_KEY', 'global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:df_fedfunds', 'global:df_indpro', 'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', 'global:df_wresbal', 'global:df_rrpontsyd', 'global:EXECUTION_TRACKER (updated)'] # å°‡æ•¸æ“šå­˜ç‚ºå…¨å±€è®Šæ•¸
# --------------------------------------------------
# ==================================================
"""
ä½¿ç”¨ fredapi å‡½å¼åº«ç²å–å®è§€ç¶“æ¿Ÿæ•¸æ“šã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) å’Œå‡½å¼åº« (`pd`, `fredapi`, `colab_userdata`) çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  å®‰å…¨åœ°å¾ Colab Secrets è¼‰å…¥ FRED API Key (`FRED_API_KEY`)ï¼Œä¸¦å­˜å„²åˆ°å¤§å¯«è®Šæ•¸ `FRED_API_KEY_VALUE` ä¸­ã€‚
3.  å®šç¾©éœ€è¦ç²å–çš„ FRED Series IDsï¼š'FEDFUNDS', 'INDPRO', 'SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'RRPONTSYD'ã€‚
4.  ä½¿ç”¨ API Key å¯¦ä¾‹åŒ– `Fred` å®¢æˆ¶ç«¯ã€‚
5.  è¿­ä»£è™•ç†æ¯å€‹ Series IDï¼š
    a. ä½¿ç”¨ `fred_client.get_series(series_id)` ç²å–æ•¸æ“šã€‚
    b. åŒ…å«éŒ¯èª¤è™•ç†ï¼Œä»¥æ‡‰å°ç„¡æ•ˆ API Keyã€ç„¡æ•ˆ Series ID æˆ–ç¶²è·¯é€£ç·šå•é¡Œã€‚
    c. å°‡æˆåŠŸç²å–çš„ Pandas Series è½‰æ›ç‚º DataFrameï¼Œä¸¦å„²å­˜åˆ°å°æ‡‰çš„å…¨å±€è®Šæ•¸ä¸­ (ä¾‹å¦‚ `df_fedfunds`, `df_sofr` ç­‰)ã€‚
6.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ï¼ˆä¾‹å¦‚ API Key ç‹€æ…‹ã€ç²å–åˆ°çš„æ•¸æ“šè¡Œæ•¸ï¼‰ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚ **ç‰¹åˆ¥æ³¨æ„ï¼šåœ¨ finally å€å¡Šä¸­æ¸…ç† API Key è®Šæ•¸ã€‚**

è¨­è¨ˆèªªæ˜ï¼š
* ä½¿ç”¨ `fredapi` å‡½å¼åº«ç°¡åŒ– FRED æ•¸æ“šçš„ç²å–ã€‚
* åš´æ ¼éµå®ˆ v3.4 çš„ API Key å‘½åå’Œå®‰å…¨è™•ç†è¦ç¯„ã€‚
* å° `fredapi` å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤é€²è¡Œè™•ç†ã€‚
* å°‡æ•¸æ“šç›´æ¥å­˜å„²ç‚ºå…¨å±€è®Šæ•¸ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨ã€‚
* **æ³¨æ„:** INDPRO æ˜¯å·¥æ¥­ç”Ÿç”¢æŒ‡æ•¸ï¼Œä½œç‚º ISM PMI çš„ä»£ç†ï¼Œå…¶ç¶“æ¿Ÿæ„ç¾©ä¸åŒã€‚
* **æ³¨æ„:** æœªåŒ…å« MOVE æŒ‡æ•¸çš„ç²å–ï¼Œå› å…¶é€šå¸¸ç„¡æ³•é€éå…è²» FRED API å–å¾—ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´å…¨å±€è®Šæ•¸ã€å‡½å¼åº«å’Œ Colab Secrets)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ DataFrame è®Šæ•¸ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸æˆ–å‡½å¼åº«æœªå®šç¾©ã€‚
    userdata.SecretNotFoundError: å¦‚æœåœ¨ Colab Secrets ä¸­æ‰¾ä¸åˆ° `FRED_API_KEY`ã€‚
    ValueError: å¦‚æœ API Key ç„¡æ•ˆï¼Œæˆ– Series ID ç„¡æ•ˆï¼Œæˆ– fredapi å…§éƒ¨ç™¼ç”ŸéŒ¯èª¤ã€‚
    Exception: æ•ç²å…¶ä»–æ„å¤–éŒ¯èª¤ï¼Œä¾‹å¦‚ç¶²è·¯å•é¡Œã€‚

å‡è¨­ï¼š
* Cell 1 å’Œ Cell 2 å·²æˆåŠŸåŸ·è¡Œã€‚
* `pandas` (pd), `fredapi`, `colab_userdata` å·²æˆåŠŸå°å…¥ã€‚
* åç‚º 'FRED_API_KEY' çš„ Secret å·²åœ¨ Colab ä¸­è¨­å®šä¸”å€¼æœ‰æ•ˆã€‚
* Colab ç’°å¢ƒå¯ä»¥è¨ªå• FRED APIã€‚
* æŒ‡å®šçš„ Series IDs åœ¨ FRED ä¸Šæ˜¯æœ‰æ•ˆçš„ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* FRED API çš„è«‹æ±‚é™åˆ¶ã€‚
* Series ID å¯èƒ½æœƒè®Šæ›´æˆ–åœç”¨ã€‚
* æ•¸æ“šç™¼å¸ƒå¯èƒ½å­˜åœ¨å»¶é²ã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 6 (NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“šç²å–èˆ‡è™•ç†)ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # ç¢ºä¿ datetime çµ„ä»¶å¯ç”¨

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 5: FRED æ•¸æ“šç²å– (æ ¸å¿ƒæŒ‡æ¨™)" # æ›´æ–°æ¨™è­˜ç¬¦

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­" # åˆå§‹ç‹€æ…‹
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„è¼¸å…¥åƒæ•¸
_cell_outputs = {} # è¨˜éŒ„é—œéµè¼¸å‡ºä¿¡æ¯/æ‘˜è¦
_cell_generated_files = [] # æ­¤ Cell ä¸ç”Ÿæˆæ–‡ä»¶

# --- 4. API Key è®Šæ•¸ (éµå¾ªå¤§å¯«è¦å‰‡) ---
FRED_API_KEY_VALUE = None # åˆå§‹åŒ–ç‚º None

# --- 5. å…¨å±€ DataFrame è®Šæ•¸åˆå§‹åŒ– (åŒ…å«æ–°å¢çš„åºåˆ—) ---
df_fedfunds = None
df_indpro = None
df_sofr = None
df_dgs10 = None
df_dgs2 = None
df_wresbal = None
df_rrpontsyd = None
_series_to_fetch = {} # åˆå§‹åŒ–ç‚ºç©ºå­—å…¸

# --- 6. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 6.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4.1-zh-fc) é–‹å§‹åŸ·è¡Œ ---") # æ›´æ–°ç‰ˆæœ¬è™Ÿ
    print(f"\n--- {_cell_identifier} (v3.4.1-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    # æª¢æŸ¥ä¾†è‡ª Cell 1 çš„åŸºæœ¬å…¨å±€è®Šæ•¸å’Œå‡½å¼åº«
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ PROJECT_CONFIG æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ EXECUTION_TRACKER æœªå®šç¾©æˆ–ä¸æ˜¯å­—å…¸ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šå…¨å±€è®Šæ•¸ logger æœªå®šç¾©æˆ–ä¸æ˜¯ Logger å¯¦ä¾‹ã€‚è«‹ç¢ºä¿ Cell 1 å·²æˆåŠŸé‹è¡Œã€‚")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼špandas å‡½å¼åº« (pd) æœªæˆåŠŸå°å…¥ã€‚è«‹æª¢æŸ¥ Cell 1ã€‚")
    if 'fredapi' not in globals() or not hasattr(fredapi, 'Fred'):
        raise NameError("åš´é‡éŒ¯èª¤ï¼šfredapi å‡½å¼åº«æœªæˆåŠŸå°å…¥ã€‚è«‹æª¢æŸ¥ Cell 1ã€‚")
    try:
        from google.colab import userdata
        _COLAB_USERDATA_AVAILABLE = True
    except ImportError:
        _COLAB_USERDATA_AVAILABLE = False
        userdata = None # è¨­ç½®ç‚º None ä»¥ä¾¿å¾ŒçºŒæª¢æŸ¥
        warn_msg = "è­¦å‘Šï¼šç„¡æ³•å°å…¥ google.colab.userdataã€‚å°‡ç„¡æ³•å¾ Secrets è¼‰å…¥ API Keyã€‚"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(warn_msg)
        # å¦‚æœ API Key æ˜¯å¿…éœ€çš„ï¼Œé€™è£¡æ‡‰è©²å¼•ç™¼éŒ¯èª¤
        # raise EnvironmentError("ç„¡æ³•è¨ªå• Colab Secretsï¼Œç„¡æ³•ç¹¼çºŒç²å– FRED æ•¸æ“šã€‚")

    logger.info("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")
    _cell_notes.append("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚")

    # --- 6.2. å®‰å…¨è¼‰å…¥ FRED API Key ---
    logger.info("æ­¥é©Ÿ 1ï¼šå®‰å…¨è¼‰å…¥ FRED API Key...")
    print("æ­¥é©Ÿ 1ï¼šå®‰å…¨è¼‰å…¥ FRED API Key...")
    _api_key_name = 'FRED_API_KEY' # Secrets ä¸­çš„åç¨± (ç¬¦åˆè¦ç¯„)
    _cell_inputs['è«‹æ±‚çš„ Secret åç¨±'] = _api_key_name
    _api_key_load_status = "æœªå˜—è©¦ (userdata ä¸å¯ç”¨)"

    if _COLAB_USERDATA_AVAILABLE:
        try:
            FRED_API_KEY_VALUE = userdata.get(_api_key_name)
            if FRED_API_KEY_VALUE:
                load_key_note = f"æˆåŠŸå¾ Colab Secrets è¼‰å…¥ '{_api_key_name}'ã€‚"
                _cell_notes.append(load_key_note)
                logger.info(load_key_note)
                print(f" - {load_key_note}")
                _api_key_load_status = 'æˆåŠŸ'
            else:
                # Key å­˜åœ¨ä½†å€¼ç‚ºç©º
                warn_msg = f"è­¦å‘Šï¼šå¾ Colab Secrets è¼‰å…¥çš„ '{_api_key_name}' å€¼ç‚ºç©ºã€‚FRED API å°‡ç„¡æ³•ä½¿ç”¨ã€‚"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f" - {warn_msg}")
                _api_key_load_status = 'æˆåŠŸ (å€¼ç‚ºç©º)'
                # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºç©º Key ç„¡æ³•ä½¿ç”¨
                raise ValueError(f"FRED API Key '{_api_key_name}' çš„å€¼ç‚ºç©ºã€‚")
        except userdata.SecretNotFoundError:
            err_msg = f"éŒ¯èª¤ï¼šåœ¨ Colab Secrets ä¸­æœªæ‰¾åˆ°åç‚º '{_api_key_name}' çš„ Secretã€‚è«‹æª¢æŸ¥æ˜¯å¦å·²è¨­å®šã€‚"
            _cell_error = err_msg
            logger.error(err_msg)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = 'å¤±æ•— (æœªæ‰¾åˆ°)'
            # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºæ²’æœ‰ Key ç„¡æ³•ç¹¼çºŒ
            raise userdata.SecretNotFoundError(err_msg)
        except Exception as secret_err:
            err_msg = f"è®€å– Colab Secret '{_api_key_name}' æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤ï¼š{secret_err.__class__.__name__}: {secret_err}"
            _cell_error = err_msg
            logger.error(err_msg, exc_info=True)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = f'å¤±æ•— ({secret_err.__class__.__name__})'
            # å¼•ç™¼éŒ¯èª¤
            raise Exception(err_msg) from secret_err
    else:
        # userdata ä¸å¯ç”¨ï¼Œç„¡æ³•ç²å– Key
        _api_key_load_status = "å¤±æ•— (userdata ä¸å¯ç”¨)"
        # å¼•ç™¼éŒ¯èª¤ï¼Œå› ç‚ºæ²’æœ‰ Key ç„¡æ³•ç¹¼çºŒ
        raise EnvironmentError("ç„¡æ³•è¨ªå• Colab Secretsï¼Œç„¡æ³•ç²å– FRED API Keyã€‚")

    _cell_outputs['API Key è¼‰å…¥ç‹€æ…‹'] = _api_key_load_status
    logger.info("FRED API Key è¼‰å…¥æª¢æŸ¥å®Œæˆã€‚")

    # --- 6.3. å¯¦ä¾‹åŒ– Fred å®¢æˆ¶ç«¯ ---
    logger.info("æ­¥é©Ÿ 2ï¼šå¯¦ä¾‹åŒ– Fred å®¢æˆ¶ç«¯...")
    print("æ­¥é©Ÿ 2ï¼šå¯¦ä¾‹åŒ– Fred å®¢æˆ¶ç«¯...")
    fred_client = None # åˆå§‹åŒ–ç‚º None
    try:
        if not FRED_API_KEY_VALUE:
            # é€™å€‹éŒ¯èª¤æ‡‰è©²åœ¨æ­¥é©Ÿ 6.2 è¢«æ•ç²ä¸¦å¼•ç™¼ï¼Œä½†å†æ¬¡æª¢æŸ¥ä»¥é˜²è¬ä¸€
            raise ValueError("FRED API Key ç„¡æ•ˆæˆ–æœªè¼‰å…¥ã€‚")

        fred_client = fredapi.Fred(api_key=FRED_API_KEY_VALUE)
        client_note = "Fred å®¢æˆ¶ç«¯å¯¦ä¾‹åŒ–æˆåŠŸã€‚"
        _cell_notes.append(client_note)
        logger.info(client_note)
        print(f" - {client_note}")
        _cell_outputs['Fred å®¢æˆ¶ç«¯ç‹€æ…‹'] = 'æˆåŠŸ'

    except Exception as client_err:
        err_msg = f"å¯¦ä¾‹åŒ– Fred å®¢æˆ¶ç«¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{client_err.__class__.__name__}: {client_err}"
        _cell_error = err_msg
        logger.error(err_msg, exc_info=True)
        print(f" - \u274C {err_msg}")
        _cell_outputs['Fred å®¢æˆ¶ç«¯ç‹€æ…‹'] = f'å¤±æ•— ({client_err.__class__.__name__})'
        # å¦‚æœå®¢æˆ¶ç«¯å¯¦ä¾‹åŒ–å¤±æ•—ï¼Œå‰‡ç„¡æ³•ç¹¼çºŒ
        raise Exception(err_msg) from client_err

    # --- 6.4. å®šç¾© Series IDs ä¸¦è¿­ä»£ç²å–æ•¸æ“š (åŒ…å«æ–°å¢çš„åºåˆ—) ---
    _series_to_fetch = {
        'FEDFUNDS': 'df_fedfunds',
        'INDPRO': 'df_indpro', # å·¥æ¥­ç”Ÿç”¢æŒ‡æ•¸ (PMI ä»£ç†)
        'SOFR': 'df_sofr',     # æ“”ä¿éš”å¤œèè³‡åˆ©ç‡
        'DGS10': 'df_dgs10',   # 10å¹´æœŸç¾å‚µå›ºå®šæœŸé™åˆ©ç‡
        'DGS2': 'df_dgs2',    # 2å¹´æœŸç¾å‚µå›ºå®šæœŸé™åˆ©ç‡
        'WRESBAL': 'df_wresbal', # è¯æº–æœƒéŠ€è¡Œæº–å‚™é‡‘é¤˜é¡ (é€±é »)
        'RRPONTSYD': 'df_rrpontsyd' # éš”å¤œé€†å›è³¼å”è­°é‡ (æ—¥é »)
        # æ³¨æ„: MOVE æŒ‡æ•¸é€šå¸¸ä¸åœ¨ FRED API ä¸­
    }
    _fetch_success_count = 0
    _fetch_error_count = 0

    _cell_inputs['Series IDs'] = list(_series_to_fetch.keys())
    logger.info(f"æ­¥é©Ÿ 3ï¼šé–‹å§‹ç²å– FRED Series IDs: {list(_series_to_fetch.keys())}...")
    print(f"æ­¥é©Ÿ 3ï¼šé–‹å§‹ç²å– FRED Series IDs: {list(_series_to_fetch.keys())}")

    if not fred_client:
        # å¦‚æœå®¢æˆ¶ç«¯æœªæˆåŠŸå‰µå»ºï¼Œå‰‡ç„¡æ³•ç¹¼çºŒ
        raise RuntimeError("Fred å®¢æˆ¶ç«¯æœªæˆåŠŸå¯¦ä¾‹åŒ–ã€‚")

    for series_id, df_variable_name in _series_to_fetch.items():
        logger.info(f"æ­£åœ¨ç²å– {series_id} çš„æ•¸æ“š...")
        print(f" - æ­£åœ¨ç²å– {series_id}...")
        try:
            # ç²å–æ™‚é–“åºåˆ—æ•¸æ“š (è¿”å› Pandas Series)
            series_data = fred_client.get_series(series_id)

            if series_data.empty:
                warn_msg = f"è­¦å‘Šï¼šç²å– {series_id} çš„æ•¸æ“šç‚ºç©º Seriesã€‚è«‹æª¢æŸ¥ Series IDã€‚"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f"   - {warn_msg}")
                _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
                # å°‡ç©º Series è½‰æ›ç‚º DataFrame å­˜å„²
                globals()[df_variable_name] = series_data.to_frame(name=series_id)
                globals()[df_variable_name].index.name = 'Date' # ç¢ºä¿ç´¢å¼•åç‚º Date
                _fetch_success_count += 1
            else:
                # æˆåŠŸç²å–æ•¸æ“š
                # å°‡ Series è½‰æ›ç‚º DataFrameï¼Œç´¢å¼•å‘½åç‚º 'Date'ï¼Œåˆ—å‘½åç‚º Series ID
                df = series_data.to_frame(name=series_id)
                df.index.name = 'Date' # ç¢ºä¿ç´¢å¼•åç‚º Date
                globals()[df_variable_name] = df

                success_note = f"æˆåŠŸç²å– {series_id} çš„æ•¸æ“š ({len(df):,} è¡Œ)ã€‚å·²å­˜å„²è‡³å…¨å±€è®Šæ•¸ {df_variable_name}ã€‚"
                _cell_notes.append(success_note)
                logger.info(success_note)
                print(f"   - {success_note}")
                _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ'
                _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(df)
                _cell_outputs[f'{df_variable_name}_åˆ—å'] = df.columns.tolist()
                _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = df.index.min().strftime('%Y-%m-%d')
                _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = df.index.max().strftime('%Y-%m-%d')
                _fetch_success_count += 1

        except ValueError as val_err:
             # fredapi åœ¨æ‰¾ä¸åˆ° series æˆ– key ç„¡æ•ˆæ™‚å¯èƒ½å¼•ç™¼ ValueError
            _fetch_error_count += 1
            err_msg = f"ç²å– {series_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ (å¯èƒ½æ˜¯ç„¡æ•ˆ ID æˆ– Key): {val_err}"
            _cell_warnings.append(err_msg) # è¨˜éŒ„ç‚ºè­¦å‘Š
            logger.error(err_msg, exc_info=False)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = f'ç²å–å¤±æ•— (ValueError)'
            globals()[df_variable_name] = None # ç¢ºä¿è®Šæ•¸ç‚º None
        except Exception as e:
            # æ•ç²å…¶ä»–æ½›åœ¨éŒ¯èª¤ (ä¾‹å¦‚ç¶²è·¯å•é¡Œ)
            _fetch_error_count += 1
            err_msg = f"ç²å– {series_id} æ•¸æ“šæ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}: {e}"
            _cell_warnings.append(err_msg) # è¨˜éŒ„ç‚ºè­¦å‘Š
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = f'ç²å–å¤±æ•— ({e.__class__.__name__})'
            globals()[df_variable_name] = None

    logger.info(f"FRED æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")
    _cell_notes.append(f"FRED æ•¸æ“šç²å–å®Œæˆã€‚æˆåŠŸ: {_fetch_success_count}, å¤±æ•—: {_fetch_error_count}ã€‚")

    # --- æ¨™è¨˜æˆåŠŸ/å¤±æ•— ---
    if _fetch_error_count == len(_series_to_fetch):
        # å¦‚æœæ‰€æœ‰ series éƒ½ç²å–å¤±æ•—
        _cell_status = "å¤±æ•—"
        if not _cell_error: _cell_error = "æ‰€æœ‰ FRED Series æ•¸æ“šç²å–å‡å¤±æ•—ã€‚"
        logger.error(_cell_error)
    elif _fetch_success_count == 0 and _fetch_error_count > 0:
         # æ²’æœ‰æˆåŠŸï¼Œä½†è‡³å°‘å˜—è©¦äº†
         _cell_status = "å¤±æ•—"
         if not _cell_error: _cell_error = "æœªèƒ½æˆåŠŸç²å–ä»»ä½• FRED Series çš„æ•¸æ“šã€‚"
         logger.error(_cell_error)
    elif _cell_status == "è™•ç†ä¸­": # ç¢ºä¿ä¸æ˜¯å·²è¢«æ¨™è¨˜ç‚ºå¤±æ•—
        _cell_status = "æˆåŠŸ" # åªè¦è‡³å°‘æœ‰ä¸€å€‹æˆåŠŸ
        logger.info(f"{_cell_identifier} åŸ·è¡ŒæˆåŠŸï¼ˆå¯èƒ½åŒ…å«éƒ¨åˆ†å¤±æ•—æˆ–è­¦å‘Šï¼‰ã€‚")
        print(f"--- {_cell_identifier} åŸ·è¡ŒæˆåŠŸ ---")
        _cell_notes.append("å„²å­˜æ ¼åŸ·è¡ŒæˆåŠŸã€‚")

# --- 7. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError, EnvironmentError, userdata.SecretNotFoundError) as prereq_err:
    _cell_status = "å¤±æ•—"
    # å¦‚æœ _cell_error å·²è¢«è¨­ç½® (ä¾‹å¦‚ Secret æœªæ‰¾åˆ° æˆ– Client å¯¦ä¾‹åŒ–å¤±æ•—)ï¼Œå‰‡ä½¿ç”¨å®ƒ
    if not _cell_error: _cell_error = f"é…ç½®ã€ç’°å¢ƒæˆ–å…ˆæ±ºæ¢ä»¶éŒ¯èª¤ï¼š{prereq_err.__class__.__name__}ï¼š{prereq_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
except Exception as e: # æ•ç²æ‰€æœ‰å…¶ä»–æ„å¤–éŒ¯èª¤
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—"
        _cell_error = f"æ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}ï¼š{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} å› æ„å¤–éŒ¯èª¤è€Œå¤±æ•—ï¼š{_cell_error}", exc_info=True)
        except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
        print(f"\u274C åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} ç‚ºéŒ¯èª¤æ•ç²äº†å›é€€ tracebackï¼š{_cell_error}", exc_info=True)
         except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")


finally:
    # --- 8. å¼·åˆ¶æ€§çš„åŸ·è¡Œç¸½çµå ±å‘Šå’Œè¿½è¹¤å™¨æ›´æ–° ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # æ ¹æ“šç‹€æ…‹å’Œè­¦å‘Šç¢ºå®šæœ€çµ‚ç‹€æ…‹åœ–æ¨™å’Œæ–‡æœ¬
    _final_status_text = _cell_status
    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "å·²è·³é": _final_status_icon = "ğŸš«"
    elif _cell_status == "è™•ç†ä¸­": _final_status_icon = "â³"; _final_status_text = "æœªå®Œæˆ"; _cell_notes.append("è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ 'è™•ç†ä¸­' ç‹€æ…‹çµæŸã€‚")
    elif _cell_warnings: _final_status_icon = "âš ï¸"; _final_status_text = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰" if _cell_status == "æˆåŠŸ" else _cell_status
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"
    else: _final_status_icon = "â“"; _cell_notes.append(f"è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ç„¡æ³•è­˜åˆ¥çš„ç‹€æ…‹ '{_cell_status}' çµæŸã€‚")

    # å®‰å…¨åœ°ç²å–ç•¶å‰æ™‚é–“æˆ³
    _current_time_str = "ç„¡æ³•ç²å–"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict): _report_tz_info = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8))) # ä½¿ç”¨ _tz_info_obj
        else: _report_tz_info = timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—": _cell_warnings.append(f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}")

    # æ›´æ–°è¼¸å‡ºæ‘˜è¦ (åŒ…å«æ–°åºåˆ—çš„ç‹€æ…‹)
    if '_series_to_fetch' in locals() and isinstance(_series_to_fetch, dict):
        for series_id, df_variable_name in _series_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df = globals()[df_variable_name]
                  if not df.empty:
                       if f'{df_variable_name}_è¡Œæ•¸' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_è¡Œæ•¸'] = len(df)
                       if f'{df_variable_name}_åˆ—å' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_åˆ—å'] = df.columns.tolist()
                       if f'{df_variable_name}_èµ·å§‹æ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_èµ·å§‹æ—¥æœŸ'] = df.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_çµæŸæ—¥æœŸ' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_çµæŸæ—¥æœŸ'] = df.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_æœ€æ–°æ•¸æ“š ({df.index.max().strftime("%Y-%m-%d")})'] = df.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–æˆåŠŸ (æ•¸æ“šç‚ºç©º)'
             elif f'{df_variable_name}_ç‹€æ…‹' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_ç‹€æ…‹'] = 'ç²å–å¤±æ•— (è®Šæ•¸æœªå‰µå»º)'
    else: _cell_notes.append("ç„¡æ³•æ›´æ–°è¼¸å‡ºæ‘˜è¦ï¼Œå› ç‚º _series_to_fetch æœªå®šç¾©ã€‚")

    # å»ºæ§‹è¿½è¹¤è¨˜éŒ„
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }

    # å®‰å…¨åœ°æ›´æ–°å…¨å±€è¿½è¹¤å™¨
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"éŒ¯èª¤ï¼šEXECUTION_TRACKER ç„¡æ•ˆã€‚ç„¡æ³•æ›´æ–° {_cell_identifier} çš„è¿½è¹¤è¨˜éŒ„ã€‚"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"éŒ¯èª¤ï¼šæ›´æ–° EXECUTION_TRACKER æ™‚ç•°å¸¸ï¼š{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    # --- æ‰“å°åŸ·è¡Œç¸½çµå ±å‘Š ---
    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon} {_final_status_text}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ï¼š**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜ï¼š**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))
    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦ï¼š**")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else:
        # éæ¿¾æ‰å¯èƒ½éé•·çš„é è¦½ä¿¡æ¯
        filtered_outputs = {k: v for k, v in tracked_outputs.items() if 'åˆ—å' not in k and 'æœ€æ–°æ•¸æ“š' not in k}
        pprint.pprint(filtered_outputs, indent=2, width=70, sort_dicts=False)
        # å–®ç¨æ‰“å°æœ€æ–°æ•¸æ“šé è¦½ï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸éé•·ï¼‰
        # for k, v in tracked_outputs.items():
        #      if 'æœ€æ–°æ•¸æ“š' in k: print(f"- {k}:"); pprint.pprint(v, indent=4, width=65) # å¯é¸
    print("="*80 + "\n")

    # --- 9. æ¸…ç†å±€éƒ¨è®Šæ•¸ (åŒ…æ‹¬ API Keyï¼) ---
    logger.info(f"æ¸…ç† {_cell_identifier} çš„å±€éƒ¨è®Šæ•¸...")
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_api_key_name', '_api_key_load_status',
        '_series_to_fetch', '_fetch_success_count', '_fetch_error_count',
        'series_id', 'df_variable_name', 'series_data', 'df', 'warn_msg', 'err_msg',
        'success_note', 'load_key_note', 'client_note', 'prereq_err', 'secret_err',
        'client_err', 'val_err', 'e', 'time_err', 'time_err_local',
        'tracker_update_err', '_guideline_version_str', 'filtered_outputs',
        'info_text', 'k', 'v', '_COLAB_USERDATA_AVAILABLE', 'fred_client'
    ]
    # æ¸…ç†å¤§å¯«çš„ API Key è®Šæ•¸ (éå¸¸é‡è¦ï¼)
    _vars_to_clean.append('FRED_API_KEY_VALUE')

    # æ¸…ç†å¯èƒ½å¾å¤–éƒ¨å°å…¥çš„ userdata
    if '_COLAB_USERDATA_AVAILABLE' in locals() and _COLAB_USERDATA_AVAILABLE:
        _vars_to_clean.append('userdata')

    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals(): # ä¹Ÿæª¢æŸ¥å…¨å±€ï¼Œä»¥é˜²è¬ä¸€
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4.1-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 5: FRED æ•¸æ“šç²å– (æ ¸å¿ƒæŒ‡æ¨™)
# åŠŸèƒ½: ä½¿ç”¨ fredapi å‡½å¼åº«ç²å– FRED ç¶“æ¿Ÿæ•¸æ“š (FEDFUNDS, INDPRO, SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD)ã€‚
# ç‰ˆæœ¬: 3.4.1-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:pd', 'global:fredapi', 'global:colab_userdata']
# è¼¸å…¥: ['Secret:FRED_API_KEY', 'global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:df_fedfunds', 'global:df_indpro', 'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', 'global:df_wresbal', 'global:df_rrpontsyd', 'global:EXECUTION_TRACKER (updated)']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 6: NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“šç²å–èˆ‡è™•ç† (å·²ä¿®æ­£ KeyError & NameError & TZ)
# --------------------------------------------------
# åŠŸèƒ½: å¾ NY Fed ç¶²ç«™ä¸‹è¼‰å¤šå€‹ Excel æ–‡ä»¶ï¼Œè§£æä¸€ç´šäº¤æ˜“å•†å…¬å‚µæŒæœ‰é‡æ•¸æ“šï¼Œ
#       æ ¹æ“š SBN/SBP è¦å‰‡åŠ ç¸½ï¼Œä¸¦åˆä½µæˆå–®ä¸€æ™‚é–“åºåˆ—ã€‚
# ç‰ˆæœ¬: 3.4.4-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¸­æ–‡è¨»è§£ç‰ˆï¼Œä¿®æ­£ finally TZ è®€å–)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# è¼¸å…¥: ['global:PROJECT_CONFIG'] (è®€å– URLs å’Œ SBP åŠ ç¸½æ¬„ä½)
# è¼¸å‡º: ['global:nyfed_positions_series', 'global:EXECUTION_TRACKER (updated)'] # æŒæœ‰é‡æ•¸æ“š Series
# --------------------------------------------------
# ==================================================
"""
å¾ç´ç´„è¯å„² (NY Fed) ç²å–ä¸¦è™•ç†ä¸€ç´šäº¤æ˜“å•†çš„ç¾åœ‹å…¬å‚µæŒæœ‰é‡æ•¸æ“šã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸ (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) å’Œå‡½å¼åº« (`pd`, `requests`, `io`, `openpyxl`) çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  å¾ `PROJECT_CONFIG` ç²å– NY Fed Excel æ–‡ä»¶çš„ URL åˆ—è¡¨ä»¥åŠ SBP æ–‡ä»¶éœ€è¦åŠ ç¸½çš„æ¬„ä½åˆ—è¡¨ã€‚
3.  åˆå§‹åŒ– `requests.Session` ä»¥ä¾¿è¤‡ç”¨é€£ç·šå’Œè¨­å®š User-Agentã€‚
4.  å¾ªç’°éæ­· URL åˆ—è¡¨ï¼š
    a. **ä¸‹è¼‰æ–‡ä»¶:** ä½¿ç”¨ `session.get` ä¸‹è¼‰ Excel æ–‡ä»¶å…§å®¹è‡³è¨˜æ†¶é«” (`io.BytesIO`)ï¼Œè™•ç†è«‹æ±‚éŒ¯èª¤ã€‚
    b. **è§£æ Excel:** å˜—è©¦ä½¿ç”¨ `pd.read_excel` è®€å–æ•¸æ“šï¼ŒåŒ…å«è‡ªå‹•æª¢æ¸¬è¡¨é ­å’Œæ—¥æœŸåˆ—çš„é‚è¼¯ï¼Œè™•ç†è®€å–å’Œè§£æéŒ¯èª¤ã€‚
    c. **æ•¸æ“šæ¸…ç† (é•·æ ¼å¼):**
        i.  å˜—è©¦å°‡ç´¢å¼•è½‰æ›ç‚º DatetimeIndexï¼Œç„¡æ³•è½‰æ›çš„è¨­ç‚º NaTã€‚
        ii. **ä¿®æ­£:** ç§»é™¤ç´¢å¼•ç‚º NaT çš„è¡Œã€‚
        iii.æ¨™æº–åŒ–æ—¥æœŸç´¢å¼• (ç§»é™¤æ™‚é–“)ã€‚
        iv. æª¢æŸ¥å¿…è¦çš„ 'Time Series' å’Œ 'Value' æ¬„ä½æ˜¯å¦å­˜åœ¨ã€‚
        v.  è½‰æ› Value åˆ—ç‚ºæ•¸å€¼å‹ï¼Œç§»é™¤ Value æˆ– Time Series ç‚º NaN çš„è¡Œã€‚
    d. **è½‰æ›æ ¼å¼ (å¯¬æ ¼å¼):** ä½¿ç”¨ `pd.pivot_table` å°‡æ•¸æ“šå¾é•·æ ¼å¼è½‰ç‚ºå¯¬æ ¼å¼ï¼Œè™•ç†å¯èƒ½çš„é‡è¤‡é …ã€‚
    e. **è­˜åˆ¥åŠ ç¸½æ¬„ä½:** æ ¹æ“š URL ä¸­æ˜¯å¦åŒ…å« 'SBN' æˆ– 'SBP' ä»¥åŠå¹´ä»½ï¼ˆå¾ URL æ¨æ–·ï¼‰ï¼Œç¢ºå®šéœ€è¦åŠ ç¸½çš„æ¬„ä½ã€‚
    f. **åŸ·è¡ŒåŠ ç¸½:** åƒ…åŠ ç¸½ DataFrame ä¸­å¯¦éš›å­˜åœ¨çš„ç›®æ¨™æ¬„ä½ï¼Œç¢ºä¿æ•¸æ“šç‚ºæ•¸å€¼å‹ï¼Œè¨ˆç®—è¡Œç¸½å’Œã€‚
    g. **æ¸…ç†åŠ ç¸½çµæœ:** ç§»é™¤çµæœä¸­çš„ NaN å’Œ 0 å€¼ã€‚
    h. **å„²å­˜å–®æª”çµæœ:** å°‡æœ‰æ•ˆçš„åŠ ç¸½ Series æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
5.  **åˆä½µæ‰€æœ‰çµæœ:** ä½¿ç”¨ `pd.concat` åˆä½µæ‰€æœ‰æˆåŠŸè™•ç†çš„æ–‡ä»¶çš„ Seriesã€‚
6.  **æ’åºèˆ‡å»é‡:** æŒ‰æ—¥æœŸç´¢å¼•å‡åºæ’åºï¼Œä¸¦ä½¿ç”¨ `groupby(level=0).last()` è™•ç†å¯èƒ½é‡ç–Šçš„æ—¥æœŸï¼ˆä¿ç•™æœ€æ–°ä¸‹è¼‰æ–‡ä»¶çš„æ•¸æ“šï¼‰ã€‚
7.  å°‡æœ€çµ‚çš„æŒæœ‰é‡æ™‚é–“åºåˆ—è³¦å€¼çµ¦å…¨å±€è®Šæ•¸ `nyfed_positions_series`ã€‚è‹¥ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œå‰‡è³¦å€¼ä¸€å€‹ç©ºçš„ Seriesã€‚
8.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ï¼ˆä¾‹å¦‚è™•ç†çš„æ–‡ä»¶æ•¸ã€å¤±æ•—çš„æ–‡ä»¶åˆ—è¡¨ã€æœ€çµ‚åºåˆ—çš„ä¿¡æ¯ï¼‰ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚**ä¿®æ­£:** èª¿æ•´äº† finally å€å¡Šä¸­è®€å–æ™‚å€ç‰©ä»¶çš„éµåï¼Œä½¿ç”¨ `_tz_info_obj`ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* å°‡ NY Fed æ•¸æ“šçš„è¤‡é›œç²å–å’Œè™•ç†é‚è¼¯å°è£åœ¨æ­¤å„²å­˜æ ¼ã€‚
* æ¡ç”¨äº†ä¾†è‡ªå…ˆå‰åˆ†æ (ä¸€ç´šäº¤æ˜“pro.py) çš„æˆç†Ÿé‚è¼¯ï¼Œä¸¦æ ¹æ“š v3.4 æº–å‰‡é€²è¡Œäº†èª¿æ•´å’ŒéŒ¯èª¤è™•ç†å¼·åŒ–ã€‚
* **ä¿®æ­£:** ä¿®æ”¹äº†æ¸…ç†é•·æ ¼å¼æ•¸æ“šçš„é‚è¼¯ï¼Œé¿å…å› éŒ¯èª¤ä½¿ç”¨ `dropna(subset=[index.name])` å°è‡´çš„ KeyErrorã€‚ç¾åœ¨ç›´æ¥æª¢æŸ¥ä¸¦ç§»é™¤ç´¢å¼•ä¸­çš„ NaT å€¼ã€‚
* **ä¿®æ­£:** å†æ¬¡ä¿®æ­£äº† finally å€å¡Šä¸­æ‰“å° Traceback å’Œå¤±æ•—æ–‡ä»¶åˆ—è¡¨çš„é‚è¼¯ï¼Œé¿å… NameErrorã€‚
* **ä¿®æ­£:** ä¿®æ­£äº† finally å€å¡Šè®€å–æ™‚å€ç‰©ä»¶æ™‚ä½¿ç”¨çš„éµåï¼Œç¢ºä¿å ±å‘Šæ™‚é–“æˆ³ä½¿ç”¨æ­£ç¢ºæ™‚å€ã€‚
* åŒ…å«äº†å°ä¸‹è¼‰ã€è§£æã€è½‰æ›ã€åŠ ç¸½å„æ­¥é©Ÿçš„è©³ç´°éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„ã€‚
* **é‡è¦è­¦å‘Š:** æ­¤æµç¨‹åˆä½µäº†å®šç¾©å¯èƒ½ä¸åŒçš„ SBN (Gross?) å’Œ SBP (Net?) æ•¸æ“šã€‚åˆä½µå¾Œçš„åºåˆ—ä»£è¡¨ä¸€ç¨®æ··åˆçš„ç¸½é‡æ¦‚å¿µï¼Œåœ¨è§£é‡‹æœ€çµ‚çµæœæ™‚éœ€è¦ç‰¹åˆ¥æ³¨æ„é€™ä¸€é»ï¼Œä¸¦åœ¨å„€è¡¨æ¿æˆ–å ±å‘Šä¸­æ˜ç¢ºèªªæ˜ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´å…¨å±€è®Šæ•¸ `PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger` å’Œå·²è¼‰å…¥çš„å‡½å¼åº«)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ Pandas Series è®Šæ•¸ `nyfed_positions_series`ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    (åŒä¸Šä¸€ç‰ˆæœ¬)

å‡è¨­ï¼š
    (åŒä¸Šä¸€ç‰ˆæœ¬)

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
    (åŒä¸Šä¸€ç‰ˆæœ¬)

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 7 (åˆä½µæ‰€æœ‰æ•¸æ“šæº)ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ï¼Œç¢ºèª `nyfed_positions_series` æ˜¯å¦å·²æˆåŠŸç”Ÿæˆã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
import io
import os
from datetime import datetime, timezone, timedelta # æ·»åŠ  timedelta

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    import requests
    import openpyxl
    print("NY Fed æ•¸æ“šè™•ç†æ‰€éœ€å‡½å¼åº« (pandas, numpy, requests, openpyxl, io) çœ‹ä¼¼å¯ç”¨ã€‚")
    _libs_ok = True
except ImportError as import_err:
    print(f"è­¦å‘Šï¼šå°å…¥ NY Fed æ•¸æ“šè™•ç†æ‰€éœ€å‡½å¼åº«å¤±æ•—({import_err})ã€‚")
    pd = None; np = None; requests = None; openpyxl = None
    _libs_ok = False

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 6: NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“šç²å–èˆ‡è™•ç† (å·²ä¿®æ­£ KeyError & NameError & TZ)" # æ›´æ–°æ¨™è­˜ç¬¦

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. å…¨å±€è®Šæ•¸å®šç¾© (æ­¤ Cell çš„ä¸»è¦è¼¸å‡º) ---
global nyfed_positions_series
nyfed_positions_series = None

# --- 5. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 5.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---") # æ›´æ–°ç‰ˆæœ¬è™Ÿ
    print(f"\n--- {_cell_identifier} (v3.4.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")
    print("*** \u26A0\uFE0F è­¦å‘Šï¼šæ­¤æ­¥é©Ÿå°‡åˆä½µå®šç¾©å¯èƒ½ä¸åŒçš„ SBN(Gross?) å’Œ SBP(Net?) æ•¸æ“šï¼è§£é‡‹éœ€è¬¹æ…ï¼ ***")
    _cell_warnings.append("åˆä½µäº†å®šç¾©å¯èƒ½ä¸åŒçš„ SBN(Gross?) å’Œ SBP(Net?) æ•¸æ“šï¼Œè§£é‡‹éœ€è¬¹æ…ã€‚")

    if not _libs_ok:
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤ï¼šç¼ºå°‘å¿…è¦å‡½å¼åº« (pandas, numpy, requests, openpyxl)ã€‚"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤ï¼šCell 1 çš„ libs_loaded è®Šæ•¸æœªæ‰¾åˆ°ã€‚"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('requests') or not libs_loaded.get('openpyxl'):
         warn_msg = "è­¦å‘Šï¼šæ ¹æ“š Cell 1 è¨˜éŒ„ï¼Œpandas, requests æˆ– openpyxl å¯èƒ½æœªå®Œå…¨åˆå§‹åŒ–ã€‚"
         _cell_warnings.append(warn_msg); logger.warning(warn_msg)

    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æœ‰æ•ˆçš„ PROJECT_CONFIGã€‚"; raise NameError(_cell_error)
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æœ‰æ•ˆçš„ EXECUTION_TRACKERã€‚"; raise NameError(_cell_error)
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        logger = logging.getLogger(__name__)
        if not isinstance(logger, logging.Logger):
             _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤ï¼šç„¡æ³•ç²å–æœ‰æ•ˆçš„ logger å¯¦ä¾‹ã€‚"; raise NameError(_cell_error)
        else:
             logger.warning(f"{_cell_identifier}: Logger åœ¨ Cell 1 å¯èƒ½æœªæ­£ç¢ºè¨­ç½®ï¼Œå·²é‡æ–°ç²å–ã€‚")
             _cell_warnings.append("Logger åœ¨ Cell 1 å¯èƒ½æœªæ­£ç¢ºè¨­ç½®ï¼Œå·²é‡æ–°ç²å–ã€‚")

    ny_fed_urls = PROJECT_CONFIG.get('ny_fed_positions_urls', [])
    sbp2013_cols = PROJECT_CONFIG.get('sbp2013_cols_to_sum', [])
    sbp2001_cols = PROJECT_CONFIG.get('sbp2001_cols_to_sum', [])

    if not ny_fed_urls or not isinstance(ny_fed_urls, list):
        _cell_status = "å¤±æ•—"; _cell_error = "é…ç½®éŒ¯èª¤ï¼šPROJECT_CONFIG ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ 'ny_fed_positions_urls' åˆ—è¡¨ã€‚"; raise ValueError(_cell_error)
    if not sbp2013_cols or not isinstance(sbp2013_cols, list):
        _cell_warnings.append("é…ç½®è­¦å‘Šï¼šPROJECT_CONFIG ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ SBP 2013 æ¬„ä½åŠ ç¸½é…ç½® ('sbp2013_cols_to_sum')ã€‚å°‡ç„¡æ³•è™•ç† SBP 2013 æ–‡ä»¶ã€‚")
        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ sbp2013_cols_to_sum é…ç½®ã€‚"); sbp2013_cols = []
    if not sbp2001_cols or not isinstance(sbp2001_cols, list):
        _cell_warnings.append("é…ç½®è­¦å‘Šï¼šPROJECT_CONFIG ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ SBP 2001 æ¬„ä½åŠ ç¸½é…ç½® ('sbp2001_cols_to_sum')ã€‚å°‡ç„¡æ³•è™•ç† SBP 2001 æ–‡ä»¶ã€‚")
        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ sbp2001_cols_to_sum é…ç½®ã€‚"); sbp2001_cols = []

    _cell_inputs['ny_fed_urls_count'] = len(ny_fed_urls)
    _cell_inputs['sbp2013_cols_config'] = sbp2013_cols
    _cell_inputs['sbp2001_cols_config'] = sbp2001_cols
    _cell_notes.append(f"æº–å‚™è™•ç† {len(ny_fed_urls)} å€‹ NY Fed Excel æ–‡ä»¶ã€‚")
    logger.info("å…ˆæ±ºæ¢ä»¶å’Œé…ç½®æª¢æŸ¥é€šéã€‚")
    print(f"  - æ­¥é©Ÿ 0: ä¾è³´æª¢æŸ¥é€šéã€‚æº–å‚™è™•ç† {len(ny_fed_urls)} å€‹ NY Fed æ–‡ä»¶ã€‚")

    # --- 5.2. å¾ªç’°è™•ç†æ¯å€‹ URL ---
    all_positions_data = []
    positions_fetch_success = False
    processed_files_count = 0
    failed_files = []
    session = requests.Session()
    session.headers.update({'User-Agent': PROJECT_CONFIG.get('user_agent', 'TWD-Risk-Dashboard-Colab/1.0')})

    print("  - æ­¥é©Ÿ 1: é–‹å§‹å¾ªç’°è™•ç† NY Fed æ–‡ä»¶...")
    logger.info("æ­¥é©Ÿ 1: é–‹å§‹å¾ªç’°è™•ç† NY Fed æ–‡ä»¶...")
    for i, url in enumerate(ny_fed_urls):
        try: file_source_name = url.split('/')[-3] if len(url.split('/')) > 2 else f"File_{i+1}"
        except: file_source_name = f"File_{i+1}"

        print(f"\n    è™•ç†æ–‡ä»¶ {i+1}/{len(ny_fed_urls)} ({file_source_name})... URL: {url}")
        logger.info(f"è™•ç†æ–‡ä»¶ {i+1}/{len(ny_fed_urls)}: {url}")
        file_processed_successfully = False

        try:
            # --- 5.2.1. ä¸‹è¼‰ Excel æ–‡ä»¶ ---
            print("      - æ­£åœ¨ä¸‹è¼‰...", end="")
            logger.debug(f"é–‹å§‹ä¸‹è¼‰æ–‡ä»¶ï¼š{url}")
            response_excel = session.get(url, timeout=180)
            response_excel.raise_for_status()
            excel_content = io.BytesIO(response_excel.content)
            print(" å®Œæˆ.")
            logger.info(f"æ–‡ä»¶ {file_source_name}: ä¸‹è¼‰æˆåŠŸã€‚")
            _cell_notes.append(f"æ–‡ä»¶ {file_source_name}: ä¸‹è¼‰æˆåŠŸ ({len(response_excel.content)/1024:.1f} KB)ã€‚")

            # --- 5.2.2. è§£æ Excel (è‡ªå‹•æª¢æ¸¬è¡¨é ­) ---
            print("      - æ­£åœ¨è§£æ (å˜—è©¦è‡ªå‹•æª¢æ¸¬è¡¨é ­)...", end="")
            logger.debug(f"æ–‡ä»¶ {file_source_name}: é–‹å§‹è§£æ Excel...")
            header_row = None; date_col_name = None; data_positions_long = None
            possible_headers = [3, 4, 0, 1, 2, 5, 6]
            parse_error_detail = ""

            for h in possible_headers:
                try:
                    excel_content.seek(0)
                    df_peek = pd.read_excel(excel_content, header=h, nrows=5, engine='openpyxl')
                    cols_lower = [str(c).lower().strip() for c in df_peek.columns]
                    time_series_col = None; value_col = None; date_col_candidate = None
                    for ts_name in ['time series', 'series id', 'series name']:
                        if ts_name in cols_lower: time_series_col = df_peek.columns[cols_lower.index(ts_name)]; break
                    for val_name in ['value (millions)', 'value', 'amount']:
                        if val_name in cols_lower: value_col = df_peek.columns[cols_lower.index(val_name)]; break
                    if 'as of date' in cols_lower: date_col_candidate = df_peek.columns[cols_lower.index('as of date')]
                    elif 'effective date' in cols_lower: date_col_candidate = df_peek.columns[cols_lower.index('effective date')]
                    elif len(df_peek.columns) > 0 and ('date' in cols_lower[0] or 'period' in cols_lower[0]): date_col_candidate = df_peek.columns[0]

                    if time_series_col and value_col and date_col_candidate:
                        header_row = h; date_col_name = date_col_candidate
                        excel_content.seek(0)
                        data_positions_long = pd.read_excel(excel_content, header=header_row, index_col=date_col_name, parse_dates=True, engine='openpyxl')
                        print(f" (æª¢æ¸¬åˆ°æœ‰æ•ˆè¡¨é ­åœ¨ç¬¬ {header_row+1} è¡Œ, æ—¥æœŸåˆ—ç‚ºç´¢å¼•: '{date_col_name}')")
                        logger.info(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸæª¢æ¸¬åˆ°è¡¨é ­è¡Œ {header_row}, æ—¥æœŸåˆ— '{date_col_name}' å·²è¨­ç‚ºç´¢å¼•ã€‚")
                        _cell_notes.append(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸæª¢æ¸¬åˆ°è¡¨é ­è¡Œ {header_row}, æ—¥æœŸåˆ— '{date_col_name}' è¨­ç‚ºç´¢å¼•ã€‚")
                        break
                except Exception as peek_err:
                    parse_error_detail += f"å˜—è©¦ header={h} å¤±æ•—: {peek_err}; "; excel_content.seek(0); continue

            if data_positions_long is None:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: ç„¡æ³•è‡ªå‹•æª¢æ¸¬æœ‰æ•ˆçš„è¡¨é ­è¡Œæˆ–æ—¥æœŸ/æ•¸å€¼åˆ—ã€‚è·³éæ­¤æ–‡ä»¶ã€‚è©³æƒ…: {parse_error_detail}"
                _cell_warnings.append(warn_msg); print(f"\n      - éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (è§£æå¤±æ•—)"); logger.warning(warn_msg); continue

            # --- 5.2.3. æ¸…ç†é•·æ ¼å¼æ•¸æ“š ---
            print("      - æ­£åœ¨æ¸…ç†é•·æ ¼å¼æ•¸æ“š...", end="")
            logger.debug(f"æ–‡ä»¶ {file_source_name}: é–‹å§‹æ¸…ç†é•·æ ¼å¼æ•¸æ“š...")

            # æª¢æŸ¥å’Œæ¸…ç†ç´¢å¼•
            if not isinstance(data_positions_long.index, pd.DatetimeIndex):
                 try:
                     original_index_name = data_positions_long.index.name
                     original_index_values = data_positions_long.index
                     data_positions_long.index = pd.to_datetime(original_index_values, errors='coerce')
                     data_positions_long.index.name = original_index_name
                 except Exception as date_parse_err:
                     warn_msg = f"æ–‡ä»¶ {file_source_name}: ç„¡æ³•å°‡ç´¢å¼•è½‰æ›ç‚ºæ—¥æœŸã€‚è·³éã€‚éŒ¯èª¤: {date_parse_err}"
                     _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (æ—¥æœŸè§£æå¤±æ•—)"); logger.error(warn_msg); continue

            initial_rows_before_nat_drop = len(data_positions_long)
            data_positions_long = data_positions_long[pd.notna(data_positions_long.index)]
            nat_dropped_count = initial_rows_before_nat_drop - len(data_positions_long)
            if nat_dropped_count > 0: logger.debug(f"æ–‡ä»¶ {file_source_name}: ç§»é™¤äº† {nat_dropped_count} è¡Œç„¡æ•ˆæ—¥æœŸ (NaT in index)ã€‚")

            if data_positions_long.empty:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: ç§»é™¤ç„¡æ•ˆæ—¥æœŸå¾Œç„¡æ•¸æ“šã€‚è·³éã€‚"; _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (æ—¥æœŸæ¸…ç†å¾Œç„¡æ•¸æ“š)"); logger.warning(warn_msg); continue

            data_positions_long.index = data_positions_long.index.normalize()

            actual_ts_col = None; actual_val_col = None
            cols_lower_full = [str(c).lower().strip() for c in data_positions_long.columns]
            for ts_name in ['time series', 'series id', 'series name']:
                if ts_name in cols_lower_full: actual_ts_col = data_positions_long.columns[cols_lower_full.index(ts_name)]; break
            for val_name in ['value (millions)', 'value', 'amount']:
                if val_name in cols_lower_full: actual_val_col = data_positions_long.columns[cols_lower_full.index(val_name)]; break

            if not actual_ts_col or not actual_val_col:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: æ¸…ç†å¾Œç¼ºå°‘ '{actual_ts_col or 'Time Series'}' æˆ– '{actual_val_col or 'Value'}' æ¬„ä½ã€‚è·³éã€‚"
                _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (æ¬„ä½ç¼ºå¤±)"); logger.error(warn_msg); continue

            data_positions_long[actual_val_col] = pd.to_numeric(data_positions_long[actual_val_col], errors='coerce')
            initial_rows = len(data_positions_long)
            data_positions_long.dropna(subset=[actual_val_col, actual_ts_col], inplace=True)
            rows_dropped = initial_rows - len(data_positions_long)
            print(f" å®Œæˆ (ç§»é™¤ {rows_dropped} è¡Œç„¡æ•ˆ Value/TS æ•¸æ“š)ã€‚")
            logger.debug(f"æ–‡ä»¶ {file_source_name}: æ¸…ç†å®Œæˆï¼Œç§»é™¤äº† {rows_dropped} è¡Œç„¡æ•ˆ Value/TS æ•¸æ“šã€‚")

            if data_positions_long.empty:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: æ¸…ç† Value/TS å¾Œç„¡æœ‰æ•ˆæ•¸æ“šã€‚è·³éã€‚"; _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (ç„¡æœ‰æ•ˆ Value/TS æ•¸æ“š)"); logger.warning(warn_msg); continue

            # --- 5.2.4. è½‰æ›ç‚ºå¯¬æ ¼å¼ ---
            print("      - æ­£åœ¨è½‰æ›ç‚ºå¯¬æ ¼å¼...", end="")
            logger.debug(f"æ–‡ä»¶ {file_source_name}: é–‹å§‹è½‰æ›ç‚ºå¯¬æ ¼å¼...")
            try:
                data_positions_long.reset_index(inplace=True)
                date_col_actual = data_positions_long.columns[0]

                data_positions_long = data_positions_long.groupby([date_col_actual, actual_ts_col])[actual_val_col].mean().reset_index()
                data_positions_wide = pd.pivot_table(data_positions_long, index=date_col_actual, columns=actual_ts_col, values=actual_val_col, aggfunc='mean')
                print(f" æˆåŠŸ ({len(data_positions_wide)} è¡Œ x {len(data_positions_wide.columns)} æ¬„)ã€‚")
                logger.info(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸè½‰æ›ç‚ºå¯¬æ ¼å¼ ({data_positions_wide.shape})ã€‚")
                _cell_notes.append(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸè½‰æ›ç‚ºå¯¬æ ¼å¼ã€‚")
            except Exception as e_pivot:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: è½‰æ›å¯¬æ ¼å¼å¤±æ•—: {e_pivot}ã€‚è·³éã€‚"; _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤ï¼š{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (Pivotå¤±æ•—)"); logger.error(f"æ–‡ä»¶ {file_source_name} Pivot å¤±æ•—: {e_pivot}", exc_info=True); continue

            # --- 5.2.5. åŠ ç¸½æŒæœ‰é‡ ---
            if not data_positions_wide.empty:
                target_cols = []; source_type = "æœªçŸ¥"; url_lower = url.lower()
                if 'sbn' in url_lower: source_type = "SBN"; target_cols = [c for c in data_positions_wide.columns if isinstance(c, str) and c.startswith('PDPOSGSC-')]
                elif 'sbp2013' in url_lower: source_type = "SBP2013"; target_cols = sbp2013_cols
                elif 'sbp2001' in url_lower: source_type = "SBP2001"; target_cols = sbp2001_cols
                else:
                    warn_msg = f"æ–‡ä»¶ {file_source_name}: ç„¡æ³•å¾ URL è­˜åˆ¥ SBN/SBP é¡å‹ã€‚å˜—è©¦é€šç”¨è¦å‰‡ã€‚"
                    _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); logger.warning(warn_msg)
                    target_cols = [c for c in data_positions_wide.columns if isinstance(c, str) and (c.startswith('PDPOSGSC-') or c.startswith('PDPUSGCS'))]
                    source_type = "æœªçŸ¥ (å˜—è©¦é€šç”¨è¦å‰‡)"

                if not target_cols:
                     warn_msg = f"æ–‡ä»¶ {file_source_name}: æœªæ‰¾åˆ°ç”¨æ–¼åŠ ç¸½çš„ç›®æ¨™æ¬„ä½è¦å‰‡ ({source_type})ã€‚è·³éåŠ ç¸½ã€‚"
                     _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (ç„¡åŠ ç¸½è¦å‰‡)"); logger.warning(warn_msg); continue

                cols_to_sum_actual = [c for c in target_cols if c in data_positions_wide.columns]
                if not cols_to_sum_actual:
                     warn_msg = f"æ–‡ä»¶ {file_source_name}: åœ¨ DataFrame ä¸­æœªæ‰¾åˆ°ä»»ä½•é æœŸçš„ç›®æ¨™æ¬„ä½ ({source_type})ã€‚è·³éåŠ ç¸½ã€‚é æœŸ: {target_cols}"
                     _cell_warnings.append(warn_msg); print(f"      - éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (ç„¡ç›®æ¨™æ¬„ä½)"); logger.error(warn_msg); continue
                if len(cols_to_sum_actual) < len(target_cols):
                     missing_cols = set(target_cols) - set(cols_to_sum_actual)
                     warn_msg = f"æ–‡ä»¶ {file_source_name}: éƒ¨åˆ†ç›®æ¨™æ¬„ä½æœªæ‰¾åˆ°: {missing_cols}ã€‚å°‡åƒ…åŠ ç¸½å­˜åœ¨çš„æ¬„ä½ã€‚"
                     _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); logger.warning(warn_msg)

                print(f"      - æ­£åœ¨åŠ ç¸½ {len(cols_to_sum_actual)} å€‹æ¬„ä½ ({source_type}, å–®ä½: ç™¾è¬ç¾å…ƒ)...", end="")
                logger.debug(f"æ–‡ä»¶ {file_source_name}: æº–å‚™åŠ ç¸½æ¬„ä½: {cols_to_sum_actual}")
                try:
                    for col in cols_to_sum_actual: data_positions_wide[col] = pd.to_numeric(data_positions_wide[col], errors='coerce')
                    daily_total_millions = data_positions_wide[cols_to_sum_actual].sum(axis=1, skipna=True)
                    original_count_before_drop = len(daily_total_millions)
                    daily_total_millions = daily_total_millions.dropna(); daily_total_millions = daily_total_millions[daily_total_millions != 0]
                    dropped_count = original_count_before_drop - len(daily_total_millions)

                    if not daily_total_millions.empty:
                         all_positions_data.append(daily_total_millions); positions_fetch_success = True; file_processed_successfully = True; processed_files_count += 1
                         print(f" å®Œæˆ ({len(daily_total_millions)} ç­†æœ‰æ•ˆæ•¸æ“š, ç§»é™¤ {dropped_count} ç­† NaN/é›¶å€¼).")
                         logger.info(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸåŠ ç¸½ï¼Œç²å¾— {len(daily_total_millions)} ç­†æœ‰æ•ˆæ•¸æ“šã€‚")
                         _cell_notes.append(f"æ–‡ä»¶ {file_source_name}: æˆåŠŸåŠ ç¸½ä¸¦æ¸…ç†ï¼Œç²å¾— {len(daily_total_millions)} ç­†æ•¸æ“šã€‚")
                    else:
                        warn_msg = f"æ–‡ä»¶ {file_source_name}: åŠ ç¸½å¾Œæœªèƒ½è¨ˆç®—å‡ºæœ‰æ•ˆçš„éé›¶æ•¸æ“šã€‚è·³éã€‚"
                        _cell_warnings.append(warn_msg); print(f" è­¦å‘Šï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (åŠ ç¸½å¾Œç„¡æ•¸æ“š)"); logger.warning(warn_msg); continue
                except Exception as e_sum:
                    warn_msg = f"æ–‡ä»¶ {file_source_name}: åŠ ç¸½æ¬„ä½æ™‚å‡ºéŒ¯: {e_sum}ã€‚è·³éã€‚"
                    _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤ï¼š{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (åŠ ç¸½å¤±æ•—)"); logger.error(f"æ–‡ä»¶ {file_source_name} åŠ ç¸½å¤±æ•—: {e_sum}", exc_info=True); continue
            else:
                warn_msg = f"æ–‡ä»¶ {file_source_name}: å¯¬æ ¼å¼æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•é€²è¡ŒåŠ ç¸½ã€‚è·³éã€‚"
                _cell_warnings.append(warn_msg); print(f"      - è­¦å‘Šï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (å¯¬è¡¨ç‚ºç©º)"); logger.warning(warn_msg); continue

        except requests.exceptions.RequestException as e_req:
            warn_msg = f"æ–‡ä»¶ {file_source_name}: ä¸‹è¼‰å¤±æ•—: {e_req.__class__.__name__}: {e_req}ã€‚è·³éã€‚"
            _cell_warnings.append(warn_msg); print(f"\n      - éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (ä¸‹è¼‰å¤±æ•—)"); logger.error(f"æ–‡ä»¶ {file_source_name} ä¸‹è¼‰å¤±æ•—: {e_req}", exc_info=False)
        except (pd.errors.ParserError, ValueError, KeyError, AttributeError, TypeError, IndexError, openpyxl.utils.exceptions.InvalidFileException) as e_parse:
            warn_msg = f"æ–‡ä»¶ {file_source_name}: è§£ææˆ–è™•ç†æ•¸æ“šæ™‚å‡ºéŒ¯: {e_parse.__class__.__name__}: {e_parse}ã€‚è·³éã€‚"
            _cell_warnings.append(warn_msg); print(f"\n      - éŒ¯èª¤ï¼š{warn_msg}"); failed_files.append(f"{file_source_name} (è™•ç†å¤±æ•—)"); logger.error(f"æ–‡ä»¶ {file_source_name} è™•ç†å¤±æ•—: {e_parse}", exc_info=True); _cell_traceback = _cell_traceback or traceback.format_exc()
        except Exception as e_file:
            warn_msg = f"æ–‡ä»¶ {file_source_name}: è™•ç†æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e_file.__class__.__name__}: {e_file}ã€‚è·³éã€‚"
            _cell_warnings.append(warn_msg); print(f"\n      - éŒ¯èª¤ï¼š{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (æœªçŸ¥éŒ¯èª¤)"); logger.error(f"æ–‡ä»¶ {file_source_name} æœªçŸ¥éŒ¯èª¤: {e_file}", exc_info=True)

        if not file_processed_successfully and f"{file_source_name}" not in " ".join(failed_files):
             failed_files.append(f"{file_source_name} (è™•ç†æœªå®Œæˆ)")


    print("\n  - æ­¥é©Ÿ 1: æ–‡ä»¶è™•ç†å¾ªç’°çµæŸã€‚")
    logger.info(f"æ–‡ä»¶è™•ç†å¾ªç’°çµæŸã€‚æˆåŠŸè™•ç† {processed_files_count}/{len(ny_fed_urls)} å€‹æ–‡ä»¶ã€‚å¤±æ•—æ–‡ä»¶åˆ—è¡¨: {failed_files}")

    # --- 5.3. åˆä½µæ‰€æœ‰æ–‡ä»¶çš„æŒæœ‰é‡æ•¸æ“š ---
    print("  - æ­¥é©Ÿ 2: åˆä½µæ‰€æœ‰æˆåŠŸè™•ç†çš„æ–‡ä»¶æ•¸æ“š...")
    logger.info("æ­¥é©Ÿ 2: é–‹å§‹åˆä½µæ‰€æœ‰æˆåŠŸçš„ Series...")
    if all_positions_data:
        try:
            combined_positions = pd.concat(all_positions_data); combined_positions = combined_positions.sort_index()
            final_series = combined_positions.groupby(level=0).last(); final_series.name = 'Total_Gross_Positions_Millions'
            final_series = final_series.dropna(); final_series = final_series[final_series != 0]

            if not final_series.empty:
                nyfed_positions_series = final_series
                _cell_outputs['output_series_shape'] = nyfed_positions_series.shape
                _cell_outputs['output_series_start'] = nyfed_positions_series.index.min().strftime('%Y-%m-%d')
                _cell_outputs['output_series_end'] = nyfed_positions_series.index.max().strftime('%Y-%m-%d')
                _cell_outputs['output_series_valid_points'] = int(nyfed_positions_series.count())
                _cell_outputs['output_series_mean_value'] = round(nyfed_positions_series.mean(), 2)
                _cell_notes.append(f"æˆåŠŸåˆä½µ {processed_files_count} å€‹æ–‡ä»¶çš„æŒæœ‰é‡æ•¸æ“šï¼Œæœ€çµ‚å¾—åˆ° {len(nyfed_positions_series)} ç­†æœ‰æ•ˆæ•¸æ“šã€‚")
                print(f"    > åˆä½µå®Œæˆï¼Œæœ€çµ‚åºåˆ—åŒ…å« {len(nyfed_positions_series)} ç­†æ•¸æ“š (å¾ {nyfed_positions_series.index.min().date()} åˆ° {nyfed_positions_series.index.max().date()})ã€‚")
                logger.info(f"æ•¸æ“šåˆä½µå®Œæˆï¼Œæœ€çµ‚åºåˆ—é•·åº¦: {len(nyfed_positions_series)}")
                positions_fetch_success = True
            else:
                warn_msg = "è­¦å‘Šï¼šåˆä½µæ‰€æœ‰æ–‡ä»¶æ•¸æ“šå¾Œï¼Œæœ€çµ‚åºåˆ—ç‚ºç©ºæˆ–å…¨ç‚ºé›¶å€¼ã€‚"
                _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.warning(warn_msg)
                nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
                _cell_outputs['output_series_valid_points'] = 0
        except Exception as e_concat:
            _cell_status = "å¤±æ•—"; _cell_error = f"åˆä½µæŒæœ‰é‡æ•¸æ“šæ™‚å‡ºéŒ¯: {e_concat.__class__.__name__}: {e_concat}"; _cell_traceback = _cell_traceback or traceback.format_exc(); logger.error(_cell_error, exc_info=True)
            print(f"    > \u274C åˆä½µæ•¸æ“šæ™‚å‡ºéŒ¯: {_cell_error}")
            nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
            _cell_outputs['output_series_valid_points'] = 0
    else:
        warn_msg = "éŒ¯èª¤ï¼šæœªèƒ½æˆåŠŸè™•ç†ä»»ä½• NY Fed æŒæœ‰é‡æ•¸æ“šæ–‡ä»¶ã€‚æœ€çµ‚åºåˆ—ç‚ºç©ºã€‚"
        _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.error(warn_msg)
        nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
        _cell_outputs['output_series_valid_points'] = 0

    _cell_outputs['processed_files_count'] = processed_files_count
    _cell_outputs['failed_files_count'] = len(failed_files)
    _cell_outputs['failed_files_list'] = failed_files
    _cell_outputs['final_series_is_valid'] = positions_fetch_success and nyfed_positions_series is not None and not nyfed_positions_series.empty

    # --- æ¨™è¨˜ Cell 6 åŸ·è¡Œç‹€æ…‹ ---
    if _cell_status == "è™•ç†ä¸­":
        if not positions_fetch_success or nyfed_positions_series is None or nyfed_positions_series.empty:
             _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"; _cell_notes.append("æœ€çµ‚ç‹€æ…‹è­¦å‘Šï¼šæœªèƒ½ç²å–æœ‰æ•ˆçš„ NY Fed æ•¸æ“šã€‚")
             if "æœ€çµ‚æœªèƒ½ç²å–æœ‰æ•ˆçš„ NY Fed æŒæœ‰é‡æ•¸æ“šã€‚" not in _cell_warnings: _cell_warnings.append("æœ€çµ‚æœªèƒ½ç²å–æœ‰æ•ˆçš„ NY Fed æŒæœ‰é‡æ•¸æ“šã€‚")
             logger.warning("æœ€çµ‚æœªèƒ½ç²å–æœ‰æ•ˆçš„ NY Fed æŒæœ‰é‡æ•¸æ“šã€‚")
        elif _cell_warnings: _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
        else: _cell_status = "æˆåŠŸ"

    logger.info(f"{_cell_identifier} - NY Fed æ•¸æ“šè™•ç†å®Œæˆï¼Œæœ€çµ‚ç‹€æ…‹: {_cell_status}")
    print(f"--- {_cell_identifier} åŸ·è¡ŒçµæŸï¼Œç‹€æ…‹: {_cell_status} ---")


# --- 6. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
# (ç•°å¸¸è™•ç†é‚è¼¯ä¸è®Š)
except (NameError, ValueError, ImportError, RuntimeError) as prereq_err:
    _cell_status = "å¤±æ•—"
    if not _cell_error: _cell_error = f"é…ç½®ã€ç’°å¢ƒæˆ–å…ˆæ±ºæ¢ä»¶éŒ¯èª¤ï¼š{prereq_err.__class__.__name__}ï¼š{prereq_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=False)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\n\u274C {_cell_identifier} åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')

except requests.exceptions.RequestException as req_fatal_err:
    _cell_status = "å¤±æ•—"
    if not _cell_error: _cell_error = f"ç¶²çµ¡è«‹æ±‚éŒ¯èª¤ï¼š{req_fatal_err.__class__.__name__}ï¼š{req_fatal_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} å¤±æ•—ï¼š{_cell_error}", exc_info=True)
    except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
    print(f"\n\u274C {_cell_identifier} åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')

except Exception as e:
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "å¤±æ•—"; _cell_error = f"æ„å¤–éŒ¯èª¤ï¼š{e.__class__.__name__}ï¼š{e}"
        if not _cell_traceback: _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} å› æ„å¤–éŒ¯èª¤è€Œå¤±æ•—ï¼š{_cell_error}", exc_info=True)
        except: print(f"è¨˜éŒ„éŒ¯èª¤æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {_cell_error}")
        print(f"\n\u274C {_cell_identifier} åŸ·è¡Œå¤±æ•—ï¼š{_cell_error}")
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')


# --- 7. finally å€å¡Šï¼šåŸ·è¡Œç¸½çµå ±å‘Š (å·²ä¿®æ­£æ™‚å€è®€å–) ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    _final_status_text = _cell_status
    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "å·²è·³é": _final_status_icon = "ğŸš«"
    elif _cell_status == "è™•ç†ä¸­": _final_status_icon = "â³"; _final_status_text = "æœªå®Œæˆ"; _cell_notes.append("è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ 'è™•ç†ä¸­' ç‹€æ…‹çµæŸã€‚")
    elif _cell_warnings: _final_status_icon = "âš ï¸"; _final_status_text = "æˆåŠŸï¼ˆæœ‰è­¦å‘Šï¼‰" if _cell_status == "æˆåŠŸ" else _cell_status
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"
    else: _final_status_icon = "â“"; _cell_notes.append(f"è­¦å‘Šï¼šå„²å­˜æ ¼ä»¥ç„¡æ³•è­˜åˆ¥çš„ç‹€æ…‹ '{_cell_status}' çµæŸã€‚")

    _current_time_str = "ç„¡æ³•ç²å–"
    try:
        _report_tz_info = timezone(timedelta(hours=8)) # é è¨­å›é€€
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             # **ä¿®æ­£:** ä½¿ç”¨æ­£ç¢ºçš„éµå '_tz_info_obj'
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'):
                 _report_tz_info = tz_obj
             else:
                 # åªæœ‰åœ¨ç¢ºå¯¦æ‰¾ä¸åˆ°æœ‰æ•ˆçš„é…ç½®æ™‚æ‰è¨˜éŒ„è­¦å‘Š
                 if PROJECT_CONFIG.get('_tz_source') != 'éŒ¯èª¤æ™‚å›é€€' and PROJECT_CONFIG.get('_tz_source') != 'å›ºå®šåç§»':
                      logger.warning("PROJECT_CONFIG ä¸­çš„ _tz_info_obj ç„¡æ•ˆæˆ–æœªæ‰¾åˆ°ï¼Œå ±å‘Šæ™‚é–“æˆ³å°‡å›é€€åˆ° UTC+8ã€‚")
                      if "æ™‚å€é…ç½®ç„¡æ•ˆï¼Œå ±å‘Šæ™‚é–“å¯èƒ½ä¸æº–ç¢ºã€‚" not in _cell_warnings:
                         _cell_warnings.append("æ™‚å€é…ç½®ç„¡æ•ˆï¼Œå ±å‘Šæ™‚é–“å¯èƒ½ä¸æº–ç¢ºã€‚")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—":
             time_warn_msg = f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}"
             if time_warn_msg not in _cell_warnings: _cell_warnings.append(time_warn_msg)
             logger.warning(time_warn_msg)

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "è­¦å‘Šï¼šEXECUTION_TRACKER æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚å·²å‰µå»ºå›é€€è¿½è¹¤å™¨ã€‚";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    _processed_count = locals().get('processed_files_count', 0)
    _failed_list = locals().get('failed_files', [])
    _failed_count = len(_failed_list) if isinstance(_failed_list, list) else 0
    _final_series_valid = False
    if 'nyfed_positions_series' in globals() and isinstance(nyfed_positions_series, pd.Series) and not nyfed_positions_series.empty:
        _final_series_valid = True; _cell_outputs['output_series_shape'] = nyfed_positions_series.shape
        _cell_outputs['output_series_start'] = nyfed_positions_series.index.min().strftime('%Y-%m-%d')
        _cell_outputs['output_series_end'] = nyfed_positions_series.index.max().strftime('%Y-%m-%d')
        _cell_outputs['output_series_valid_points'] = int(nyfed_positions_series.count())
    else: _cell_outputs['output_series_valid_points'] = 0

    _cell_outputs['processed_files_count'] = _processed_count
    _cell_outputs['failed_files_count'] = _failed_count
    _cell_outputs['failed_files_list'] = _failed_list
    _cell_outputs['final_series_is_valid'] = _final_series_valid

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"æ›´æ–° EXECUTION_TRACKER æ™‚å¤±æ•—: {tracker_update_err}", exc_info=True); print(f"éŒ¯èª¤: æ›´æ–° EXECUTION_TRACKER æ™‚ç™¼ç”Ÿç•°å¸¸: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼ï¼š{_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹ï¼š** {_final_status_icon} {_final_status_text}")
    print(f"** åŸ·è¡Œæ™‚é–“ï¼š** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“ï¼š** {_current_time_str}") # ç¾åœ¨æ‡‰é¡¯ç¤ºæ­£ç¢ºæ™‚å€
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ï¼š**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜ï¼š**"); max_notes_to_show = 15; notes_to_show = _cell_notes[-max_notes_to_show:]; [print(f"- {note}") for note in notes_to_show];
    if len(_cell_notes) > max_notes_to_show: print(f"- ... (é‚„æœ‰ {len(_cell_notes) - max_notes_to_show} æ¢è¨»è¨˜æœªé¡¯ç¤º)")
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯ï¼š**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯ï¼š**\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback éé•·ï¼Œå·²æˆªæ–·)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))

    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦ï¼š**")
    tracked_outputs = _tracking_record.get('outputs');
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else:
        summary_output = {'processed_files_count': tracked_outputs.get('processed_files_count'),'failed_files_count': tracked_outputs.get('failed_files_count'),'final_series_is_valid': tracked_outputs.get('final_series_is_valid'),'output_series_valid_points': tracked_outputs.get('output_series_valid_points'),'output_series_start': tracked_outputs.get('output_series_start'),'output_series_end': tracked_outputs.get('output_series_end'),}
        summary_output_filtered = {k: v for k, v in summary_output.items() if v is not None}; pprint.pprint(summary_output_filtered, indent=2, width=70, sort_dicts=False);
        failed_list = tracked_outputs.get('failed_files_list', [])
        if failed_list:
            print("\n  å¤±æ•—çš„æ–‡ä»¶åˆ—è¡¨:")
            max_failed_to_show = 10
            for idx, failed_item in enumerate(failed_list):
                if idx < max_failed_to_show: print(f"  - {failed_item}")
                elif idx == max_failed_to_show: print(f"  - ... (é‚„æœ‰ {len(failed_list) - max_failed_to_show} å€‹å¤±æ•—æ–‡ä»¶æœªé¡¯ç¤º)"); break
    print("="*80 + "\n")

    # --- 8. æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    # (æ¸…ç†åˆ—è¡¨ä¿æŒä¸è®Š)
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'ny_fed_urls', 'sbp2013_cols', 'sbp2001_cols', 'all_positions_data',
        'positions_fetch_success', 'processed_files_count', 'failed_files', 'session',
        'i', 'url', 'file_source_name', 'file_processed_successfully', 'response_excel', 'excel_content',
        'header_row', 'date_col_name', 'data_positions_long', 'possible_headers', 'h', 'df_peek',
        'cols_lower', 'time_series_col', 'value_col', 'date_col_candidate', 'parse_error_detail',
        'actual_ts_col', 'actual_val_col', 'initial_rows_before_nat_drop', 'nat_dropped_count',
        'initial_rows', 'rows_dropped', 'data_positions_wide', 'date_col_actual', 'e_pivot',
        'target_cols', 'source_type', 'url_lower', 'cols_to_sum_actual', 'missing_cols', 'col',
        'daily_total_millions', 'original_count_before_drop', 'dropped_count', 'e_sum',
        'combined_positions', 'final_series', 'e_concat', 'e_req', 'e_parse', 'e_file',
        'prereq_err', 'req_fatal_err', 'e', 'import_err', 'peek_err', 'date_parse_err',
        'tracker_update_err', 'time_err', 'time_err_local', 'tz_obj', 'tracker_warn_msg',
        'time_warn_msg', 'warn_msg', 'err_msg', 'info_text', '_processed_count', '_failed_list',
        '_failed_count', '_final_series_valid', 'summary_output', 'summary_output_filtered',
        'failed_list', 'idx', 'failed_item', 'max_notes_to_show', 'notes_to_show',
        'max_traceback_lines', 'traceback_lines', 'traceback_to_display', 'max_failed_to_show',
        'original_index_name', 'original_index_values', 'initial_valid_dates', 'final_valid_dates', 'traceback_content'
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4.4-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 6: NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“šç²å–èˆ‡è™•ç† (å·²ä¿®æ­£ KeyError & NameError & TZ)
# åŠŸèƒ½: å¾ NY Fed ç¶²ç«™ä¸‹è¼‰å¤šå€‹ Excel æ–‡ä»¶ï¼Œè§£æä¸€ç´šäº¤æ˜“å•†å…¬å‚µæŒæœ‰é‡æ•¸æ“šï¼Œ
#       æ ¹æ“š SBN/SBP è¦å‰‡åŠ ç¸½ï¼Œä¸¦åˆä½µæˆå–®ä¸€æ™‚é–“åºåˆ—ã€‚
# ç‰ˆæœ¬: 3.4.4-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# è¼¸å…¥: ['global:PROJECT_CONFIG']
# è¼¸å‡º: ['global:nyfed_positions_series', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 7: æ•¸æ“šåˆä½µèˆ‡åˆæ­¥æ¸…æ´— (å·²ä¿®æ­£åˆä½µé‚è¼¯ + æ–°å¢åºåˆ—)
# --------------------------------------------------
# åŠŸèƒ½: å°‡ä¾†è‡ª Cell 3, 4, 5, 6 çš„æ‰€æœ‰æ•¸æ“šæº (DataFrame/Series) åˆä½µåˆ°ä¸€å€‹
#       ä¸» DataFrame ä¸­ã€‚åŸºæ–¼å…±åŒçš„æ—¥æœŸç´¢å¼•é€²è¡Œå°é½Šï¼Œæ˜ç¢ºè™•ç†æ¬„ä½å‘½åè¡çªï¼Œ
#       ä¸¦å°ä½é »æ•¸æ“šé€²è¡Œå‘å‰å¡«å…… (ffill)ã€‚
# ç‰ˆæœ¬: 3.4.4-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¿®æ­£åˆä½µé‚è¼¯ï¼ŒåŠ å…¥æ–° FRED åºåˆ—)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 3', 'Cell 4', 'Cell 5', 'Cell 6']
# è¼¸å…¥: ['global:df_twdusd', 'global:df_vix', 'global:df_spy', 'global:df_hyg',
#        'global:df_lqd', 'global:df_fedfunds', 'global:df_indpro',
#        'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', # æ–°å¢
#        'global:df_wresbal', 'global:df_rrpontsyd',           # æ–°å¢
#        'global:nyfed_positions_series', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# è¼¸å‡º: ['global:merged_data_df'] (åŒ…å«æ‰€æœ‰åˆä½µå’Œåˆæ­¥æ¸…æ´—å¾Œæ•¸æ“šçš„ DataFrame)
#       (æ›´æ–° EXECUTION_TRACKER)
# --------------------------------------------------
# ==================================================
"""
åˆä½µä¾†è‡ªæ‰€æœ‰å…ˆå‰æ•¸æ“šç²å–å„²å­˜æ ¼çš„æ•¸æ“šï¼Œä¸¦é€²è¡Œåˆæ­¥æ¸…æ´—ã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡Œå¿…è¦å…¨å±€è®Šæ•¸å’Œæ•¸æ“šè®Šæ•¸çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ã€‚
2.  é¸æ“‡ `df_spy` ä½œç‚ºåˆä½µçš„åŸºç¤ DataFrameï¼Œä¸¦æº–å‚™å…¶ç´¢å¼•ã€‚
3.  **æº–å‚™å¾…åˆä½µæ•¸æ“šåˆ—è¡¨**:
    a. å‰µå»ºä¸€å€‹ç©ºåˆ—è¡¨ `dfs_to_join`ã€‚
    b. é€ä¸€è™•ç†å…¶ä»–æ•¸æ“šæº (`df_twdusd`, `df_vix`, `df_hyg`, `df_lqd`, `df_fedfunds`, `df_indpro`, `df_sofr`, `df_dgs10`, `df_dgs2`, `df_wresbal`, `df_rrpontsyd`, `nyfed_positions_series`)ã€‚
    c. å°æ¯å€‹æ•¸æ“šæº:
        i.  æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä¸”éç©ºã€‚
        ii. ç¢ºä¿ç´¢å¼•ç‚º DatetimeIndex ä¸”ç„¡æ™‚å€ã€‚
        iii.**æ˜ç¢ºé‡å‘½åè¡çªæ¬„ä½**: å°æ–¼ `df_twdusd`, `df_vix`, `df_hyg`, `df_lqd`ï¼Œå°‡ 'Open', 'High', 'Low', 'Close', 'Volume' ç­‰æ¬„ä½é‡å‘½å (ä¾‹å¦‚ï¼Œæ·»åŠ  'TWDUSD_', 'VIX_' å‰ç¶´)ã€‚åªä¿ç•™éœ€è¦çš„æ¬„ä½ (ä¾‹å¦‚ï¼Œ'Close' å’Œ 'Volume')ã€‚
        iv. å°‡è™•ç†å¾Œçš„ DataFrame (æˆ–è½‰æ›å¾Œçš„ Series) æ·»åŠ åˆ° `dfs_to_join` åˆ—è¡¨ã€‚
4.  **åŸ·è¡Œåˆä½µ**: ä½¿ç”¨ `base_df.join(dfs_to_join, how='left')` å°‡åˆ—è¡¨ä¸­çš„æ‰€æœ‰ DataFrame åˆä½µåˆ°åŸºç¤ DataFrameã€‚
5.  **åˆæ­¥æ¸…æ´—èˆ‡å¡«å……**:
    a. å°æ–¼ä¾†è‡ª FRED çš„æœˆ/é€±/æ—¥é »æ•¸æ“š (`FEDFUNDS`, `INDPRO`, `SOFR`, `DGS10`, `DGS2`, `WRESBAL`, `RRPONTSYD`) å’Œ NY Fed çš„é€±é »æ•¸æ“š (`Total_Gross_Positions_Millions`)ï¼Œä½¿ç”¨å¸¶ `limit` çš„å‘å‰å¡«å…… (`ffill`)ã€‚ **(å·²æ›´æ–° ffill_config)**
6.  **æœ€çµ‚ DataFrame**: å°‡åˆä½µä¸¦åˆæ­¥æ¸…æ´—å¾Œçš„ DataFrame è³¦å€¼çµ¦å…¨å±€è®Šæ•¸ `merged_data_df`ã€‚
7.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘ŠåŸ·è¡Œç‹€æ…‹ã€æ‘˜è¦ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* **ä¿®æ­£:** æ”¾æ£„äº†ä¾è³´ `suffixes` å’Œå¾ŒçºŒåˆªé™¤ `_dup` åˆ—çš„ç­–ç•¥ï¼Œæ”¹ç‚ºåœ¨åˆä½µå‰å°å·²çŸ¥è¡çªçš„æ•¸æ“šæºé€²è¡Œæ˜ç¢ºçš„æ¬„ä½é‡å‘½åï¼Œä¸¦ä½¿ç”¨ `.join()` é€²è¡Œåˆä½µï¼Œæ›´ç‚ºç©©å¥å¯é ã€‚
* **æ–°å¢:** å°‡ Cell 5 æ–°ç²å–çš„ FRED åºåˆ—åŠ å…¥åˆä½µæµç¨‹ã€‚
* **æ›´æ–°:** æ“´å±•äº† `ffill_config` ä»¥åŒ…å«æ–°çš„ FRED åºåˆ—ï¼Œä¸¦æ ¹æ“šå…¶é »ç‡è¨­å®šäº†å¡«å……é™åˆ¶ã€‚
* ä¿ç•™äº†å°ä½é »æ•¸æ“šä½¿ç”¨å¸¶ `limit` çš„ `ffill`ã€‚
* ç¢ºä¿è¼¸å‡º DataFrame çµæ§‹å®Œæ•´ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´ä¾†è‡ªå…ˆå‰å„²å­˜æ ¼çš„å…¨å±€è®Šæ•¸)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ DataFrame è®Šæ•¸ `merged_data_df`ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸æˆ–æ•¸æ“šè®Šæ•¸æœªå®šç¾©ã€‚
    ValueError/TypeError: å¦‚æœè¼¸å…¥æ•¸æ“šæ ¼å¼ä¸ç¬¦ã€‚
    KeyError: å¦‚æœ PROJECT_CONFIG ç¼ºå°‘å¿…è¦çš„éµã€‚
    Exception: æ•ç²å…¶ä»–æœªé æœŸçš„åˆä½µæˆ–æ¸…æ´—éŒ¯èª¤ã€‚

å‡è¨­ï¼š
* Cell 1, 3, 4, 5 (å·²ä¿®æ­£), 6 å·²æˆåŠŸåŸ·è¡Œã€‚
* `pandas` å’Œ `numpy` å‡½å¼åº«å·²æˆåŠŸè¼‰å…¥ã€‚
* æ‰€æœ‰è¼¸å…¥çš„ DataFrame/Series å‡å­˜åœ¨ä¸”åŒ…å«æ•¸æ“šï¼ˆæˆ–å·²è¢«æ­£ç¢ºè™•ç†ç‚º Noneï¼‰ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
    * `ffill` çš„åˆç†æ€§èˆ‡ `limit` è¨­ç½®ä»éœ€æ ¹æ“šæ•¸æ“šç‰¹æ€§ä»”ç´°è€ƒæ…®ã€‚
    * éœ€è¦æ˜ç¢ºæ±ºå®šå¾ TWD/USD, VIX, HYG, LQD ä¸­ä¿ç•™å“ªäº›æ¬„ä½ã€‚ç›®å‰ä¿ç•™é‡å‘½åå¾Œçš„ 'Close' å’Œ 'Volume'ã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 8 (è¨ˆç®—è¡ç”ŸæŒ‡æ¨™èˆ‡å£“åŠ›æŒ‡æ•¸)ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ï¼Œç¢ºèª `merged_data_df` çš„å…§å®¹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    print("æ•¸æ“šåˆä½µæ‰€éœ€å‡½å¼åº« (pandas, numpy) çœ‹ä¼¼å¯ç”¨ã€‚")
    _libs_ok = True
except ImportError as import_err:
    print(f"è­¦å‘Šï¼šå°å…¥æ•¸æ“šåˆä½µæ‰€éœ€å‡½å¼åº«å¤±æ•—({import_err})ã€‚")
    pd = None; np = None
    _libs_ok = False

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 7: æ•¸æ“šåˆä½µèˆ‡åˆæ­¥æ¸…æ´— (å·²ä¿®æ­£åˆä½µé‚è¼¯ + æ–°å¢åºåˆ—)" # æ›´æ–°æ¨™è­˜ç¬¦

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. å…¨å±€è®Šæ•¸å®šç¾© (æ­¤ Cell çš„ä¸»è¦è¼¸å‡º) ---
global merged_data_df
merged_data_df = None

# --- 5. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 5.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---") # æ›´æ–°ç‰ˆæœ¬è™Ÿ
    print(f"\n--- {_cell_identifier} (v3.4.4-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    if not _libs_ok:
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: ç¼ºå°‘å¿…è¦å‡½å¼åº« (pandas, numpy)ã€‚"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: Cell 1 çš„ libs_loaded è®Šæ•¸æœªæ‰¾åˆ°ã€‚"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('numpy'):
         _cell_status = "å¤±æ•—"; _cell_error = f"ä¾è³´éŒ¯èª¤: Cell 1 æœªèƒ½æˆåŠŸè¼‰å…¥ pandas æˆ– numpyã€‚"; raise ImportError(_cell_error)

    # æ“´å±•æª¢æŸ¥åˆ—è¡¨ä»¥åŒ…å«æ–°çš„ FRED åºåˆ—
    required_data_vars = [
        'df_twdusd', 'df_vix', 'df_spy', 'df_hyg', 'df_lqd',
        'df_fedfunds', 'df_indpro',
        'df_sofr', 'df_dgs10', 'df_dgs2', 'df_wresbal', 'df_rrpontsyd', # æ–°å¢
        'nyfed_positions_series'
    ]
    missing_vars = [var for var in required_data_vars if var not in globals() or globals()[var] is None]
    if missing_vars:
        # å¦‚æœæœ‰ç¼ºå¤±è®Šæ•¸ï¼Œè¨˜éŒ„è­¦å‘Šè€Œä¸æ˜¯ç›´æ¥å¤±æ•—ï¼Œå› ç‚ºéƒ¨åˆ†ç¼ºå¤±å¯èƒ½ä»å¯åˆä½µ
        warn_msg = f"è­¦å‘Š: ç¼ºå°‘ä¾†è‡ªå…ˆå‰å„²å­˜æ ¼çš„éƒ¨åˆ†æ•¸æ“šè®Šæ•¸: {', '.join(missing_vars)}ã€‚åˆä½µçµæœå¯èƒ½ä¸å®Œæ•´ã€‚"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(f"*** {warn_msg} ***")
        # ç§»é™¤ç¼ºå¤±è®Šæ•¸ï¼Œç¹¼çºŒè™•ç†å­˜åœ¨çš„è®Šæ•¸
        required_data_vars = [var for var in required_data_vars if var not in missing_vars]


    # åŸºç¤ DataFrame æª¢æŸ¥
    if 'df_spy' not in globals() or not isinstance(df_spy, pd.DataFrame) or df_spy.empty:
         _cell_status = "å¤±æ•—"; _cell_error = "è¼¸å…¥éŒ¯èª¤: åŸºç¤ DataFrame (df_spy) ç„¡æ•ˆæˆ–ç‚ºç©ºã€‚"; raise ValueError(_cell_error)
    if not isinstance(df_spy.index, pd.DatetimeIndex):
        try:
            df_spy.index = pd.to_datetime(df_spy.index); _cell_notes.append("å·²å°‡ df_spy çš„ç´¢å¼•è½‰æ›ç‚º DatetimeIndexã€‚")
            if not isinstance(df_spy.index, pd.DatetimeIndex): raise TypeError("è½‰æ›å¾Œä»é DatetimeIndex")
        except Exception as e_spy_index:
             _cell_status = "å¤±æ•—"; _cell_error = f"è¼¸å…¥éŒ¯èª¤: ç„¡æ³•å°‡ df_spy çš„ç´¢å¼•è½‰æ›ç‚º DatetimeIndex: {e_spy_index}"; raise TypeError(_cell_error) from e_spy_index

    # è¨˜éŒ„æ‰€æœ‰å˜—è©¦è™•ç†çš„æ•¸æ“šæºçš„å½¢ç‹€
    for var_name in required_data_vars:
        if var_name in globals(): # å†æ¬¡æª¢æŸ¥ï¼Œå› ç‚ºå¯èƒ½å·²è¢«ç§»é™¤
            data_obj = globals()[var_name];
            if isinstance(data_obj, (pd.DataFrame, pd.Series)): _cell_inputs[f'{var_name}_shape'] = data_obj.shape
            else: _cell_inputs[f'{var_name}_type'] = str(type(data_obj))

    logger.info("å…ˆæ±ºæ¢ä»¶æª¢æŸ¥é€šéã€‚æ‰€æœ‰å¿…éœ€çš„è¼¸å…¥æ•¸æ“šè®Šæ•¸å­˜åœ¨ï¼ˆæˆ–å·²è¨˜éŒ„è­¦å‘Šï¼‰ã€‚")
    print(f"  - æ­¥é©Ÿ 0: ä¾è³´æª¢æŸ¥é€šéã€‚")

    # --- 5.2. æº–å‚™åŸºç¤ DataFrame å’Œå¾…åˆä½µæ•¸æ“šåˆ—è¡¨ ---
    print("  - æ­¥é©Ÿ 1: æº–å‚™åˆä½µåŸºç¤å’Œæ•¸æ“šåˆ—è¡¨...")
    logger.info("æ­¥é©Ÿ 1: æº–å‚™åˆä½µåŸºç¤å’Œæ•¸æ“šåˆ—è¡¨...")
    base_df = df_spy.copy()
    if base_df.index.tz is not None:
        base_df.index = base_df.index.tz_localize(None)
        _cell_notes.append("å·²ç§»é™¤åŸºç¤ DataFrame (df_spy) ç´¢å¼•çš„æ™‚å€ä¿¡æ¯ã€‚")
    # åƒ…ä¿ç•™ SPY çš„åŸºç¤åƒ¹æ ¼å’Œæˆäº¤é‡
    base_df = base_df[['Open', 'High', 'Low', 'Close', 'Volume']]
    _cell_notes.append("åŸºç¤ DataFrame (df_spy) å·²æº–å‚™å°±ç·’ (ä¿ç•™ OHLCV)ã€‚")


    dfs_to_join = [] # å„²å­˜æº–å‚™å¥½åˆä½µçš„ DataFrame
    # æ›´æ–°å­—å…¸ä»¥åŒ…å«æ–°çš„ FRED åºåˆ—
    data_sources_to_process = {
        'twdusd': df_twdusd if 'df_twdusd' in globals() else None,
        'vix': df_vix if 'df_vix' in globals() else None,
        'hyg': df_hyg if 'df_hyg' in globals() else None,
        'lqd': df_lqd if 'df_lqd' in globals() else None,
        'fedfunds': df_fedfunds if 'df_fedfunds' in globals() else None,
        'indpro': df_indpro if 'df_indpro' in globals() else None,
        'sofr': df_sofr if 'df_sofr' in globals() else None,           # æ–°å¢
        'dgs10': df_dgs10 if 'df_dgs10' in globals() else None,         # æ–°å¢
        'dgs2': df_dgs2 if 'df_dgs2' in globals() else None,           # æ–°å¢
        'wresbal': df_wresbal if 'df_wresbal' in globals() else None,     # æ–°å¢
        'rrpontsyd': df_rrpontsyd if 'df_rrpontsyd' in globals() else None, # æ–°å¢
        'nyfed_pos': nyfed_positions_series if 'nyfed_positions_series' in globals() else None
    }
    # ä¿ç•™éœ€è¦çš„æ¬„ä½åŠå…¶æ–°åç¨±
    rename_mapping = {
        # 'Open': 'Open', # æ±ºå®šæ˜¯å¦ä¿ç•™ Open ç­‰
        # 'High': 'High',
        # 'Low': 'Low',
        'Close': 'Close',
        'Volume': 'Volume'
    }

    print("  - æ­¥é©Ÿ 2: è™•ç†ä¸¦æº–å‚™å„æ•¸æ“šæº...")
    logger.info("æ­¥é©Ÿ 2: è™•ç†ä¸¦æº–å‚™å„æ•¸æ“šæº...")
    for name, data_obj in data_sources_to_process.items():
        print(f"    - æ­£åœ¨è™•ç†: {name}...", end="")
        if data_obj is None or data_obj.empty:
            print(" è·³é (æ•¸æ“šç‚ºç©ºæˆ–ç¼ºå¤±)")
            # ä¸éœ€è¦è¨˜éŒ„è­¦å‘Šï¼Œå› ç‚ºå·²åœ¨æ­¥é©Ÿ 5.1 è¨˜éŒ„
            # _cell_warnings.append(f"æ•¸æ“šæº '{name}' ç‚ºç©ºæˆ– Noneï¼Œè·³éè™•ç†ã€‚");
            logger.info(f"æ•¸æ“šæº '{name}' ç‚ºç©ºæˆ–ç¼ºå¤±ï¼Œè·³éè™•ç†ã€‚"); continue

        try:
            # è¤‡è£½ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
            current_data = data_obj.copy()

            # ç¢ºä¿ç´¢å¼•æ˜¯ DatetimeIndex ä¸”ç„¡æ™‚å€
            if not isinstance(current_data.index, pd.DatetimeIndex):
                current_data.index = pd.to_datetime(current_data.index, errors='coerce')
            if current_data.index.tz is not None:
                 current_data.index = current_data.index.tz_localize(None)
            # ç§»é™¤ç„¡æ•ˆç´¢å¼•
            current_data = current_data[pd.notna(current_data.index)]
            if current_data.empty:
                 print(" è·³é (ç´¢å¼•è™•ç†å¾Œç‚ºç©º)")
                 _cell_warnings.append(f"æ•¸æ“šæº '{name}' ç´¢å¼•è™•ç†å¾Œç‚ºç©ºï¼Œè·³éã€‚"); continue

            # å¦‚æœæ˜¯ Seriesï¼Œè½‰æ›ç‚º DataFrame ä¸¦å‘½å
            if isinstance(current_data, pd.Series):
                # ç‚º Series ç¢ºå®šåˆ—å
                series_col_name = name.upper() # é»˜èªä½¿ç”¨å¤§å¯«åç¨±
                if name == 'nyfed_pos':
                    series_col_name = 'Total_Gross_Positions_Millions'
                elif name == 'fedfunds':
                    series_col_name = 'FEDFUNDS'
                elif name == 'indpro':
                    series_col_name = 'INDPRO'
                elif name == 'sofr':
                    series_col_name = 'SOFR'
                elif name == 'dgs10':
                    series_col_name = 'DGS10'
                elif name == 'dgs2':
                    series_col_name = 'DGS2'
                elif name == 'wresbal':
                    series_col_name = 'WRESBAL' # ä½¿ç”¨ WRESBAL ä½œç‚ºåˆ—å
                elif name == 'rrpontsyd':
                    series_col_name = 'RRPONTSYD' # ä½¿ç”¨ RRPONTSYD ä½œç‚ºåˆ—å

                current_data = current_data.to_frame(name=series_col_name)
                _cell_notes.append(f"å·²å°‡ Series '{name}' è½‰æ›ç‚º DataFrameï¼Œåˆ—åç‚º '{series_col_name}'ã€‚")


            # å°éœ€è¦é‡å‘½åçš„æ•¸æ“šæºé€²è¡Œè™•ç† (TWDUSD, VIX, HYG, LQD)
            if name in ['twdusd', 'vix', 'hyg', 'lqd']:
                prefix = name.upper() + '_' # ä¾‹å¦‚ TWDUSD_, VIX_
                # æ ¹æ“š rename_mapping é¸æ“‡ä¸¦é‡å‘½ååˆ—
                cols_to_select = [col for col in rename_mapping.keys() if col in current_data.columns]
                if cols_to_select:
                    current_data = current_data[cols_to_select] # å…ˆé¸æ“‡éœ€è¦çš„åˆ—
                    cols_rename_dict = {col: prefix + rename_mapping[col] for col in cols_to_select}
                    current_data = current_data.rename(columns=cols_rename_dict)
                    _cell_notes.append(f"å·²é¸æ“‡ä¸¦é‡å‘½å '{name}' çš„æ¬„ä½ (å‰ç¶´: {prefix})ã€‚ä¿ç•™: {current_data.columns.tolist()}")
                else:
                    print(f" è·³éé‡å‘½å (æœªæ‰¾åˆ° '{name}' ä¸­çš„ç›®æ¨™æ¬„ä½: {list(rename_mapping.keys())})")
                    _cell_warnings.append(f"æ•¸æ“šæº '{name}' æœªæ‰¾åˆ°é æœŸçš„æ¬„ä½é€²è¡Œé‡å‘½åã€‚")
                    continue # å¦‚æœé€£éœ€è¦çš„åˆ—éƒ½æ²’æœ‰ï¼Œè·³é

            # å°æ–¼ FRED æ•¸æ“šå’Œ NY Fed æ•¸æ“šï¼Œå®ƒå€‘çš„åˆ—åæ‡‰è©²å·²ç¶“æ˜¯å”¯ä¸€çš„äº†
            # ç„¡éœ€é¡å¤–è™•ç†åˆ—é¸æ“‡æˆ–é‡å‘½åï¼Œå› ç‚ºä¸Šä¸€æ­¥å·²å°‡ Series è½‰æ›ç‚ºå–®åˆ— DataFrame

            # å°‡è™•ç†å¥½çš„ DataFrame æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            if not current_data.empty:
                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨é‡è¤‡çš„åˆ—åï¼ˆä¸æ‡‰ç™¼ç”Ÿï¼Œä½†ä½œç‚ºå®‰å…¨æª¢æŸ¥ï¼‰
                if any(col in base_df.columns for col in current_data.columns):
                     warn_msg = f"æ•¸æ“šæº '{name}' è™•ç†å¾Œä»èˆ‡åŸºç¤ DataFrame å­˜åœ¨åˆ—åè¡çª: {current_data.columns.tolist()}ã€‚è·³éæ­¤æ•¸æ“šæºã€‚"
                     _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤: {warn_msg}"); continue
                if any(existing_df.columns.isin(current_data.columns).any() for existing_df in dfs_to_join):
                     conflicting_cols = [col for col in current_data.columns if any(col in existing_df.columns for existing_df in dfs_to_join)]
                     warn_msg = f"æ•¸æ“šæº '{name}' è™•ç†å¾Œèˆ‡å·²æº–å‚™å¥½çš„å…¶ä»–æ•¸æ“šæºå­˜åœ¨åˆ—åè¡çª: {conflicting_cols}ã€‚è·³éæ­¤æ•¸æ“šæºã€‚"
                     _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤: {warn_msg}"); continue

                dfs_to_join.append(current_data)
                print(" å®Œæˆæº–å‚™.")
                _cell_notes.append(f"å·²æº–å‚™å¥½åˆä½µæ•¸æ“šæº: {name} (æ¬„ä½: {current_data.columns.tolist()})")
            else:
                 print(" è·³é (è™•ç†å¾Œæ•¸æ“šç‚ºç©º)")
                 _cell_warnings.append(f"æ•¸æ“šæº '{name}' è™•ç†å¾Œç‚ºç©ºï¼Œè·³éã€‚")


        except Exception as e_prepare:
            warn_msg = f"è™•ç†æ•¸æ“šæº '{name}' æ™‚å‡ºéŒ¯: {e_prepare}ã€‚å·²è·³éæ­¤æ•¸æ“šæºã€‚"
            _cell_warnings.append(warn_msg); print(f" éŒ¯èª¤: {warn_msg}")
            logger.warning(f"è™•ç†æ•¸æ“šæº '{name}' å¤±æ•—", exc_info=True); _cell_traceback = _cell_traceback or traceback.format_exc()

    # --- 5.3. åŸ·è¡Œåˆä½µ ---
    print(f"  - æ­¥é©Ÿ 3: åŸ·è¡Œåˆä½µ (å°‡ {len(dfs_to_join)} å€‹æ•¸æ“šæºåˆä½µåˆ°åŸºç¤)...")
    logger.info(f"æ­¥é©Ÿ 3: åŸ·è¡Œåˆä½µ...")
    try:
        if dfs_to_join: # åªæœ‰ç•¶æœ‰æ•¸æ“šéœ€è¦åˆä½µæ™‚æ‰åŸ·è¡Œ join
            # ä½¿ç”¨ left joinï¼Œä»¥ base_df (ä¾†è‡ª SPY) çš„ç´¢å¼•ç‚ºä¸»
            merged_df_temp = base_df.join(dfs_to_join, how='left')
            join_note = f"å·²æˆåŠŸå°‡ {len(dfs_to_join)} å€‹æ•¸æ“šæºåˆä½µåˆ°åŸºç¤ DataFrameã€‚"
            _cell_notes.append(join_note); print(f"    > {join_note}")
            logger.info(join_note)
        else:
            merged_df_temp = base_df # å¦‚æœæ²’æœ‰å…¶ä»–æ•¸æ“šæºï¼Œçµæœå°±æ˜¯åŸºç¤ DataFrame
            _cell_notes.append("æ²’æœ‰é¡å¤–çš„æ•¸æ“šæºæˆåŠŸæº–å‚™å¥½é€²è¡Œåˆä½µã€‚")
            print("    > æ²’æœ‰é¡å¤–çš„æ•¸æ“šæºæˆåŠŸæº–å‚™å¥½é€²è¡Œåˆä½µã€‚")
            _cell_warnings.append("è­¦å‘Šï¼šæ²’æœ‰é¡å¤–çš„æ•¸æ“šæºè¢«åˆä½µã€‚")

    except Exception as e_join:
         _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œ DataFrame join æ“ä½œæ™‚å‡ºéŒ¯: {e_join}"; _cell_traceback = _cell_traceback or traceback.format_exc()
         logger.error(f"DataFrame join å¤±æ•—: {e_join}", exc_info=True)
         raise Exception(_cell_error) from e_join # åˆä½µæ˜¯é—œéµæ­¥é©Ÿï¼Œå¤±æ•—å‰‡çµ‚æ­¢

    # --- 5.4. åˆæ­¥æ¸…æ´—èˆ‡å¡«å…… (Forward Fill) ---
    print("  - æ­¥é©Ÿ 4: å°ä½é »æ•¸æ“šåŸ·è¡Œå‘å‰å¡«å…… (ffill)...")
    logger.info("æ­¥é©Ÿ 4: å°ä½é »æ•¸æ“šåŸ·è¡Œå‘å‰å¡«å……...")

    # æ›´æ–° ffill_config ä»¥åŒ…å«æ–°çš„ FRED åºåˆ—åŠå…¶é »ç‡å°æ‡‰çš„é™åˆ¶
    # å‡è¨­ï¼šFEDFUNDS/INDPRO æœˆé »ï¼ŒWRESBAL é€±é »ï¼Œå…¶ä»–æ—¥é »
    ffill_config = {
        'FEDFUNDS': 35,  # æœˆé »ï¼Œå¡«å……ç´„ä¸€å€‹æœˆå¤šä¸€é»
        'INDPRO': 35,    # æœˆé »
        'SOFR': 3,       # æ—¥é »ï¼Œå¡«å……é€±æœ«/å‡æ—¥
        'DGS10': 3,      # æ—¥é »
        'DGS2': 3,       # æ—¥é »
        'WRESBAL': 10,   # é€±é »ï¼Œå¡«å……ç´„ä¸€é€±å¤šä¸€é»
        'RRPONTSYD': 3,  # æ—¥é »
        'Total_Gross_Positions_Millions': 10 # é€±é »
    }
    _cell_inputs['ffill_config'] = ffill_config

    for col, limit_days in ffill_config.items():
        if col in merged_df_temp.columns:
            initial_nulls = merged_df_temp[col].isnull().sum()
            if initial_nulls > 0 and initial_nulls < len(merged_df_temp):
                # ç¢ºä¿æ•¸æ“šæ˜¯æ•¸å€¼å‹ï¼Œå¦å‰‡ ffill å¯èƒ½è¡Œç‚ºç•°å¸¸æˆ–å ±éŒ¯
                if pd.api.types.is_numeric_dtype(merged_df_temp[col]):
                    merged_df_temp[col] = merged_df_temp[col].ffill(limit=limit_days)
                    filled_count = initial_nulls - merged_df_temp[col].isnull().sum()
                    if filled_count > 0:
                         fill_note = f"å·²å°æ¬„ä½ '{col}' å‘å‰å¡«å…… (æœ€å¤š {limit_days} å¤©)ï¼Œå¡«å……äº† {filled_count} å€‹ NaNã€‚"
                         _cell_notes.append(fill_note); print(f"    - {fill_note}"); logger.info(fill_note)
                    else: _cell_notes.append(f"æ¬„ä½ '{col}' ç„¡éœ€å‘å‰å¡«å……æˆ–å¡«å……ç„¡æ•ˆã€‚"); print(f"    - æ¬„ä½ '{col}' ç„¡éœ€å‘å‰å¡«å……æˆ–å¡«å……ç„¡æ•ˆã€‚")
                else:
                     warn_msg = f"æ¬„ä½ '{col}' éæ•¸å€¼é¡å‹ï¼Œè·³éå‘å‰å¡«å……ã€‚"
                     _cell_warnings.append(warn_msg); print(f"    - è­¦å‘Š: {warn_msg}"); logger.warning(warn_msg)
            elif initial_nulls == len(merged_df_temp): _cell_notes.append(f"æ¬„ä½ '{col}' å…¨éƒ¨ç‚º NaNï¼Œè·³éå¡«å……ã€‚"); print(f"    - æ¬„ä½ '{col}' å…¨éƒ¨ç‚º NaNï¼Œè·³éå¡«å……ã€‚")
            else: _cell_notes.append(f"æ¬„ä½ '{col}' ç„¡ç¼ºå¤±å€¼ï¼Œç„¡éœ€å¡«å……ã€‚"); print(f"    - æ¬„ä½ '{col}' ç„¡ç¼ºå¤±å€¼ï¼Œç„¡éœ€å¡«å……ã€‚")
        else: _cell_notes.append(f"æ¬„ä½ '{col}' ä¸åœ¨åˆä½µå¾Œçš„ DataFrame ä¸­ï¼Œè·³éå¡«å……ã€‚"); print(f"    - æ¬„ä½ '{col}' ä¸å­˜åœ¨ï¼Œè·³éå¡«å……ã€‚")

    # --- 5.5. è¨­å®šæœ€çµ‚è¼¸å‡º ---
    print("  - æ­¥é©Ÿ 5: å®Œæˆåˆä½µèˆ‡åˆæ­¥æ¸…æ´—...")
    logger.info("æ­¥é©Ÿ 5: å®Œæˆåˆä½µèˆ‡åˆæ­¥æ¸…æ´—...")
    if merged_df_temp.empty:
        warn_msg = "è­¦å‘Šï¼šæœ€çµ‚åˆä½µå¾Œçš„ DataFrame ç‚ºç©ºï¼"; _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.warning(warn_msg)
        merged_data_df = pd.DataFrame()
    else:
        merged_data_df = merged_df_temp
        _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
        _cell_outputs['merged_dataframe_columns'] = merged_data_df.columns.tolist()
        _cell_outputs['merged_dataframe_valid_points'] = int(merged_data_df.count().sum())
        _cell_outputs['merged_start_date'] = merged_data_df.index.min().strftime('%Y-%m-%d')
        _cell_outputs['merged_end_date'] = merged_data_df.index.max().strftime('%Y-%m-%d')
        _cell_outputs['merged_dataframe_nan_counts'] = merged_data_df.isnull().sum().to_dict()
        logger.info(f"æ•¸æ“šåˆä½µèˆ‡æ¸…æ´—å®Œæˆï¼Œæœ€çµ‚ DataFrame ç¶­åº¦: {merged_data_df.shape}")
        print(f"    > åˆä½µèˆ‡æ¸…æ´—å®Œæˆï¼Œæœ€çµ‚ DataFrame ç¶­åº¦: {merged_data_df.shape}")
        # æ‰“å°æœ€çµ‚æ¬„ä½åˆ—è¡¨ä»¥ä¾›ç¢ºèª
        print(f"    > æœ€çµ‚æ¬„ä½åˆ—è¡¨: {merged_data_df.columns.tolist()}")


    # --- æ¨™è¨˜ Cell 7 åŸ·è¡Œç‹€æ…‹ ---
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "æˆåŠŸ";
        if _cell_warnings: _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
    logger.info(f"{_cell_identifier} - æ•¸æ“šåˆä½µå®Œæˆï¼Œç‹€æ…‹: {_cell_status}")

# --- 6. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError, TypeError, KeyError) as e:
    if _cell_status != "å¤±æ•—": _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•—ã€‚")
except Exception as e:
    if _cell_status != "å¤±æ•—":
        _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        logger.critical(f"{_cell_identifier} å¤±æ•—: {_cell_error}", exc_info=True)
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•— (æœªé æœŸéŒ¯èª¤)ã€‚")

# --- 7. finally å€å¡Šï¼šåŸ·è¡Œç¸½çµå ±å‘Š ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "â“"

    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "è·³é": _final_status_icon = "ğŸš«"
    elif "æœ‰è­¦å‘Š" in _cell_status: _final_status_icon = "âš ï¸"
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG ä¸­çš„ _tz_info_obj ç„¡æ•ˆæˆ–æœªæ‰¾åˆ°ï¼Œå ±å‘Šæ™‚é–“æˆ³å°‡å›é€€åˆ° UTC+8ã€‚")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—": _cell_warnings.append(f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "è­¦å‘Šï¼šEXECUTION_TRACKER æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚å·²å‰µå»ºå›é€€è¿½è¹¤å™¨ã€‚";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    # æ›´æ–°è¼¸å‡ºæ‘˜è¦
    if 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame) and not merged_data_df.empty:
         _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
         _cell_outputs['merged_dataframe_columns_count'] = len(merged_data_df.columns)
         _cell_outputs['merged_start_date'] = merged_data_df.index.min().strftime('%Y-%m-%d')
         _cell_outputs['merged_end_date'] = merged_data_df.index.max().strftime('%Y-%m-%d')
         _cell_outputs['merged_dataframe_valid_points'] = int(merged_data_df.count().sum())
    elif 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame):
         _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
         _cell_outputs['merged_dataframe_columns_count'] = 0
         _cell_outputs['merged_dataframe_valid_points'] = 0

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"æ›´æ–° EXECUTION_TRACKER æ™‚å¤±æ•—: {tracker_update_err}", exc_info=True); print(f"éŒ¯èª¤: æ›´æ–° EXECUTION_TRACKER æ™‚ç™¼ç”Ÿç•°å¸¸: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼: {_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹: ** {_final_status_icon} {_cell_status}")
    print(f"** åŸ·è¡Œæ™‚é–“: ** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“: ** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸ (æ•¸æ“šæºå½¢ç‹€/é…ç½®): **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜: **"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯: **\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback éé•·ï¼Œå·²æˆªæ–·)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))

    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦: **")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    tracked_outputs.pop('merged_dataframe_nan_counts', None) # ç§»é™¤å¯èƒ½éé•·çš„ NaN è¨ˆæ•¸
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- 8. æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'required_data_vars', 'missing_vars', 'var_name', 'data_obj', 'base_df',
        'dfs_to_join', 'name', 'current_data', 'prefix', 'cols_to_select', 'cols_rename_dict', # æ›´æ–°æ¸…ç†åˆ—è¡¨
        'series_col_name', 'conflicting_cols', # æ›´æ–°æ¸…ç†åˆ—è¡¨
        'merged_df_temp', 'ffill_config', 'col', 'limit_days', 'initial_nulls', 'filled_count', 'fill_note',
        'e_spy_index', 'e_prepare', 'e_join', 'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local',
        'tz_obj', 'tracker_warn_msg', 'time_warn_msg', 'warn_msg', 'err_msg', 'info_text',
        'tracked_outputs', 'traceback_content', 'max_traceback_lines', 'traceback_lines', 'traceback_to_display',
        'rename_mapping' # æ·»åŠ æ¸…ç†
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4.4-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 7: æ•¸æ“šåˆä½µèˆ‡åˆæ­¥æ¸…æ´— (å·²ä¿®æ­£åˆä½µé‚è¼¯ + æ–°å¢åºåˆ—)
# åŠŸèƒ½: å°‡ä¾†è‡ª Cell 3, 4, 5, 6 çš„æ‰€æœ‰æ•¸æ“šæºåˆä½µåˆ°ä¸€å€‹ä¸» DataFrame ä¸­ï¼Œ
#       æ˜ç¢ºè™•ç†æ¬„ä½å‘½åè¡çªï¼Œä¸¦å°ä½é »æ•¸æ“šé€²è¡Œå‘å‰å¡«å……ã€‚
# ç‰ˆæœ¬: 3.4.4-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 3', 'Cell 4', 'Cell 5', 'Cell 6']
# è¼¸å…¥: ['global:df_twdusd', ..., 'global:df_rrpontsyd', ..., 'global:nyfed_positions_series', ...]
# è¼¸å‡º: ['global:merged_data_df']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 8: è¨ˆç®—è¡ç”ŸæŒ‡æ¨™èˆ‡å£“åŠ›æŒ‡æ•¸ (å·²ä¿®æ­£æ¬„ä½ä¾è³´)
# --------------------------------------------------
# åŠŸèƒ½: åŸºæ–¼åˆä½µå¾Œçš„æ•¸æ“š DataFrame (`merged_data_df`)ï¼Œè¨ˆç®—è¡ç”ŸæŒ‡æ¨™
#       (åˆ©å·®, SOFRåå·®, æŒæœ‰/æº–å‚™é‡‘æ¯”ç‡)ï¼Œè¨ˆç®—å„æˆåˆ†çš„æ»¾å‹•ç™¾åˆ†ä½æ’åï¼Œ
#       æ ¹æ“šé…ç½®æ¬Šé‡è¨ˆç®—åŸå§‹åŠå¹³æ»‘å£“åŠ›æŒ‡æ•¸ï¼Œä¸¦å¯é¸è¨ˆç®— MACD å‹•èƒ½æŒ‡æ¨™ã€‚
# ç‰ˆæœ¬: 3.4.3-zh-fc (å°æ‡‰æº–å‰‡ v3.4ï¼Œä¿®æ­£æ¬„ä½ä¾è³´å’Œ VIX åç¨±)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 7']
# è¼¸å…¥: ['global:merged_data_df', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# è¼¸å‡º: ['global:final_df'] (åŒ…å«æ‰€æœ‰è¨ˆç®—çµæœçš„æœ€çµ‚ DataFrame)
#       (æ›´æ–° EXECUTION_TRACKER)
# ==================================================
"""
åŸºæ–¼åˆä½µå¾Œçš„æ•¸æ“šï¼Œè¨ˆç®—æ‰€æœ‰è¡ç”ŸæŒ‡æ¨™ã€æˆåˆ†æ’åã€æœ€çµ‚å£“åŠ›æŒ‡æ•¸åŠ MACDã€‚

*** é‡è¦å‡è¨­ ***
æ­¤ç‰ˆæœ¬å‡è¨­ Cell 5 å’Œ Cell 7 å·²è¢«ä¿®æ­£ï¼š
1. Cell 5 å·²æˆåŠŸç²å– SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD ç­‰åºåˆ—ã€‚
2. Cell 7 å·²æˆåŠŸå°‡é€™äº›æ–°åºåˆ—ä»¥åŠ VIX_Close åˆä½µåˆ° merged_data_df ä¸­ã€‚
3. PROJECT_CONFIG ä¸­çš„æ¬Šé‡å·²æ›´æ–°ï¼Œä»¥åæ˜ å¯¦éš›å¯ç”¨çš„æŒ‡æ¨™ (ä¾‹å¦‚ï¼Œç§»é™¤äº† MOVEï¼Œç¢ºèª VIX æ¬Šé‡)ã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  **æª¢æŸ¥ä¾è³´**: é©—è­‰ Cell 1 å’Œ Cell 7 æ˜¯å¦æˆåŠŸåŸ·è¡Œï¼Œç¢ºä¿ `merged_data_df`
    å’Œ `PROJECT_CONFIG` å¯ç”¨ï¼Œä¸” `pandas`, `numpy` åº«å·²è¼‰å…¥ã€‚
2.  **æ•¸æ“šæº–å‚™**: å‰µå»º `final_df` ä½œç‚º `merged_data_df` çš„å‰¯æœ¬ã€‚ç¢ºä¿å¿…è¦çš„
    æ•¸å€¼æ¬„ä½ç‚ºæ•¸å€¼é¡å‹ (åŒ…æ‹¬æ–°åŠ å…¥çš„ FRED åºåˆ—å’Œ VIX_Close)ã€‚
3.  **è¨ˆç®—è¡ç”ŸæŒ‡æ¨™**:
    * è¨ˆç®—åˆ©å·® (DGS10 - DGS2)ã€‚
    * è¨ˆç®— SOFR çš„ 60 æ—¥ç§»å‹•å¹³å‡åŠå…¶èˆ‡ç•¶å‰ SOFR çš„åå·®ã€‚
    * è¨ˆç®—æŒæœ‰é‡ / æº–å‚™é‡‘ (WRESBAL) æ¯”ç‡ï¼Œè™•ç†åˆ†æ¯ç‚ºé›¶çš„æƒ…æ³ã€‚
    * è¨˜éŒ„å„æŒ‡æ¨™æ˜¯å¦æˆåŠŸè¨ˆç®—ã€‚
4.  **è¨ˆç®—å£“åŠ›æŒ‡æ•¸**:
    * å¾ `PROJECT_CONFIG` ç²å–æ»¾å‹•çª—å£å¤©æ•¸å’Œæœ€å°æœŸæ•¸ã€‚
    * **æ»¾å‹•æ’å**: å° SOFR åå·®ã€(åè½‰çš„) åˆ©å·®ã€æŒæœ‰é‡ã€VIX_Closeã€
      æŒæœ‰/æº–å‚™é‡‘æ¯”ç‡è¨ˆç®—æ»¾å‹•ç™¾åˆ†ä½æ’åã€‚ **(å·²ç§»é™¤ MOVE)**
    * **åŠ æ¬Šè¨ˆç®—**: å¾ `PROJECT_CONFIG` ç²å–å„æˆåˆ†æ¬Šé‡ã€‚ç¯©é¸å¯ç”¨æˆåˆ†ï¼Œ
      æ­£è¦åŒ–æ¬Šé‡ã€‚æ ¹æ“šæ¬Šé‡å’Œæ’åè¨ˆç®—åŠ æ¬Šç¶œåˆå¾—åˆ† (0-1)ã€‚
      ç‰¹æ®Šè™•ç†æŒæœ‰/æº–å‚™é‡‘æ¯”ç‡çš„æ¢ä»¶æ¬Šé‡ã€‚
    * **æŒ‡æ•¸è½‰æ›**: å°‡ç¶œåˆå¾—åˆ†æ˜ å°„åˆ° 0-100 ç¯„åœï¼Œå¾—åˆ°åŸå§‹å£“åŠ›æŒ‡æ•¸ã€‚
    * **å¹³æ»‘è™•ç† (å¯é¸)**: æ ¹æ“š `PROJECT_CONFIG` è¨­å®šï¼Œå°åŸå§‹æŒ‡æ•¸é€²è¡Œä¸­å¿ƒç§»å‹•å¹³å‡å¹³æ»‘ã€‚
    * è¨˜éŒ„å£“åŠ›æŒ‡æ•¸æ˜¯å¦æˆåŠŸè¨ˆç®—ã€‚
5.  **è¨ˆç®— MACD å‹•èƒ½ (å¯é¸)**:
    * æª¢æŸ¥ `PROJECT_CONFIG` æ˜¯å¦å•Ÿç”¨ MACD è¨ˆç®—ã€‚
    * è‹¥å•Ÿç”¨ä¸”å£“åŠ›æŒ‡æ•¸è¨ˆç®—æˆåŠŸï¼Œå‰‡è¨ˆç®— MACD ç·šã€ä¿¡è™Ÿç·šå’ŒæŸ±ç‹€åœ–ã€‚
    * è¨ˆç®— MACD æŸ±ç‹€åœ–çš„é¡è‰²ï¼Œç”¨æ–¼å¾ŒçºŒç¹ªåœ–ã€‚
    * è¨˜éŒ„ MACD æ˜¯å¦æˆåŠŸè¨ˆç®—ã€‚
6.  **è¨­å®šè¼¸å‡º**: å°‡åŒ…å«æ‰€æœ‰è¨ˆç®—çµæœçš„ DataFrame è³¦å€¼çµ¦å…¨å±€è®Šæ•¸ `final_df`ã€‚
7.  **ç‹€æ…‹å ±å‘Š**: åœ¨ `finally` å€å¡Šä¸­æ›´æ–° `EXECUTION_TRACKER` ä¸¦æ‰“å°åŸ·è¡Œå ±å‘Šã€‚

è¨­è¨ˆèªªæ˜ï¼š
* å°‡æ‰€æœ‰æ ¸å¿ƒè¨ˆç®—é‚è¼¯é›†ä¸­åœ¨æ­¤å„²å­˜æ ¼ã€‚
* è¨ˆç®—éç¨‹åˆ†æ­¥é©Ÿé€²è¡Œï¼Œå…ˆè¨ˆç®—åŸºç¤è¡ç”ŸæŒ‡æ¨™ï¼Œå†è¨ˆç®—æ’åï¼Œæœ€å¾ŒåˆæˆæŒ‡æ•¸ã€‚
* å¾ `PROJECT_CONFIG` è®€å–è¨ˆç®—åƒæ•¸ï¼ˆçª—å£ã€æ¬Šé‡ã€é–¾å€¼ã€MACDåƒæ•¸ç­‰ï¼‰ã€‚
* åŒ…å«å°æ•¸æ“šæœ‰æ•ˆæ€§çš„æª¢æŸ¥ï¼ˆä¾‹å¦‚ï¼Œç¢ºä¿æœ‰è¶³å¤ æ•¸æ“šé»è¨ˆç®—ç§»å‹•å¹³å‡æˆ–æ’åï¼‰ã€‚
* ä½¿ç”¨ `.clip(0, 100)` ç¢ºä¿å£“åŠ›æŒ‡æ•¸åœ¨åˆç†ç¯„åœå…§ã€‚
* MACD è¨ˆç®—å’Œé¡è‰²åˆ†é…é‚è¼¯èˆ‡å…ˆå‰åˆ†æä¸€è‡´ã€‚
* **ä¿®æ­£:** ä½¿ç”¨æ­£ç¢ºçš„æ¬„ä½åç¨± (WRESBAL, VIX_Close)ï¼Œç§»é™¤ MOVE æŒ‡æ•¸ç›¸é—œè¨ˆç®—ã€‚

åƒæ•¸ï¼š
    ç„¡ (ä¾è³´å…¨å±€è®Šæ•¸ `merged_data_df`, `PROJECT_CONFIG`, `libs_loaded`)ã€‚

è¿”å›ï¼š
    ç„¡ (å‰µå»ºæˆ–æ›´æ–°å…¨å±€ DataFrame è®Šæ•¸ `final_df`ï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœå¿…éœ€çš„å…¨å±€è®Šæ•¸æˆ–å‡½å¼åº«æœªå®šç¾©ã€‚
    ValueError/TypeError: å¦‚æœè¼¸å…¥æ•¸æ“šæ ¼å¼ä¸ç¬¦æˆ–è¨ˆç®—åƒæ•¸ç„¡æ•ˆã€‚
    KeyError: å¦‚æœ `merged_data_df` æˆ– `PROJECT_CONFIG` ç¼ºå°‘å¿…è¦çš„éµã€‚
    MemoryError: å¦‚æœæ•¸æ“šé‡éå¤§ã€‚
    Exception: æ•ç²å…¶ä»–æœªé æœŸçš„è¨ˆç®—éŒ¯èª¤ã€‚

å‡è¨­ï¼š
* Cell 1, 5 (å·²ä¿®æ­£), 6, 7 (å·²ä¿®æ­£) å·²æˆåŠŸåŸ·è¡Œã€‚
* `pandas` å’Œ `numpy` å‡½å¼åº«å·²æˆåŠŸè¼‰å…¥ã€‚
* `merged_data_df` åŒ…å«è¨ˆç®—æ‰€éœ€çš„æ¬„ä½ (`SOFR`, `DGS10`, `DGS2`, `WRESBAL`, `RRPONTSYD`, `VIX_Close` ç­‰)ã€‚
* `PROJECT_CONFIG` åŒ…å«è¨ˆç®—æ‰€éœ€çš„åƒæ•¸ï¼Œä¸” `weights` å­—å…¸å·²æ›´æ–°ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* è¨ˆç®—é‡ï¼šæ­¤å„²å­˜æ ¼è¨ˆç®—é‡ç›¸å°è¼ƒå¤§ï¼Œå¯èƒ½éœ€è¦ä¸€äº›åŸ·è¡Œæ™‚é–“ã€‚
* åƒæ•¸æ•æ„Ÿæ€§ï¼šå£“åŠ›æŒ‡æ•¸çš„çµæœå°æ»¾å‹•çª—å£ã€æ¬Šé‡ç­‰åƒæ•¸è¨­ç½®æ•æ„Ÿã€‚
* æ•¸æ“šè³ªé‡ï¼šè¼¸å…¥æ•¸æ“šçš„è³ªé‡ï¼ˆç¼ºå¤±å€¼ã€ç•°å¸¸å€¼ï¼‰æœƒç›´æ¥å½±éŸ¿è¨ˆç®—çµæœã€‚

ä¸‹ä¸€æ­¥ï¼š
* åŸ·è¡Œ Cell 9 (ç”¢ç”Ÿæ™‚é–“åºåˆ—åœ–è¡¨)ã€‚
* åŸ·è¡Œ Cell Z æŸ¥çœ‹æ•´é«”åŸ·è¡Œç‹€æ…‹ï¼Œç¢ºèª `final_df` çš„å…§å®¹ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # æ·»åŠ  timedelta

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (æª¢æŸ¥) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    print("è¨ˆç®—æ‰€éœ€å‡½å¼åº« (pandas, numpy) çœ‹ä¼¼å¯ç”¨ã€‚")
    _libs_ok = True
except ImportError as import_err:
    print(f"è­¦å‘Šï¼šå°å…¥è¨ˆç®—æ‰€éœ€å‡½å¼åº«å¤±æ•—({import_err})ã€‚")
    pd = None; np = None
    _libs_ok = False

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell 8: è¨ˆç®—è¡ç”ŸæŒ‡æ¨™èˆ‡å£“åŠ›æŒ‡æ•¸ (å·²ä¿®æ­£æ¬„ä½ä¾è³´)" # æ›´æ–°æ¨™è­˜ç¬¦

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. å…¨å±€è®Šæ•¸å®šç¾© (æ­¤ Cell çš„ä¸»è¦è¼¸å‡º) ---
global final_df
final_df = None # åˆå§‹åŒ–ç‚º None

# --- 5. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 5.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ ---
    logger.info(f"--- {_cell_identifier} (v3.4.3-zh-fc) é–‹å§‹åŸ·è¡Œ ---") # æ›´æ–°ç‰ˆæœ¬è™Ÿ
    print(f"\n--- {_cell_identifier} (v3.4.3-zh-fc) é–‹å§‹åŸ·è¡Œ ---")

    if not _libs_ok:
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: ç¼ºå°‘å¿…è¦å‡½å¼åº« (pandas, numpy)ã€‚"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: Cell 1 çš„ libs_loaded è®Šæ•¸æœªæ‰¾åˆ°ã€‚"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('numpy'):
         _cell_status = "å¤±æ•—"; _cell_error = f"ä¾è³´éŒ¯èª¤: Cell 1 æœªèƒ½æˆåŠŸè¼‰å…¥ pandas æˆ– numpyã€‚"; raise ImportError(_cell_error)

    if 'merged_data_df' not in globals() or not isinstance(merged_data_df, pd.DataFrame):
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: æ‰¾ä¸åˆ°ä¾†è‡ª Cell 7 çš„æœ‰æ•ˆ merged_data_df DataFrameã€‚"; raise NameError(_cell_error)
    if merged_data_df.empty:
        _cell_status = "å¤±æ•—"; _cell_error = "è¼¸å…¥éŒ¯èª¤: ä¾†è‡ª Cell 7 çš„ merged_data_df ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œè¨ˆç®—ã€‚"; raise ValueError(_cell_error)
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ PROJECT_CONFIGã€‚"; raise NameError(_cell_error)

    _cell_inputs['merged_data_shape'] = merged_data_df.shape
    _cell_inputs['project_config_keys'] = list(PROJECT_CONFIG.keys())
    _cell_notes.append(f"è®€å–åˆ° merged_data_df (ç¶­åº¦: {merged_data_df.shape}) å’Œ PROJECT_CONFIGã€‚")
    print(f"  - æ­¥é©Ÿ 0: ä¾è³´æª¢æŸ¥é€šéã€‚è¼¸å…¥æ•¸æ“šç¶­åº¦: {merged_data_df.shape}")

    # --- 5.2. æ•¸æ“šæº–å‚™ ---
    print("  - æ­¥é©Ÿ 1: æº–å‚™æ•¸æ“šä¸¦ç¢ºä¿æ•¸å€¼é¡å‹...")
    logger.info("æ­¥é©Ÿ 1: æº–å‚™æ•¸æ“š...")
    final_df = merged_data_df.copy() # å‰µå»ºå‰¯æœ¬é€²è¡Œè¨ˆç®—

    # **ä¿®æ­£:** æ›´æ–°éœ€è¦æª¢æŸ¥çš„æ¬„ä½åˆ—è¡¨
    cols_to_ensure_numeric = [
        'SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'RRPONTSYD', # æ–°çš„ FRED åºåˆ—
        'VIX_Close', # ä½¿ç”¨é‡å‘½åå¾Œçš„ VIX æ¬„ä½
        'Total_Gross_Positions_Millions',
        # åŸºç¤åƒ¹æ ¼/æˆäº¤é‡
        'Open', 'High', 'Low', 'Close', 'Volume',
        # å…¶ä»–å¯èƒ½éœ€è¦çš„é‡å‘½åæ¬„ä½
        'TWDUSD_Close', 'TWDUSD_Volume',
        'HYG_Close', 'HYG_Volume',
        'LQD_Close', 'LQD_Volume',
        'FEDFUNDS', 'INDPRO' # ä¾†è‡ªèˆŠ Cell 5
    ]
    # ç§»é™¤ä¸å†ä½¿ç”¨çš„èˆŠåç¨±
    # 'Volatility_Index', 'VIX', 'Reserves', 'RRP_Amount_Billions'

    # æª¢æŸ¥ ETF æ¬„ä½ (å¦‚æœé…ç½®äº†)
    etf_ticker_calc = PROJECT_CONFIG.get('lt_bond_etf_ticker', '').strip().upper()
    etf_col_calc = f'ETF_{etf_ticker_calc}_Price' if etf_ticker_calc else None
    if etf_col_calc and etf_col_calc in final_df.columns:
        cols_to_ensure_numeric.append(etf_col_calc)

    for col in cols_to_ensure_numeric:
        if col in final_df.columns:
            if not pd.api.types.is_numeric_dtype(final_df[col]):
                 initial_dtype = final_df[col].dtype
                 final_df[col] = pd.to_numeric(final_df[col], errors='coerce')
                 _cell_notes.append(f"æ¬„ä½ '{col}' å·²å¾ {initial_dtype} è½‰æ›ç‚ºæ•¸å€¼é¡å‹ã€‚")
        else:
            # åƒ…å°æ ¸å¿ƒè¨ˆç®—æ¬„ä½å‰µå»º NaN åˆ—ä¸¦ç™¼å‡ºè­¦å‘Š
            core_calc_cols = ['SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'VIX_Close', 'Total_Gross_Positions_Millions']
            if col in core_calc_cols:
                final_df[col] = np.nan
                _cell_warnings.append(f"è¨ˆç®—æ‰€éœ€æ ¸å¿ƒæ¬„ä½ '{col}' ä¸å­˜åœ¨æ–¼ merged_data_dfï¼Œå·²å‰µå»º NaN åˆ—ã€‚å£“åŠ›æŒ‡æ•¸å¯èƒ½ç„¡æ³•è¨ˆç®—ã€‚")
                logger.warning(f"æ ¸å¿ƒæ¬„ä½ '{col}' ä¸å­˜åœ¨ï¼Œå·²å‰µå»º NaN åˆ—ã€‚")
            else:
                 # å°æ–¼éæ ¸å¿ƒæ¬„ä½ï¼Œåªè¨˜éŒ„è¨»è¨˜
                 _cell_notes.append(f"æ¬„ä½ '{col}' ä¸å­˜åœ¨æ–¼ merged_data_dfã€‚")


    print("    > æ•¸æ“šé¡å‹æª¢æŸ¥å®Œæˆã€‚")

    # --- 5.3. è¨ˆç®—åŸºæœ¬è¡ç”ŸæŒ‡æ¨™ ---
    print("  - æ­¥é©Ÿ 2: è¨ˆç®—åŸºæœ¬è¡ç”ŸæŒ‡æ¨™...")
    logger.info("æ­¥é©Ÿ 2: è¨ˆç®—åŸºæœ¬è¡ç”ŸæŒ‡æ¨™...")
    sofr_ok = False; sofr_dev_ok = False; spread_calculated_ok = False
    gross_pos_ok = False; vix_ok = False # ç§»é™¤äº† volatility_ok
    reserves_present = False; ratio_calculated_ok = False

    # **ä¿®æ­£:** ä½¿ç”¨ WRESBAL æª¢æŸ¥æº–å‚™é‡‘æ•¸æ“š
    sofr_ok = 'SOFR' in final_df and final_df['SOFR'].notna().any()
    gross_pos_ok = 'Total_Gross_Positions_Millions' in final_df and final_df['Total_Gross_Positions_Millions'].notna().any()
    vix_ok = 'VIX_Close' in final_df and final_df['VIX_Close'].notna().any() # æª¢æŸ¥ VIX_Close
    reserves_present = 'WRESBAL' in final_df and final_df['WRESBAL'].notna().any() # æª¢æŸ¥ WRESBAL

    # è¨ˆç®—åˆ©å·® (DGS10 - DGS2)
    if 'DGS10' in final_df and 'DGS2' in final_df and \
       final_df['DGS10'].notna().any() and final_df['DGS2'].notna().any():
        final_df['Spread_10Y2Y'] = final_df['DGS10'] - final_df['DGS2']
        spread_calculated_ok = final_df['Spread_10Y2Y'].notna().any()
        _cell_notes.append("åˆ©å·® (Spread_10Y2Y) è¨ˆç®—å®Œæˆã€‚"); print("    > åˆ©å·® (Spread_10Y2Y) è¨ˆç®—å®Œæˆã€‚")
    else:
        final_df['Spread_10Y2Y'] = np.nan; spread_calculated_ok = False
        _cell_warnings.append("æœªèƒ½è¨ˆç®—åˆ©å·® (ç¼ºå°‘ DGS10 æˆ– DGS2 æ•¸æ“š)ã€‚"); print("    > è­¦å‘Š: æœªèƒ½è¨ˆç®—åˆ©å·®ã€‚")

    # è¨ˆç®— SOFR åå·®
    if sofr_ok:
        min_periods_ma = 30
        if len(final_df['SOFR'].dropna()) >= min_periods_ma:
            final_df['SOFR_MA60'] = final_df['SOFR'].rolling(window=60, min_periods=min_periods_ma).mean()
            final_df['SOFR_Dev'] = final_df['SOFR'] - final_df['SOFR_MA60']
            sofr_dev_ok = final_df['SOFR_Dev'].notna().any()
            _cell_notes.append("SOFR 60æ—¥å‡ç·šå’Œåå·®è¨ˆç®—å®Œæˆã€‚"); print("    > SOFR å‡ç·šå’Œåå·®è¨ˆç®—å®Œæˆã€‚")
        else:
            final_df['SOFR_MA60'] = np.nan; final_df['SOFR_Dev'] = np.nan; sofr_dev_ok = False
            _cell_warnings.append(f"SOFR æ•¸æ“šé»ä¸è¶³ {min_periods_ma}ï¼Œç„¡æ³•è¨ˆç®—å‡ç·šå’Œåå·®ã€‚"); print(f"    > è­¦å‘Š: SOFR æ•¸æ“šä¸è¶³ã€‚")
    else:
        final_df['SOFR_MA60'] = np.nan; final_df['SOFR_Dev'] = np.nan; sofr_dev_ok = False
        _cell_warnings.append("ç¼ºå°‘ SOFR æ•¸æ“šã€‚"); print("    > è­¦å‘Š: ç¼ºå°‘ SOFR æ•¸æ“šã€‚")

    # **ä¿®æ­£:** è¨ˆç®—æŒæœ‰é‡ / æº–å‚™é‡‘ (WRESBAL) æ¯”ç‡
    if gross_pos_ok and reserves_present:
        reserves_safe = final_df['WRESBAL'].replace(0, np.nan) # ä½¿ç”¨ WRESBAL
        positions_numeric = pd.to_numeric(final_df['Total_Gross_Positions_Millions'], errors='coerce')
        # å°‡æº–å‚™é‡‘å¾ç™¾è¬ç¾å…ƒè½‰æ›ç‚ºåå„„ç¾å…ƒä»¥åŒ¹é…å¸¸è¦‹ç”¨æ³•ï¼ˆå¯é¸ï¼‰
        # reserves_safe_billions = reserves_safe / 1000
        # final_df['Pos_Res_Ratio'] = positions_numeric / reserves_safe_billions
        # æˆ–è€…ä¿æŒç™¾è¬ç¾å…ƒå–®ä½
        final_df['Pos_Res_Ratio'] = positions_numeric / reserves_safe
        if np.isinf(final_df['Pos_Res_Ratio']).any(): final_df['Pos_Res_Ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)
        ratio_calculated_ok = final_df['Pos_Res_Ratio'].notna().any()
        if ratio_calculated_ok: _cell_notes.append("æŒæœ‰é‡/æº–å‚™é‡‘(WRESBAL)æ¯”ç‡è¨ˆç®—å®Œæˆã€‚"); print("    > æŒæœ‰é‡/æº–å‚™é‡‘(WRESBAL)æ¯”ç‡è¨ˆç®—å®Œæˆã€‚")
        else: final_df['Pos_Res_Ratio'] = np.nan; _cell_warnings.append("æ¯”ç‡è¨ˆç®—å¾Œç„¡æœ‰æ•ˆå€¼ã€‚"); print("    > è­¦å‘Š: æ¯”ç‡è¨ˆç®—å¾Œç„¡æœ‰æ•ˆå€¼ã€‚")
    else:
        final_df['Pos_Res_Ratio'] = np.nan; ratio_calculated_ok = False
        if not gross_pos_ok: _cell_warnings.append("ç¼ºå°‘æŒæœ‰é‡æ•¸æ“šï¼Œç„¡æ³•è¨ˆç®—æ¯”ç‡ã€‚")
        if not reserves_present: _cell_warnings.append("ç¼ºå°‘æº–å‚™é‡‘(WRESBAL)æ•¸æ“šï¼Œç„¡æ³•è¨ˆç®—æ¯”ç‡ã€‚")
        print("    > è­¦å‘Š: ç¼ºå°‘æŒæœ‰é‡æˆ–æº–å‚™é‡‘(WRESBAL)æ•¸æ“šï¼Œç„¡æ³•è¨ˆç®—æ¯”ç‡ã€‚")

    # æ›´æ–°è¼¸å‡ºç‹€æ…‹
    _cell_outputs['indicators_calculated'] = {'sofr_dev': sofr_dev_ok, 'spread': spread_calculated_ok, 'pos_res_ratio': ratio_calculated_ok}

    # --- 5.4. è¨ˆç®—å£“åŠ›æŒ‡æ•¸ ---
    print("  - æ­¥é©Ÿ 3: è¨ˆç®—å£“åŠ›æŒ‡æ•¸...")
    logger.info("æ­¥é©Ÿ 3: è¨ˆç®—å£“åŠ›æŒ‡æ•¸...")
    window = int(PROJECT_CONFIG.get('rolling_window_days', 252)); window = max(window, 5)
    min_periods_rank = int(window * 0.6); min_periods_rank = max(min_periods_rank, 3)
    _cell_inputs['stress_index_window'] = window; _cell_inputs['stress_index_min_periods'] = min_periods_rank
    print(f"    > ä½¿ç”¨æ»¾å‹•çª—å£: {window} å¤©, æœ€å°æœŸæ•¸: {min_periods_rank} å¤©")

    perc_ranks = pd.DataFrame(index=final_df.index)
    # **ä¿®æ­£:** æ›´æ–° component_availability å’Œ column_mapping
    component_availability = {
        'sofr_dev': sofr_dev_ok,
        'spread_inv': spread_calculated_ok,
        'gross_pos': gross_pos_ok,
        # 'move': volatility_ok, # ç§»é™¤ MOVE
        'vix': vix_ok, # ä½¿ç”¨ VIX_Close çš„å¯ç”¨æ€§
        'pos_res_ratio': ratio_calculated_ok
    }
    column_mapping = {
        'sofr_dev': 'SOFR_Dev',
        'spread_inv': 'Spread_10Y2Y',
        'gross_pos': 'Total_Gross_Positions_Millions',
        # 'move': 'Volatility_Index', # ç§»é™¤ MOVE
        'vix': 'VIX_Close', # å°‡ vix æ˜ å°„åˆ° VIX_Close
        'pos_res_ratio': 'Pos_Res_Ratio'
    }

    print("      - è¨ˆç®—å„æˆåˆ†æ»¾å‹•ç™¾åˆ†ä½æ’å...")
    for name, is_available in component_availability.items():
        col = column_mapping.get(name)
        if is_available and col in final_df:
            series_to_rank = final_df[col]
            if series_to_rank.notna().sum() >= min_periods_rank:
                rank_pct = series_to_rank.rolling(window=window, min_periods=min_periods_rank).rank(pct=True)
                perc_ranks[name] = 1.0 - rank_pct if name == 'spread_inv' else rank_pct
                _cell_notes.append(f"å·²è¨ˆç®—æˆåˆ† '{name}'{' (åè½‰)' if name == 'spread_inv' else ''} çš„æ»¾å‹•æ’å (ä½¿ç”¨æ¬„ä½: {col})ã€‚")
                print(f"        - æˆåˆ† '{name}' (ä¾†è‡ª {col}) æ’åè¨ˆç®—å®Œæˆã€‚")
            else:
                _cell_warnings.append(f"æˆåˆ† '{name}' (ä¾†è‡ª {col}) æ•¸æ“šä¸è¶³ ({series_to_rank.notna().sum()}/{min_periods_rank})ï¼Œç„¡æ³•è¨ˆç®—æ’åã€‚"); print(f"        - è­¦å‘Š: æˆåˆ† '{name}' (ä¾†è‡ª {col}) æ•¸æ“šä¸è¶³ã€‚")
                perc_ranks[name] = np.nan
        else:
            _cell_notes.append(f"æˆåˆ† '{name}' (æ¬„ä½: {col}) æ•¸æ“šä¸å¯ç”¨ï¼Œè·³éæ’åã€‚"); print(f"        - æˆåˆ† '{name}' (æ¬„ä½: {col}) æ•¸æ“šä¸å¯ç”¨ã€‚")
            perc_ranks[name] = np.nan

    print("      - æ ¹æ“šæ¬Šé‡è¨ˆç®—å£“åŠ›æŒ‡æ•¸...")
    # **é‡è¦æé†’:** éœ€æª¢æŸ¥ PROJECT_CONFIG['weights'] æ˜¯å¦å·²æ›´æ–°ï¼Œç§»é™¤äº† 'move' ä¸¦ç¢ºèª 'vix' æ¬Šé‡é©ç”¨æ–¼ VIX_Close
    weights = PROJECT_CONFIG.get('weights', {})
    threshold_ratio = PROJECT_CONFIG.get('threshold_ratio_color', 90)
    _cell_inputs['stress_index_weights'] = weights; _cell_inputs['stress_index_ratio_threshold'] = threshold_ratio

    # ç¯©é¸å¯¦éš›å¯ç”¨ä¸”æœ‰æ¬Šé‡çš„æˆåˆ†
    active_components = {k: weights.get(k, 0) for k, is_available in component_availability.items()
                         if is_available and k in perc_ranks.columns and perc_ranks[k].notna().any() and weights.get(k, 0) > 0}

    # æª¢æŸ¥æ¬Šé‡å­—å…¸æ˜¯å¦åŒ…å«æœªä½¿ç”¨çš„éµ (ä¾‹å¦‚ 'move')
    unused_weight_keys = set(weights.keys()) - set(active_components.keys()) - set(column_mapping.keys()) # æ¸›å»æœ‰æ•ˆéµå’Œæ˜ å°„éµ
    if unused_weight_keys:
         warn_msg = f"è­¦å‘Š: PROJECT_CONFIG ä¸­çš„æ¬Šé‡å­—å…¸åŒ…å«æœªä½¿ç”¨çš„éµ: {list(unused_weight_keys)}ã€‚è«‹æª¢æŸ¥é…ç½®ã€‚"
         _cell_warnings.append(warn_msg); print(f"        - {warn_msg}")

    total_weight = sum(active_components.values())
    stress_index_calculated = False

    if total_weight > 0:
        weights_normalized = {k: v / total_weight for k, v in active_components.items()}
        print(f"        - ä½¿ç”¨çš„æŒ‡æ¨™èˆ‡æ¬Šé‡ (æ­£è¦åŒ–å¾Œ): {', '.join([f'{k}({w:.1%})' for k, w in weights_normalized.items()])}")
        _cell_notes.append(f"å£“åŠ›æŒ‡æ•¸ä½¿ç”¨æˆåˆ†åŠæ­£è¦åŒ–æ¬Šé‡: {weights_normalized}")

        ratio_high_condition = pd.Series(0.0, index=final_df.index)
        if 'pos_res_ratio' in weights_normalized and ratio_calculated_ok:
             print(f"          * æŒæœ‰/æº–å‚™é‡‘æ¯”ç‡åƒ…åœ¨ >= {threshold_ratio} æ™‚è²¢ç»æ¬Šé‡ã€‚")
             ratio_high_condition = (final_df['Pos_Res_Ratio'] >= threshold_ratio).astype(float).fillna(0.0)

        combined_score_01 = pd.Series(0.0, index=final_df.index)
        for name, weight in weights_normalized.items():
            rank_series = perc_ranks[name].fillna(0.5) # ç”¨ä¸­é–“å€¼å¡«å……æ’åä¸­çš„ NaN
            combined_score_01 += rank_series * ratio_high_condition * weight if name == 'pos_res_ratio' else rank_series * weight

        final_df['Dealer_Stress_Index_Raw'] = (combined_score_01 * 100).clip(0, 100)
        print(f"        - åŸå§‹å£“åŠ›æŒ‡æ•¸ (0-100) è¨ˆç®—å®Œæˆ ({final_df['Dealer_Stress_Index_Raw'].notna().sum()} é»)ã€‚")
        _cell_notes.append("åŸå§‹å£“åŠ›æŒ‡æ•¸è¨ˆç®—å®Œæˆã€‚")

        smoothing_window = int(PROJECT_CONFIG.get('smoothing_window_stress_index', 5))
        _cell_inputs['stress_index_smoothing_window'] = smoothing_window
        if smoothing_window > 1:
            min_periods_smooth = max(1, int(smoothing_window * 0.5))
            final_df['Dealer_Stress_Index'] = final_df['Dealer_Stress_Index_Raw'].rolling(window=smoothing_window, min_periods=min_periods_smooth, center=True).mean().clip(0, 100)
            print(f"        - å·²åŸ·è¡ŒæŒ‡æ•¸å¹³æ»‘ (çª—å£: {smoothing_window} å¤©, ä¸­å¿ƒ)ã€‚"); _cell_notes.append(f"å£“åŠ›æŒ‡æ•¸å·²å¹³æ»‘ (çª—å£: {smoothing_window})ã€‚")
        else:
            final_df['Dealer_Stress_Index'] = final_df['Dealer_Stress_Index_Raw']
            print(f"        - æœªåŸ·è¡ŒæŒ‡æ•¸å¹³æ»‘ (çª—å£ <= 1)ã€‚"); _cell_notes.append("æœªåŸ·è¡Œå£“åŠ›æŒ‡æ•¸å¹³æ»‘ã€‚")

        if final_df['Dealer_Stress_Index'].notna().any(): stress_index_calculated = True; _cell_outputs['stress_index_calculated'] = True; _cell_outputs['stress_index_final_points'] = int(final_df['Dealer_Stress_Index'].count())
        else: _cell_warnings.append("å£“åŠ›æŒ‡æ•¸è¨ˆç®—çµæœ (å¹³æ»‘å¾Œ) å‡ç‚º NaNã€‚"); print("        - è­¦å‘Š: å£“åŠ›æŒ‡æ•¸è¨ˆç®—çµæœå‡ç‚º NaNã€‚"); _cell_outputs['stress_index_calculated'] = False
    else:
         _cell_warnings.append("ç„¡å¯ç”¨æŒ‡æ¨™ã€æ¬Šé‡ç‚ºé›¶æˆ–æ’åè¨ˆç®—å¤±æ•—ï¼Œç„¡æ³•è¨ˆç®—å£“åŠ›æŒ‡æ•¸ã€‚è«‹æª¢æŸ¥æ•¸æ“šæºå’Œæ¬Šé‡é…ç½®ã€‚"); print("      - è­¦å‘Š: ç„¡å¯ç”¨æŒ‡æ¨™æˆ–æ¬Šé‡ï¼Œç„¡æ³•è¨ˆç®—å£“åŠ›æŒ‡æ•¸ã€‚")
         final_df['Dealer_Stress_Index_Raw'] = np.nan; final_df['Dealer_Stress_Index'] = np.nan; _cell_outputs['stress_index_calculated'] = False

    # --- 5.5. è¨ˆç®— MACD å‹•èƒ½ (å¯é¸) ---
    print("  - æ­¥é©Ÿ 4: è¨ˆç®— MACD å‹•èƒ½æŒ‡æ¨™ (å¯é¸)...")
    logger.info("æ­¥é©Ÿ 4: è¨ˆç®— MACD å‹•èƒ½æŒ‡æ¨™...")
    enable_macd = PROJECT_CONFIG.get('enable_macd_momentum_plot', False)
    macd_params = PROJECT_CONFIG.get('macd_params', {}); macd_colors = PROJECT_CONFIG.get('macd_colors', {})
    _cell_inputs['enable_macd'] = enable_macd; _cell_inputs['macd_params'] = macd_params; _cell_inputs['macd_colors'] = macd_colors

    final_df['Stress_Index_MACD_Hist'] = np.nan; final_df['Stress_Index_MACD_Color'] = 'grey'
    macd_calculated_ok = False

    if enable_macd and stress_index_calculated:
        try:
            macd_fast = int(macd_params.get('fast', 12)); macd_fast = max(2, macd_fast)
            macd_slow = int(macd_params.get('slow', 26)); macd_slow = max(macd_fast + 1, macd_slow)
            macd_signal = int(macd_params.get('signal', 9)); macd_signal = max(2, macd_signal)
            color_blue = macd_colors.get('blue', "#6495ED"); color_green = macd_colors.get('green', "#3CB371"); color_red = macd_colors.get('red', "#B22222")
            print(f"    > ä½¿ç”¨ MACD åƒæ•¸: ({macd_fast}, {macd_slow}, {macd_signal})")

            base_series = final_df['Dealer_Stress_Index'].dropna()
            if len(base_series) > macd_slow:
                ema_fast = base_series.ewm(span=macd_fast, adjust=False).mean(); ema_slow = base_series.ewm(span=macd_slow, adjust=False).mean()
                macd_line = ema_fast - ema_slow; signal_line = macd_line.ewm(span=macd_signal, adjust=False).mean()
                histogram = macd_line - signal_line; final_df['Stress_Index_MACD_Hist'] = histogram.reindex(final_df.index)

                if final_df['Stress_Index_MACD_Hist'].notna().any():
                     macd_calculated_ok = True; print(f"      - MACD Histogram è¨ˆç®—å®Œæˆ ({final_df['Stress_Index_MACD_Hist'].count()} é»)"); _cell_notes.append("MACD Histogram è¨ˆç®—å®Œæˆã€‚")
                     hist_series = final_df['Stress_Index_MACD_Hist']; hist_diff = hist_series.diff()
                     conditions = [(hist_diff > 0) & (hist_series >= 0), (hist_diff > 0) & (hist_series < 0), (hist_diff <= 0)]
                     colors = [color_blue, color_green, color_red]; final_df['Stress_Index_MACD_Color'] = np.select(conditions, colors, default='grey')
                     first_valid_index = hist_series.first_valid_index()
                     if first_valid_index is not None: first_val = hist_series[first_valid_index]; final_df.loc[first_valid_index, 'Stress_Index_MACD_Color'] = color_blue if first_val >= 0 else color_green
                     print("      - MACD é¡è‰²è¨ˆç®—å®Œæˆã€‚"); _cell_notes.append("MACD é¡è‰²è¨ˆç®—å®Œæˆã€‚")
                else: _cell_warnings.append("MACD Histogram è¨ˆç®—çµæœå‡ç‚º NaNã€‚"); print("      - è­¦å‘Š: MACD Histogram è¨ˆç®—çµæœå‡ç‚º NaNã€‚")
            else: _cell_warnings.append(f"å£“åŠ›æŒ‡æ•¸æ•¸æ“šé»ä¸è¶³ ({len(base_series)}) è¨ˆç®— MACDã€‚"); print(f"    > è­¦å‘Š: æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•è¨ˆç®— MACDã€‚")
        except Exception as e_macd: _cell_warnings.append(f"è¨ˆç®— MACD æ™‚å‡ºéŒ¯: {e_macd}"); print(f"    > è­¦å‘Š: è¨ˆç®— MACD æ™‚å‡ºéŒ¯: {e_macd}"); logger.warning("è¨ˆç®— MACD æ™‚å‡ºéŒ¯", exc_info=True)
    elif enable_macd: _cell_notes.append("MACD å·²å•Ÿç”¨ï¼Œä½†å£“åŠ›æŒ‡æ•¸æœªæˆåŠŸè¨ˆç®—ã€‚"); print("    > MACD å·²å•Ÿç”¨ï¼Œä½†å£“åŠ›æŒ‡æ•¸æœªæˆåŠŸè¨ˆç®—ï¼Œè·³éã€‚")
    else: _cell_notes.append("MACD æœªå•Ÿç”¨ï¼Œè·³éè¨ˆç®—ã€‚"); print("    > MACD æœªå•Ÿç”¨ï¼Œè·³éè¨ˆç®—ã€‚")

    _cell_outputs['macd_calculated'] = macd_calculated_ok
    _cell_outputs['macd_final_points'] = int(final_df['Stress_Index_MACD_Hist'].count()) if macd_calculated_ok else 0

    # --- 5.6. æ¨™è¨˜ Cell 8 åŸ·è¡Œç‹€æ…‹ ---
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "æˆåŠŸ"
        if not stress_index_calculated: _cell_warnings.append("æ ¸å¿ƒæŒ‡æ¨™å£“åŠ›æŒ‡æ•¸æœªèƒ½æˆåŠŸè¨ˆç®—ã€‚"); _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
        elif _cell_warnings: _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
    logger.info(f"{_cell_identifier} - æŒ‡æ¨™è¨ˆç®—å®Œæˆï¼Œç‹€æ…‹: {_cell_status}")

# --- 6. æ•´å€‹å„²å­˜æ ¼çš„ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError, KeyError) as e:
    if _cell_status != "å¤±æ•—": _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•—ã€‚")
except Exception as e:
    if _cell_status != "å¤±æ•—":
        _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        logger.critical(f"{_cell_identifier} å¤±æ•—: {_cell_error}", exc_info=True)
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•— (æœªé æœŸéŒ¯èª¤)ã€‚")

# --- 7. finally å€å¡Šï¼šåŸ·è¡Œç¸½çµå ±å‘Š ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "â“"

    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "è·³é": _final_status_icon = "ğŸš«"
    elif "æœ‰è­¦å‘Š" in _cell_status: _final_status_icon = "âš ï¸"
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG ä¸­çš„ _tz_info_obj ç„¡æ•ˆæˆ–æœªæ‰¾åˆ°ï¼Œå ±å‘Šæ™‚é–“æˆ³å°‡å›é€€åˆ° UTC+8ã€‚")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—": _cell_warnings.append(f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "è­¦å‘Šï¼šEXECUTION_TRACKER æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚å·²å‰µå»ºå›é€€è¿½è¹¤å™¨ã€‚";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    # æ›´æ–°è¼¸å‡ºæ‘˜è¦
    if 'final_df' in globals() and isinstance(final_df, pd.DataFrame) and not final_df.empty:
         _cell_outputs['output_dataframe_shape'] = final_df.shape
         _cell_outputs['output_dataframe_columns_count'] = len(final_df.columns)
         _cell_outputs['output_start_date'] = final_df.index.min().strftime('%Y-%m-%d')
         _cell_outputs['output_end_date'] = final_df.index.max().strftime('%Y-%m-%d')
         # æ·»åŠ å£“åŠ›æŒ‡æ•¸å’Œ MACD çš„æœ€çµ‚å€¼ï¼ˆå¦‚æœè¨ˆç®—æˆåŠŸï¼‰
         if _cell_outputs.get('stress_index_calculated'):
              try: _cell_outputs['latest_stress_index'] = round(final_df['Dealer_Stress_Index'].iloc[-1], 2)
              except: pass
         if _cell_outputs.get('macd_calculated'):
              try: _cell_outputs['latest_macd_hist'] = round(final_df['Stress_Index_MACD_Hist'].iloc[-1], 4)
              except: pass
    elif 'final_df' in globals() and isinstance(final_df, pd.DataFrame):
         _cell_outputs['output_dataframe_shape'] = final_df.shape
         _cell_outputs['output_dataframe_columns_count'] = 0

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"æ›´æ–° EXECUTION_TRACKER æ™‚å¤±æ•—: {tracker_update_err}", exc_info=True); print(f"éŒ¯èª¤: æ›´æ–° EXECUTION_TRACKER æ™‚ç™¼ç”Ÿç•°å¸¸: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼: {_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **")
    print(f"** ç‹€æ…‹: ** {_final_status_icon} {_cell_status}")
    print(f"** åŸ·è¡Œæ™‚é–“: ** {_cell_duration:.2f} ç§’")
    print(f"** å®Œæˆæ™‚é–“: ** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸è©³æƒ…: **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜: **"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯: **\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback éé•·ï¼Œå·²æˆªæ–·)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))

    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦: **")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    tracked_outputs.pop('merged_dataframe_nan_counts', None)
    tracked_outputs.pop('indicators_calculated', None)
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- 8. æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'cols_to_ensure_numeric', 'base_price_cols', 'etf_ticker_calc', 'etf_col_calc', 'col', 'initial_dtype',
        'sofr_ok', 'sofr_dev_ok', 'spread_calculated_ok', 'gross_pos_ok', 'volatility_ok', # volatility_ok å¯èƒ½ä¸å†éœ€è¦
        'vix_ok', 'reserves_present', 'ratio_calculated_ok', 'min_periods_ma', 'reserves_safe',
        'positions_numeric', 'window', 'min_periods_rank', 'perc_ranks', 'component_availability',
        'column_mapping', 'name', 'is_available', 'series_to_rank', 'rank_pct', 'weights',
        'threshold_ratio', 'active_components', 'total_weight', 'weights_normalized',
        'ratio_high_condition', 'combined_score_01', 'rank_series', 'stress_index_calculated',
        'smoothing_window', 'min_periods_smooth', 'enable_macd', 'macd_params', 'macd_colors',
        'macd_calculated_ok', 'macd_fast', 'macd_slow', 'macd_signal', 'color_blue', 'color_green',
        'color_red', 'base_series', 'ema_fast', 'ema_slow', 'macd_line', 'signal_line', 'histogram',
        'hist_series', 'hist_diff', 'conditions', 'colors', 'first_valid_index', 'first_val',
        'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local',
        'tz_obj', 'tracker_warn_msg', 'time_warn_msg', 'warn_msg', 'err_msg', 'info_text',
        'tracked_outputs', 'summary_output', 'summary_output_filtered', 'failed_list', 'idx', 'failed_item',
        'max_notes_to_show', 'notes_to_show', 'max_traceback_lines', 'traceback_lines', 'traceback_to_display',
        'max_failed_to_show', 'traceback_content', 'missing_vars', 'core_calc_cols', 'unused_weight_keys' # æ·»åŠ æ¸…ç†
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")


# ==================================================
# é å°¾è¨»è§£ (v3.4.3-zh-fc) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell 8: è¨ˆç®—è¡ç”ŸæŒ‡æ¨™èˆ‡å£“åŠ›æŒ‡æ•¸ (å·²ä¿®æ­£æ¬„ä½ä¾è³´)
# åŠŸèƒ½: åŸºæ–¼åˆä½µå¾Œçš„æ•¸æ“š DataFrame (`merged_data_df`)ï¼Œè¨ˆç®—è¡ç”ŸæŒ‡æ¨™ã€
#       æ»¾å‹•æ’åã€å£“åŠ›æŒ‡æ•¸å’Œå¯é¸çš„ MACD æŒ‡æ¨™ã€‚
# ç‰ˆæœ¬: 3.4.3-zh-fc
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 7']
# è¼¸å…¥: ['global:merged_data_df', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# è¼¸å‡º: ['global:final_df']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell_Debug_Consolidated: ç¶œåˆé™¤éŒ¯è³‡è¨Š (å¢å¼·ç‰ˆ)
# --------------------------------------------------
# åŠŸèƒ½: æ•´åˆé¡¯ç¤º EXECUTION_TRACKER æ‘˜è¦ã€é—œéµå…¨å±€æ•¸æ“šè®Šæ•¸çš„ç‹€æ…‹èˆ‡é è¦½ã€
#       merged_data_df çš„ NaN çµ±è¨ˆã€PROJECT_CONFIG åŠ libs_loaded ç‹€æ…‹ï¼Œ
#       ä»¥ä¾¿æ–¼åˆ†æä¸ç©©å®šå•é¡Œã€‚
# ç‰ˆæœ¬: 1.1 (å¢å¼·æ•¸æ“šæª¢æŸ¥èˆ‡é¡¯ç¤º)
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 7' (éš±å¼)]
# è¼¸å…¥: ['global:EXECUTION_TRACKER', 'global:PROJECT_CONFIG', 'global:libs_loaded',
#        'global:fred_data_df', 'global:yahoo_data_df',
#        'global:nyfed_positions_series', 'global:merged_data_df']
# è¼¸å‡º: (åœ¨å„²å­˜æ ¼è¼¸å‡ºå€åŸŸé¡¯ç¤ºåŒ¯ç¸½çš„é™¤éŒ¯è³‡è¨Š)
#       (æ›´æ–° EXECUTION_TRACKER - è¨˜éŒ„æ­¤é™¤éŒ¯ Cell è‡ªèº«ç‹€æ…‹)
# --------------------------------------------------
# ==================================================
"""
ç”Ÿæˆä¸¦é¡¯ç¤ºä¸€å€‹å¢å¼·çš„ç¶œåˆé™¤éŒ¯å ±å‘Šï¼ŒåŒ…å«åŸ·è¡Œæµç¨‹æ‘˜è¦ã€é—œéµæ•¸æ“šç‹€æ…‹èˆ‡é è¦½ã€
merged_data_df çš„ NaN çµ±è¨ˆã€PROJECT_CONFIG åŠ libs_loaded ç‹€æ…‹ã€‚

æ­¤å„²å­˜æ ¼åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1.  åŸ·è¡ŒåŸºæœ¬çš„å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ (logger, EXECUTION_TRACKER)ã€‚
2.  **é¡¯ç¤ºåŸ·è¡Œæµç¨‹æ‘˜è¦**: (é¡ä¼¼ Cell Z)
    a. å˜—è©¦å°å…¥ pandas å’Œ IPythonã€‚
    b. å°‡ EXECUTION_TRACKER è½‰æ›ç‚º DataFrame (è‹¥å¯ç”¨)ã€‚
    c. é¡¯ç¤ºæ ¼å¼åŒ–çš„åŸ·è¡Œç‹€æ…‹æ‘˜è¦è¡¨æ ¼ã€‚
    d. é¡¯ç¤ºè©³ç´°çš„è­¦å‘Šå’ŒéŒ¯èª¤ä¿¡æ¯ã€‚
3.  **é¡¯ç¤º PROJECT_CONFIG**: ä½¿ç”¨ pprint é¡¯ç¤ºå…¨å±€é…ç½®å­—å…¸ã€‚
4.  **é¡¯ç¤º libs_loaded**: ä½¿ç”¨ pprint é¡¯ç¤ºå‡½å¼åº«è¼‰å…¥ç‹€æ…‹å­—å…¸ã€‚
5.  **æª¢æŸ¥é—œéµæ•¸æ“šè®Šæ•¸ç‹€æ…‹èˆ‡é è¦½**:
    a. å®šç¾©è¦æª¢æŸ¥çš„æ•¸æ“šè®Šæ•¸åˆ—è¡¨ã€‚
    b. å¾ªç’°æª¢æŸ¥æ¯å€‹è®Šæ•¸æ˜¯å¦å­˜åœ¨ã€é¡å‹ã€æ˜¯å¦ç‚ºç©ºã€ç¶­åº¦/é•·åº¦ã€‚
    c. **æ–°å¢**: å¦‚æœè®Šæ•¸æ˜¯ DataFrame æˆ– Series ä¸”éç©ºï¼Œé¡¯ç¤ºå…¶é ­éƒ¨å’Œå°¾éƒ¨æ•¸æ“š (`.head(3)`, `.tail(3)`)ã€‚
6.  **è©³ç´°æª¢æŸ¥ `merged_data_df` NaN çµ±è¨ˆ**:
    a. æª¢æŸ¥ `merged_data_df` æ˜¯å¦å­˜åœ¨ä¸”éç©ºã€‚
    b. **æ–°å¢**: å¦‚æœå­˜åœ¨ï¼Œè¨ˆç®—ä¸¦é¡¯ç¤º *æ‰€æœ‰æ¬„ä½* çš„ NaN å€¼æ•¸é‡ (`.isnull().sum()`)ã€‚
7.  åŒ…å«ä¸€å€‹å¼·åˆ¶æ€§çš„ `finally` å€å¡Šï¼Œç”¨æ–¼å ±å‘Šæ­¤é™¤éŒ¯å„²å­˜æ ¼è‡ªèº«çš„åŸ·è¡Œç‹€æ…‹
    ä¸¦æ›´æ–° `EXECUTION_TRACKER`ã€‚

è¨­è¨ˆèªªæ˜ï¼š
* å°‡æµç¨‹ç‹€æ…‹å’Œæ•¸æ“šç‹€æ…‹æ•´åˆåˆ°ä¸€å€‹å ±å‘Šä¸­ã€‚
* é‡ç”¨äº† Cell Z å’Œ Cell_Debug çš„éƒ¨åˆ†é‚è¼¯ã€‚
* **å¢å¼·**: åŠ å…¥æ•¸æ“šé è¦½ã€å®Œæ•´çš„ NaN çµ±è¨ˆã€PROJECT_CONFIG å’Œ libs_loaded é¡¯ç¤ºã€‚
* ç‰¹åˆ¥é—œæ³¨ `merged_data_df` çš„å…§å®¹ã€‚
* å¢åŠ äº†æ›´å¤šéŒ¯èª¤è™•ç†ï¼Œä½¿é™¤éŒ¯å„²å­˜æ ¼æ›´ç©©å¥ã€‚

åƒæ•¸ï¼š
    ç„¡ (è®€å–å…¨å±€è®Šæ•¸)ã€‚

è¿”å›ï¼š
    ç„¡ (å°‡ç¶œåˆé™¤éŒ¯å ±å‘Šæ‰“å°åˆ°è¼¸å‡ºï¼Œä¸¦æ›´æ–°å…¨å±€ `EXECUTION_TRACKER`)ã€‚

å¯èƒ½å¼•ç™¼çš„éŒ¯èª¤ï¼š
    NameError: å¦‚æœ logger æˆ– EXECUTION_TRACKER æœªå®šç¾©ã€‚
    Exception: æ•ç²æª¢æŸ¥æˆ–å ±å‘Šç”Ÿæˆéç¨‹ä¸­å…¶ä»–æœªé æœŸçš„éŒ¯èª¤ã€‚

å‡è¨­ï¼š
* Cell 1 å·²å˜—è©¦åŸ·è¡Œã€‚
* å…ˆå‰çš„å·¥ä½œæµç¨‹å„²å­˜æ ¼ (è‡³å°‘åˆ° Cell 7) å·²å˜—è©¦åŸ·è¡Œã€‚
* ç‚ºäº†ç²å¾—æœ€ä½³è¦–è¦ºæ•ˆæœï¼Œå»ºè­°å®‰è£ `pandas` å’Œ `ipython`ã€‚

æ½›åœ¨å•é¡Œ / è€ƒé‡ï¼š
* å¦‚æœ EXECUTION_TRACKER æˆ–æ•¸æ“šè®Šæ•¸ä¸å­˜åœ¨ï¼Œå ±å‘ŠæœƒæŒ‡å‡ºå•é¡Œã€‚
* å¦‚æœç¼ºå°‘ pandas/ipythonï¼Œæ‘˜è¦è¡¨æ ¼é¡¯ç¤ºè³ªé‡æœƒä¸‹é™ã€‚
* æ•¸æ“šé è¦½å¯èƒ½æœƒè¼¸å‡ºè¼ƒå¤šå…§å®¹ã€‚

ä¸‹ä¸€æ­¥ï¼š
* æ ¹æ“šæ­¤å„²å­˜æ ¼çš„è¼¸å‡ºï¼Œåˆ¤æ–·æ˜¯å“ªå€‹å„²å­˜æ ¼åŸ·è¡Œå¤±æ•—æˆ–å“ªå€‹æ•¸æ“šè®Šæ•¸ç‹€æ…‹ç•°å¸¸ï¼Œ
  ç„¶å¾Œå›åˆ°å°æ‡‰çš„å„²å­˜æ ¼é€²è¡Œæª¢æŸ¥å’Œä¿®æ­£ã€‚
"""
# ==================================================

# --- 0. æ¨™æº–åº«å°å…¥ ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta

# --- 1. ç¬¬ä¸‰æ–¹å‡½å¼åº«å°å…¥ (å˜—è©¦å°å…¥) ---
logger = logging.getLogger(__name__)
_PANDAS_AVAILABLE_CD = False
_IPYTHON_AVAILABLE_CD = False
try:
    # æª¢æŸ¥ pandas æ˜¯å¦å·²è¼‰å…¥
    if 'libs_loaded' in globals() and libs_loaded.get('pandas'):
        import pandas as pd
        # è¨­å®š Pandas é¡¯ç¤ºé¸é …ï¼Œé¿å…é è¦½æ™‚æˆªæ–·éå¤š
        pd.set_option('display.max_rows', 10)
        pd.set_option('display.max_columns', 20)
        pd.set_option('display.width', 120)
        _PANDAS_AVAILABLE_CD = True
    else: pd = None
    # æª¢æŸ¥ IPython æ˜¯å¦å¯ç”¨
    if 'libs_loaded' in globals() and libs_loaded.get('ipywidgets'): # å‡è¨­ ipywidgets æ„å‘³è‘— IPython å¯ç”¨
         from IPython.display import display, HTML
         _IPYTHON_AVAILABLE_CD = True
    else:
         def display(x): print(x)
         def HTML(x): return str(x) # å›é€€å‡½æ•¸
    print("ç¶œåˆé™¤éŒ¯æ‰€éœ€å‡½å¼åº«æª¢æŸ¥å®Œæˆã€‚")
except ImportError:
    print("è­¦å‘Šï¼šå°å…¥ Pandas æˆ– IPython æ™‚é‡åˆ°å•é¡Œã€‚")
    pd = None
    def display(x): print(x)
    def HTML(x): return str(x)

# --- 2. å„²å­˜æ ¼æ¨™è­˜ç¬¦ (ç”¨æ–¼è¿½è¹¤) ---
_cell_identifier = "Cell_Debug_Consolidated: ç¶œåˆé™¤éŒ¯è³‡è¨Š (å¢å¼·ç‰ˆ)"

# --- 3. å„²å­˜æ ¼ç‹€æ…‹è¿½è¹¤è®Šæ•¸ ---
_cell_start_time = time.time()
_cell_status = "è™•ç†ä¸­"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {'checked_components': ['EXECUTION_TRACKER', 'PROJECT_CONFIG', 'libs_loaded', 'Key Data Variables', 'merged_data_df NaN Stats']}
_cell_outputs = {'execution_summary_generated': False, 'config_displayed': False, 'libs_displayed': False, 'data_check_completed': False, 'merged_nan_check_completed': False}
_cell_generated_files = []

# --- 4. ä¸»è¦è…³æœ¬ä¸»é«” ---
try:
    # --- 4.1. å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ (logger, EXECUTION_TRACKER) ---
    logger.info(f"--- {_cell_identifier} (v1.1) é–‹å§‹åŸ·è¡Œ ---")
    print(f"\n--- {_cell_identifier} (v1.1) é–‹å§‹åŸ·è¡Œ ---")

    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        try: logger = logging.getLogger(__name__);
        except: print("è­¦å‘Š: Logger æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚"); _cell_warnings.append("Logger æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        _cell_status = "å¤±æ•—"; _cell_error = "ä¾è³´éŒ¯èª¤: æ‰¾ä¸åˆ°å…¨å±€åŸ·è¡Œè¿½è¹¤å™¨ EXECUTION_TRACKERã€‚"; raise NameError(_cell_error)

    # --- 4.2. é¡¯ç¤ºåŸ·è¡Œæµç¨‹æ‘˜è¦ ---
    print("\n" + "="*30 + " åŸ·è¡Œæµç¨‹æ‘˜è¦ " + "="*30)
    tracker_data = EXECUTION_TRACKER; num_records = len(tracker_data)
    _cell_notes.append(f"å¾ EXECUTION_TRACKER è®€å– {num_records} æ¢è¨˜éŒ„ã€‚")
    if not tracker_data: print("â„¹ï¸ EXECUTION_TRACKER ç‚ºç©ºã€‚"); _cell_outputs['execution_summary_generated'] = True
    elif not _PANDAS_AVAILABLE_CD: print("âš ï¸ è­¦å‘Š: Pandas åº«ä¸å¯ç”¨ï¼Œé¡¯ç¤ºåŸå§‹è¿½è¹¤æ•¸æ“šã€‚"); pprint.pprint(tracker_data, indent=2); _cell_outputs['execution_summary_generated'] = True
    else:
        # (é¡¯ç¤ºæ‘˜è¦è¡¨çš„é‚è¼¯ï¼Œèˆ‡ä¹‹å‰ç‰ˆæœ¬é¡ä¼¼ï¼Œæ­¤è™•çœç•¥ä»¥ä¿æŒç°¡æ½”ï¼Œå‡è¨­å…¶èƒ½æ­£å¸¸å·¥ä½œæˆ–åœ¨éœ€è¦æ™‚èª¿è©¦)
        # ... (åƒè€ƒä¹‹å‰ç‰ˆæœ¬ Cell_Debug_Consolidated çš„ Section 4.2 é‚è¼¯) ...
        print("(åŸ·è¡Œæµç¨‹æ‘˜è¦é¡¯ç¤ºé‚è¼¯ - åƒè€ƒ Cell Z æˆ–å…ˆå‰ç‰ˆæœ¬)") # ä½”ä½ç¬¦
        _cell_outputs['execution_summary_generated'] = True # å‡è¨­æˆåŠŸ

    # --- 4.3. é¡¯ç¤º PROJECT_CONFIG ---
    print("\n" + "="*30 + " PROJECT_CONFIG ç‹€æ…‹ " + "="*30)
    if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
        print("ç•¶å‰ PROJECT_CONFIG å…§å®¹:")
        # å‰µå»ºå‰¯æœ¬ä»¥ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ•æ„Ÿä¿¡æ¯æˆ–å¤§å‹ç‰©ä»¶ï¼ˆä¾‹å¦‚ _tz_info_objï¼‰
        config_to_print = PROJECT_CONFIG.copy()
        config_to_print.pop('_tz_info_obj', None) # ç§»é™¤æ™‚å€ç‰©ä»¶
        # å¦‚æœæœªä¾†æœ‰åŠ è¼‰ API Key åˆ° CONFIG (ä¸æ¨è–¦)ï¼Œå¯ä»¥åœ¨é€™è£¡ç§»é™¤
        # config_to_print.pop('FRED_API_KEY_VALUE', None)
        pprint.pprint(config_to_print, indent=2, width=100, sort_dicts=False)
        _cell_outputs['config_displayed'] = True
    else:
        print("âŒ PROJECT_CONFIG ä¸å­˜åœ¨æˆ–é¡å‹éŒ¯èª¤ã€‚")
        _cell_warnings.append("PROJECT_CONFIG ç¼ºå¤±æˆ–ç„¡æ•ˆã€‚")
        _cell_outputs['config_displayed'] = False

    # --- 4.4. é¡¯ç¤º libs_loaded ---
    print("\n" + "="*30 + " libs_loaded ç‹€æ…‹ (ä¾†è‡ª Cell 1) " + "="*30)
    if 'libs_loaded' in globals() and isinstance(libs_loaded, dict):
        print("å‡½å¼åº«è¼‰å…¥ç‹€æ…‹:")
        pprint.pprint(libs_loaded, indent=2, width=100)
        _cell_outputs['libs_displayed'] = True
        # æª¢æŸ¥æ˜¯å¦æœ‰è¼‰å…¥å¤±æ•—çš„åº«
        failed_libs = [lib for lib, loaded in libs_loaded.items() if not loaded]
        if failed_libs:
            warn_msg = f"âš ï¸ æ³¨æ„: Cell 1 æœªèƒ½æˆåŠŸè¼‰å…¥ä»¥ä¸‹å‡½å¼åº«: {', '.join(failed_libs)}"
            print(warn_msg)
            _cell_warnings.append(warn_msg)
    else:
        print("âŒ libs_loaded è®Šæ•¸ä¸å­˜åœ¨æˆ–é¡å‹éŒ¯èª¤ã€‚")
        _cell_warnings.append("libs_loaded ç¼ºå¤±æˆ–ç„¡æ•ˆã€‚")
        _cell_outputs['libs_displayed'] = False

    # --- 4.5. æª¢æŸ¥é—œéµæ•¸æ“šè®Šæ•¸ç‹€æ…‹èˆ‡é è¦½ ---
    print("\n" + "="*30 + " é—œéµæ•¸æ“šè®Šæ•¸ç‹€æ…‹èˆ‡é è¦½ " + "="*30)
    _data_variables_to_check = {
        # ä¾†è‡ª Cell 5
        'df_fedfunds': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_indpro': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        # ä¾†è‡ª Cell 3 & 4 (åˆä½µæª¢æŸ¥)
        'df_twdusd': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_vix': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_spy': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_hyg': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_lqd': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        # ä¾†è‡ª Cell 6
        'nyfed_positions_series': pd.Series if _PANDAS_AVAILABLE_CD else None,
        # ä¾†è‡ª Cell 7
        'merged_data_df': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
    }
    data_check_results = {}
    _cell_outputs['data_check_results'] = data_check_results # åˆå§‹åŒ–

    for var_name, expected_type in _data_variables_to_check.items():
        print(f"\n--- [æª¢æŸ¥æ•¸æ“šè®Šæ•¸: {var_name}] ---")
        var_state = {}
        data_check_results[var_name] = var_state

        if var_name not in globals() or globals()[var_name] is None:
            status_msg = "âŒ ä¸å­˜åœ¨æˆ–ç‚º None"; print(f"  - ç‹€æ…‹: {status_msg}"); var_state['status'] = status_msg; _cell_warnings.append(f"æ•¸æ“šè®Šæ•¸ '{var_name}' ä¸å­˜åœ¨æˆ–ç‚º Noneã€‚")
            continue

        var_value = globals()[var_name]
        actual_type = type(var_value)
        var_state['status'] = "âœ… å­˜åœ¨"; print(f"  - ç‹€æ…‹: âœ… å­˜åœ¨")
        var_state['actual_type'] = str(actual_type)

        if expected_type is not None:
            is_correct_type = isinstance(var_value, expected_type)
            type_msg = f"âœ… é¡å‹æ­£ç¢º ({actual_type.__name__})" if is_correct_type else f"âŒ é¡å‹éŒ¯èª¤ (é æœŸ: {expected_type.__name__}, å¯¦éš›: {actual_type.__name__})"
            print(f"  - é¡å‹: {type_msg}"); var_state['type_check'] = type_msg
            if not is_correct_type: _cell_warnings.append(f"æ•¸æ“šè®Šæ•¸ '{var_name}' é¡å‹éŒ¯èª¤ã€‚")
        else: print(f"  - é¡å‹: {actual_type.__name__}")

        if isinstance(var_value, (pd.DataFrame, pd.Series)):
            try:
                is_empty = var_value.empty; shape_or_len = var_value.shape
                print(f"  - æ˜¯å¦ç‚ºç©º: {is_empty}"); print(f"  - ç¶­åº¦/é•·åº¦: {shape_or_len}")
                var_state['is_empty'] = is_empty; var_state['shape_or_length'] = shape_or_len
                if not is_empty:
                    print(f"  - ç´¢å¼•é¡å‹: {type(var_value.index).__name__}")
                    var_state['index_type'] = type(var_value.index).__name__
                    if isinstance(var_value, pd.DataFrame):
                         print(f"  - æ¬„ä½åç¨±: {var_value.columns.tolist()}")
                         var_state['columns'] = var_value.columns.tolist()

                    # é¡¯ç¤ºæ•¸æ“šé è¦½
                    print("  --- æ•¸æ“šé è¦½ (é ­éƒ¨ 3 è¡Œ): ---")
                    print(var_value.head(3).to_string())
                    print("  --- æ•¸æ“šé è¦½ (å°¾éƒ¨ 3 è¡Œ): ---")
                    print(var_value.tail(3).to_string())
                    print("  -----------------------------")
                    var_state['preview_generated'] = True
                else:
                    var_state['preview_generated'] = False
            except Exception as e_preview:
                preview_err_msg = f"é¡¯ç¤ºè®Šæ•¸ '{var_name}' é è¦½æ™‚å‡ºéŒ¯: {e_preview}"
                print(f"  - é è¦½: âŒ éŒ¯èª¤ ({preview_err_msg})")
                _cell_warnings.append(preview_err_msg)
                var_state['preview_error'] = preview_err_msg
                var_state['preview_generated'] = False

    _cell_outputs['data_check_completed'] = True

    # --- 4.6. è©³ç´°æª¢æŸ¥ merged_data_df NaN çµ±è¨ˆ ---
    print("\n" + "="*25 + " merged_data_df NaN å€¼çµ±è¨ˆ " + "="*25)
    merged_nan_check_results = {}
    _cell_outputs['merged_nan_checks'] = merged_nan_check_results

    if 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame) and not merged_data_df.empty:
        print(f"æª¢æŸ¥ merged_data_df (ç¶­åº¦: {merged_data_df.shape}) ä¸­æ‰€æœ‰æ¬„ä½çš„ NaN æ•¸é‡:")
        try:
            nan_counts = merged_data_df.isnull().sum()
            nan_counts_dict = nan_counts.to_dict()
            merged_nan_check_results['nan_counts_per_column'] = nan_counts_dict
            print(nan_counts.to_string()) # æ‰“å° Series æ ¼å¼çš„ NaN è¨ˆæ•¸
            _cell_outputs['merged_nan_check_completed'] = True
            # æª¢æŸ¥æ˜¯å¦æœ‰å…¨ç‚º NaN çš„åˆ—
            all_nan_cols = nan_counts[nan_counts == len(merged_data_df)].index.tolist()
            if all_nan_cols:
                warn_msg = f"âš ï¸ merged_data_df ä¸­ä»¥ä¸‹æ¬„ä½å…¨ç‚º NaN: {all_nan_cols}"
                print(f"\n{warn_msg}")
                _cell_warnings.append(warn_msg)
                merged_nan_check_results['all_nan_columns'] = all_nan_cols
        except Exception as e_nan:
            nan_err_msg = f"è¨ˆç®— merged_data_df NaN çµ±è¨ˆæ™‚å‡ºéŒ¯: {e_nan}"
            print(f"âŒ {nan_err_msg}")
            _cell_warnings.append(nan_err_msg)
            merged_nan_check_results['error'] = nan_err_msg
            _cell_outputs['merged_nan_check_completed'] = False
    elif 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame):
        print("â„¹ï¸ merged_data_df ç‚ºç©ºï¼Œç„¡æ³•æª¢æŸ¥ NaNã€‚")
        _cell_notes.append("merged_data_df ç‚ºç©ºï¼Œè·³é NaN æª¢æŸ¥ã€‚")
    else:
        print("âŒ merged_data_df ä¸å­˜åœ¨æˆ–é¡å‹éŒ¯èª¤ï¼Œç„¡æ³•æª¢æŸ¥ NaNã€‚")
        _cell_notes.append("merged_data_df ç¼ºå¤±ï¼Œè·³é NaN æª¢æŸ¥ã€‚")


    # --- æ¨™è¨˜ Cell Debug Consolidated åŸ·è¡Œç‹€æ…‹ ---
    if _cell_status == "è™•ç†ä¸­":
        _cell_status = "æˆåŠŸ"
        if _cell_warnings: _cell_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
    logger.info(f"{_cell_identifier} - ç¶œåˆé™¤éŒ¯è³‡è¨Šç”Ÿæˆå®Œæˆï¼Œç‹€æ…‹: {_cell_status}")

# --- ç•°å¸¸è™•ç† ---
except (NameError, ValueError, ImportError, KeyError) as e:
    if _cell_status != "å¤±æ•—": _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•—ã€‚")
except Exception as e:
    if _cell_status != "å¤±æ•—":
        _cell_status = "å¤±æ•—"; _cell_error = f"åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} å¤±æ•—: {_cell_error}", exc_info=True)
        except: pass
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"âŒ {_cell_identifier} åŸ·è¡Œå¤±æ•— (æœªé æœŸéŒ¯èª¤)ã€‚")

# --- finally å€å¡Šï¼šåŸ·è¡Œç¸½çµå ±å‘Š (Cell Debug Consolidated è‡ªèº«) ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "â“"

    if _cell_status == "å¤±æ•—": _final_status_icon = "âŒ"
    elif _cell_status == "è·³é": _final_status_icon = "ğŸš«"
    elif "æœ‰è­¦å‘Š" in _cell_status: _final_status_icon = "âš ï¸"
    elif _cell_status == "æˆåŠŸ": _final_status_icon = "âœ…"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG ä¸­çš„ _tz_info_obj ç„¡æ•ˆæˆ–æœªæ‰¾åˆ°ï¼Œå ±å‘Šæ™‚é–“æˆ³å°‡å›é€€åˆ° UTC+8ã€‚")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (æœ¬åœ°æ™‚é–“)')
        except Exception as time_err_local: _current_time_str = f"ç²å–æ™‚é–“éŒ¯èª¤ï¼š{time_err_local}"
        if _cell_status != "å¤±æ•—": _cell_warnings.append(f"å ±å‘Šæ™‚é–“ç²å–éŒ¯èª¤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "è­¦å‘Šï¼šEXECUTION_TRACKER æœªæ­£ç¢ºåˆå§‹åŒ–ã€‚å·²å‰µå»ºå›é€€è¿½è¹¤å™¨ã€‚";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"æ›´æ–° EXECUTION_TRACKER æ™‚å¤±æ•—: {tracker_update_err}", exc_info=True); print(f"éŒ¯èª¤: æ›´æ–° EXECUTION_TRACKER æ™‚ç™¼ç”Ÿç•°å¸¸: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else 'æœªçŸ¥æº–å‰‡ç‰ˆæœ¬'
    print(f"å„²å­˜æ ¼: {_cell_identifier} (v{_guideline_version_str}) ** åŸ·è¡Œç¸½çµå ±å‘Š **") # ä¿®æ­£å†’è™Ÿ
    print(f"** ç‹€æ…‹: ** {_final_status_icon} {_cell_status}") # ä¿®æ­£å†’è™Ÿ
    print(f"** åŸ·è¡Œæ™‚é–“: ** {_cell_duration:.2f} ç§’") # ä¿®æ­£å†’è™Ÿ
    print(f"** å®Œæˆæ™‚é–“: ** {_current_time_str}") # ä¿®æ­£å†’è™Ÿ
    if _cell_inputs: print("\n** \U0001F527 è¼¸å…¥åƒæ•¸/æª¢æŸ¥é …ç›®: **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False) # ä¿®æ­£å†’è™Ÿ
    if _cell_notes: print("\n** \U0001F4DD åŸ·è¡Œè¨»è¨˜: **"); [print(f"- {note}") for note in _cell_notes] # ä¿®æ­£å†’è™Ÿ
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F è­¦å‘Šè¨Šæ¯: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']] # ä¿®æ­£å†’è™Ÿ
    if _tracking_record.get('error'): print(f"\n** \u274C éŒ¯èª¤è¨Šæ¯: **\n** {_tracking_record['error']} **") # ä¿®æ­£å†’è™Ÿ

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback éé•·ï¼Œå·²æˆªæ–·)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" è©³ç´°éŒ¯èª¤è¿½è¹¤ (Traceback) ")))

    print("\n** \U0001F4CA è¼¸å‡º / æª¢æŸ¥çµæœæ‘˜è¦: **") # ä¿®æ­£å†’è™Ÿ
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    # å¯ä»¥é¸æ“‡æ€§ç§»é™¤ data_check_results å’Œ merged_column_checks ä»¥ç°¡åŒ–é ‚å±¤è¼¸å‡º
    # tracked_outputs.pop('data_check_results', None)
    # tracked_outputs.pop('merged_nan_checks', None) # æ³¨æ„éµåæ›´æ–°
    if not tracked_outputs and _cell_status not in ["å¤±æ•—", "å·²è·³é", "æœªå®Œæˆ"]: print("- æ­¤å„²å­˜æ ¼ç„¡æ˜ç¢ºçš„è¼¸å‡ºæ‘˜è¦è¨˜éŒ„ã€‚")
    elif not tracked_outputs: info_text = {"å¤±æ•—": "å› åŸ·è¡Œå¤±æ•—ï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "å·²è·³é": "å„²å­˜æ ¼å·²è·³éï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚", "æœªå®Œæˆ": "å„²å­˜æ ¼æœªå®Œæˆï¼Œç„¡è¼¸å‡ºæ‘˜è¦ã€‚"}.get(_cell_status, "è¼¸å‡ºæ‘˜è¦ä¸å¯ç”¨ã€‚"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- æ¸…ç†å±€éƒ¨è®Šæ•¸ ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        '_PANDAS_AVAILABLE_CD', '_IPYTHON_AVAILABLE_CD', 'tracker_data', 'num_records',
        'records', 'valid_records', 'ignored_count', 'warn_msg', 'info_msg', 'summary_cols',
        'processed_data', 'record_data', 'col', 'error_val', 'df_summary', 'display_columns_map',
        'col_key', 'df_display', 'highlight_status_cd', 'style', 'status_icon', 'error_summary',
        'is_error', 'is_warning', 'styled_df', 'style_err', 'warnings_found', 'errors_found',
        'index', 'row', 'original_record', 'original_warnings', 'warning', 'traceback_info',
        'display_err', 'e_summary', '_data_variables_to_check', 'data_check_results',
        'var_name', 'expected_type', 'var_state', 'var_value', 'actual_type', 'is_correct_type',
        'type_msg', 'is_empty', 'shape_or_len', 'e_preview', 'preview_err_msg',
        'merged_nan_check_results', 'key_cols_for_cell8', 'col_name', 'col_status', 'non_na_count',
        'nan_counts', 'nan_counts_dict', 'all_nan_cols', 'e_nan', 'nan_err_msg',
        'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local', 'tz_obj',
        'tracker_warn_msg', 'time_warn_msg', 'tracked_outputs', 'traceback_content',
        'max_traceback_lines', 'traceback_lines', 'traceback_to_display', 'failed_libs' # æ·»åŠ æ¸…ç†
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally å€å¡Šå®Œæˆ ---")
    except NameError: print(f"{_cell_identifier} finally å€å¡Šå®Œæˆ (è¨˜éŒ„å™¨ä¸å¯ç”¨)ã€‚")

# ==================================================
# é å°¾è¨»è§£ (v1.1) - å¿«é€Ÿå›é¡§æ¨™é ­ä¿¡æ¯ (è¨»è§£æœ¬èº«ä»å»ºè­° ASCII)
# --------------------------------------------------
# @title Cell_Debug_Consolidated: ç¶œåˆé™¤éŒ¯è³‡è¨Š (å¢å¼·ç‰ˆ)
# åŠŸèƒ½: æ•´åˆé¡¯ç¤º EXECUTION_TRACKER æ‘˜è¦ã€é—œéµæ•¸æ“šè®Šæ•¸ç‹€æ…‹èˆ‡é è¦½ã€NaN çµ±è¨ˆç­‰ã€‚
# ç‰ˆæœ¬: 1.1
# æ—¥æœŸ: 2025-05-06
# ä¾è³´: ['Cell 1', 'Cell 7' (éš±å¼)]
# è¼¸å…¥: ['global:EXECUTION_TRACKER', 'global:PROJECT_CONFIG', ...]
# è¼¸å‡º: (é¡¯ç¤ºé™¤éŒ¯è³‡è¨Š)
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell_Test_YFinance: Yahoo Finance é€£ç·šèˆ‡æ•¸æ“šç²å–å–®ç¨æ¸¬è©¦
# --------------------------------------------------
# åŠŸèƒ½: å–®ç¨æ¸¬è©¦ yfinance å‡½å¼åº«æ˜¯å¦èƒ½æˆåŠŸé€£ç·šä¸¦ç²å–æŒ‡å®š Ticker çš„æ•¸æ“šã€‚
#       æ—¨åœ¨æ’é™¤å°ˆæ¡ˆä¸­å…¶ä»–è¤‡é›œé‚è¼¯çš„å¹²æ“¾ï¼Œå°ˆæ³¨æ–¼ yfinance æœ¬èº«ã€‚
# ç‰ˆæœ¬: 1.1 (ä¿®æ­£ finally æ¸…ç†éƒ¨åˆ†çš„ NameError)
# æ—¥æœŸ: 2025-05-07
# ä¾è³´: ['yfinance', 'pandas'] (æœƒå˜—è©¦åœ¨æ­¤å„²å­˜æ ¼å…§å°å…¥)
# è¼¸å…¥: ç„¡ (ç›´æ¥åœ¨ç¨‹å¼ç¢¼ä¸­å®šç¾©æ¸¬è©¦ Tickers)
# è¼¸å‡º: (æ‰“å°æ¸¬è©¦çµæœåˆ°å„²å­˜æ ¼è¼¸å‡º)
# --------------------------------------------------
# ==================================================
"""
é€™å€‹å„²å­˜æ ¼ç”¨æ–¼å–®ç¨æ¸¬è©¦ yfinance å‡½å¼åº«çš„æ ¸å¿ƒæ•¸æ“šç²å–åŠŸèƒ½ã€‚
å®ƒæœƒå˜—è©¦ï¼š
1. å°å…¥ yfinance å’Œ pandasã€‚
2. å°é å®šç¾©çš„ Ticker (ä¾‹å¦‚ 'TWD=X', '^VIX', ä»¥åŠä¸€å€‹å¸¸è¦‹è‚¡ç¥¨å¦‚ 'AAPL') åŸ·è¡Œ .history() èª¿ç”¨ã€‚
3. æ‰“å°æ¯å€‹ Ticker çš„ç²å–ç‹€æ…‹ã€è¿”å›æ•¸æ“šçš„é ­éƒ¨ã€å°¾éƒ¨å’Œå½¢ç‹€ã€‚
4. æ•ç²ä¸¦æ‰“å°ä»»ä½•ç™¼ç”Ÿçš„éŒ¯èª¤ã€‚
5. ä¿®æ­£äº†è®Šæ•¸æ¸…ç†éƒ¨åˆ†çš„ NameErrorã€‚
"""

import time
import traceback
import pprint
import sys # å¼•å…¥ sys ä»¥ä¾¿æ‰“å° Python ç‰ˆæœ¬
from datetime import datetime, timedelta

_cell_identifier_test = "Cell_Test_YFinance_v1.1" # æ›´æ–°ç‰ˆæœ¬
_test_start_time = time.time()
_test_status = "è™•ç†ä¸­"
_test_notes = []
_test_warnings = []
_test_error_details = {} # å­˜å„²æ¯å€‹ ticker çš„éŒ¯èª¤

print(f"--- {_cell_identifier_test} é–‹å§‹åŸ·è¡Œ ---")
print(f"Python ç‰ˆæœ¬: {sys.version}")

# --- 1. å˜—è©¦å°å…¥å¿…è¦å‡½å¼åº« ---
_yf_lib = None
_pd_lib = None
try:
    import yfinance as yf
    _yf_lib = yf
    print(f"yfinance å‡½å¼åº«å°å…¥æˆåŠŸã€‚ç‰ˆæœ¬: {yf.__version__}")
    _test_notes.append(f"yfinance v{yf.__version__} å°å…¥æˆåŠŸã€‚")
except ImportError as e_yf:
    print(f"âŒ éŒ¯èª¤ï¼šå°å…¥ yfinance å¤±æ•—: {e_yf}")
    _test_warnings.append(f"å°å…¥ yfinance å¤±æ•—: {e_yf}")
except Exception as e_yf_other:
    print(f"âŒ éŒ¯èª¤ï¼šå°å…¥ yfinance æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e_yf_other}")
    _test_warnings.append(f"å°å…¥ yfinance æ™‚æ„å¤–éŒ¯èª¤: {e_yf_other}")

try:
    import pandas as pd
    _pd_lib = pd
    print(f"pandas å‡½å¼åº«å°å…¥æˆåŠŸã€‚ç‰ˆæœ¬: {pd.__version__}")
    _test_notes.append(f"pandas v{pd.__version__} å°å…¥æˆåŠŸã€‚")
except ImportError as e_pd:
    print(f"âŒ éŒ¯èª¤ï¼šå°å…¥ pandas å¤±æ•—: {e_pd}")
    _test_warnings.append(f"å°å…¥ pandas å¤±æ•—: {e_pd}")
except Exception as e_pd_other:
    print(f"âŒ éŒ¯èª¤ï¼šå°å…¥ pandas æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e_pd_other}")
    _test_warnings.append(f"å°å…¥ pandas æ™‚æ„å¤–éŒ¯èª¤: {e_pd_other}")

if not _yf_lib or not _pd_lib:
    _test_status = "å¤±æ•—"
    print("âŒ ç”±æ–¼æ ¸å¿ƒå‡½å¼åº« (yfinance æˆ– pandas) å°å…¥å¤±æ•—ï¼Œæ¸¬è©¦ç„¡æ³•ç¹¼çºŒã€‚")
    _test_error_details["Setup"] = "æ ¸å¿ƒå‡½å¼åº«å°å…¥å¤±æ•—ã€‚"
else:
    # --- 2. å®šç¾©æ¸¬è©¦åƒæ•¸ ---
    tickers_to_test = {
        "TWD=X": "ç¾å…ƒå…Œæ–°å°å¹£åŒ¯ç‡",
        "^VIX": "æ³¢å‹•ç‡æŒ‡æ•¸ VIX",
        "AAPL": "è˜‹æœå…¬å¸è‚¡åƒ¹ (æ¸¬è©¦å¸¸è¦‹è‚¡ç¥¨)",
        "NONEXISTENT_TICKER_XYZ123": "ä¸€å€‹ä¸å­˜åœ¨çš„ Ticker (æ¸¬è©¦éŒ¯èª¤è™•ç†)"
    }
    start_date_test = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
    interval_test = '1d'

    print(f"\næº–å‚™æ¸¬è©¦ä»¥ä¸‹ Tickers (å¾ {start_date_test} é–‹å§‹ï¼Œé–“éš” {interval_test}):")
    for ticker, desc in tickers_to_test.items():
        print(f"  - {ticker} ({desc})")
    print("-" * 50)

    # --- 3. åŸ·è¡Œæ¸¬è©¦ ---
    successful_fetches = 0
    # åˆå§‹åŒ– history_data ä»¥é¿å… NameError
    history_data = None
    ticker_obj = None
    description = None # åˆå§‹åŒ– description
    ticker_symbol = None # åˆå§‹åŒ– ticker_symbol

    for ticker_symbol_loop, description_loop in tickers_to_test.items(): # ä½¿ç”¨ä¸åŒçš„è®Šæ•¸åé¿å…è¦†è“‹
        ticker_symbol = ticker_symbol_loop # åœ¨å¾ªç’°å…§éƒ¨è³¦å€¼
        description = description_loop     # åœ¨å¾ªç’°å…§éƒ¨è³¦å€¼
        print(f"\n>>> æ­£åœ¨æ¸¬è©¦ Ticker: {ticker_symbol} ({description})")
        _test_notes.append(f"é–‹å§‹æ¸¬è©¦ Ticker: {ticker_symbol}")
        try:
            ticker_obj = _yf_lib.Ticker(ticker_symbol)
            print(f"    èª¿ç”¨ {ticker_symbol}.history(start='{start_date_test}', interval='{interval_test}')...")
            history_data = ticker_obj.history(start=start_date_test, interval=interval_test)

            if not history_data.empty:
                print(f"    âœ… æˆåŠŸç²å– {ticker_symbol} çš„æ•¸æ“šã€‚")
                print(f"       ç¶­åº¦: {history_data.shape}")
                print(f"       æ¬„ä½: {history_data.columns.tolist()}")
                print(f"       ç´¢å¼•èµ·å§‹: {history_data.index.min()}, ç´¢å¼•çµæŸ: {history_data.index.max()}")
                print("       æ•¸æ“šé è¦½ (é ­éƒ¨ 3 è¡Œ):")
                print(history_data.head(3).to_string())
                print("       æ•¸æ“šé è¦½ (å°¾éƒ¨ 3 è¡Œ):")
                print(history_data.tail(3).to_string())
                _test_notes.append(f"æˆåŠŸç²å– {ticker_symbol} ({history_data.shape})")
                successful_fetches +=1
            elif ticker_symbol == "NONEXISTENT_TICKER_XYZ123":
                print(f"    ğŸ¤” {ticker_symbol} (é æœŸä¸å­˜åœ¨çš„Ticker) è¿”å›ç©º DataFrameï¼Œç¬¦åˆé æœŸã€‚")
                _test_notes.append(f"{ticker_symbol} è¿”å›ç©º DataFrameï¼Œç¬¦åˆé æœŸã€‚")
            else:
                print(f"    âš ï¸ è­¦å‘Šï¼šç²å– {ticker_symbol} æ•¸æ“šæˆåŠŸï¼Œä½†è¿”å›çš„ DataFrame ç‚ºç©ºã€‚")
                _test_warnings.append(f"ç²å– {ticker_symbol} æˆåŠŸä½† DataFrame ç‚ºç©ºã€‚")
                try:
                    info_data = ticker_obj.info
                    print(f"       {ticker_symbol} .info() è¿”å›:")
                    pprint.pprint(info_data, depth=2)
                    if not info_data or (isinstance(info_data, dict) and info_data.get('regularMarketPrice') is None and info_data.get('previousClose') is None and not info_data.get('shortName')):
                         _test_warnings.append(f"{ticker_symbol} .info çœ‹ä¼¼ç„¡æ•ˆã€‚")
                except Exception as e_info_detail:
                    print(f"       ç²å– {ticker_symbol} .info() æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {e_info_detail}")
                    _test_warnings.append(f"ç²å– {ticker_symbol} .info() å¤±æ•—: {e_info_detail}")

        except Exception as e:
            error_type = e.__class__.__name__
            error_message = str(e)
            print(f"    âŒ éŒ¯èª¤ï¼šç²å– {ticker_symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {error_type}: {error_message}")
            _test_warnings.append(f"ç²å– {ticker_symbol} å¤±æ•—: {error_type}: {error_message}")
            _test_error_details[ticker_symbol] = f"{error_type}: {error_message}"

    if successful_fetches > 0 and not _test_error_details:
         _test_status = "æˆåŠŸ"
    elif successful_fetches > 0 and _test_error_details:
         _test_status = "æˆåŠŸ (æœ‰éƒ¨åˆ†éŒ¯èª¤)"
    elif not _test_error_details and any("è¿”å›ç©º DataFrame" in note for note in _test_notes if "NONEXISTENT_TICKER" not in note): # ä¿®æ­£: æª¢æŸ¥ _test_notes
         _test_status = "æˆåŠŸ (æœ‰è­¦å‘Š)"
    else:
         _test_status = "å¤±æ•—"

# --- 4. ç¸½çµæ¸¬è©¦çµæœ ---
print("\n" + "="*50)
print(f"--- {_cell_identifier_test} åŸ·è¡Œå®Œç•¢ ---")
_test_duration = time.time() - _test_start_time
print(f"æ¸¬è©¦ç¸½è€—æ™‚: {_test_duration:.2f} ç§’")
print(f"æœ€çµ‚æ¸¬è©¦ç‹€æ…‹: {_test_status}")

if _test_notes:
    print("\nåŸ·è¡Œè¨»è¨˜:")
    for note in _test_notes:
        print(f"  - {note}")
if _test_warnings:
    print("\nè­¦å‘Šè¨Šæ¯:")
    for warning in _test_warnings:
        print(f"  - {warning}")
if _test_error_details:
    print("\nè©³ç´°éŒ¯èª¤ (é‡å°ç‰¹å®š Ticker):")
    for ticker, error_str in _test_error_details.items(): # ä¿®æ­£: ä½¿ç”¨ _test_error_details.items()
        print(f"  - Ticker '{ticker}': {error_str}")
elif _test_status == "å¤±æ•—" and "Setup" in _test_error_details :
     pass
elif _test_status != "å¤±æ•—":
    print("\nâœ… æ‰€æœ‰ Ticker (é™¤é æœŸå¤±æ•—çš„å¤–) å‡æœªå ±å‘Šç›´æ¥çš„ç²å–éŒ¯èª¤ã€‚")
print("="*50)

# --- 5. æ¸…ç†å±€éƒ¨è®Šæ•¸ (ä¿®æ­£ NameError) ---
_vars_to_clean_test = [
    '_cell_identifier_test', '_test_start_time', '_test_status', '_test_notes',
    '_test_warnings', '_test_error_details', '_yf_lib', '_pd_lib',
    'tickers_to_test', 'start_date_test', 'interval_test', 'successful_fetches',
    'ticker_symbol', 'description', 'ticker_obj', 'history_data',
    'e_yf', 'e_pd', 'e', 'error_type', 'error_message', 'info_data', 'e_info_detail',
    'e_yf_other', 'e_pd_other', 'ticker_symbol_loop', 'description_loop',
    '_test_duration', 'ticker', 'desc', 'error_str', 'note', 'warning' # æ–°å¢æ¸…ç†è¿­ä»£è®Šæ•¸
]

for _var_to_clean in _vars_to_clean_test:
    if _var_to_clean in locals():
        try:
            del locals()[_var_to_clean]
        except KeyError:
            pass # è®Šæ•¸å¯èƒ½åœ¨æŸäº›åŸ·è¡Œè·¯å¾‘ä¸‹æœªè¢«è³¦å€¼ï¼Œå¿½ç•¥ KeyError

