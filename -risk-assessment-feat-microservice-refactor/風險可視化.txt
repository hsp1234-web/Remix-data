# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 1: 專案初始化與全局設定 (初始化專用)
# --------------------------------------------------
# 功能: 初始化專案，安裝並導入必要函式庫，定義全局配置和追蹤器。必須是第一個執行的儲存格。
# 版本: 3.4.3-zh-fc (對應準則 v3.4，中文註解版，修正 userdata 檢查與 finally logger)
# 日期: 2025-05-07
# 依賴: None (僅依賴 Colab 環境與可能設定的 Secrets)
# 輸入: ['Colab Secrets: YOUR_API_KEY_NAME_1', 'Colab Secrets: YOUR_API_KEY_NAME_2'] (範例，請根據實際使用的 API Key 修改)
# 輸出: ['global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger',
#        'global:libs_loaded', 'global:target_tz', 'global:pd', 'global:np', ...] (若導入成功)
# --------------------------------------------------
# ==================================================
"""
初始化 Google Colab 環境以進行專案。

此儲存格執行以下步驟：
1.  導入標準函式庫。
2.  檢查 logging 模組，獲取 logger 實例。
3.  安裝必要的第三方函式庫。
4.  嘗試導入核心函式庫，並記錄狀態到 `libs_loaded`：
    - 特別處理 `google.colab`，嘗試導入 `userdata` 並記錄其狀態。
5.  定義並初始化 `PROJECT_CONFIG` 和 `EXECUTION_TRACKER`。
6.  配置 logger。
7.  設定時區，並將時區物件存儲到 `target_tz` 和 `PROJECT_CONFIG`。
8.  嘗試從 Colab Secrets 讀取 API 金鑰（如果 `userdata` 可用）。
9.  打印最終初始化信息。
10. `finally` 區塊報告執行狀態並更新 `EXECUTION_TRACKER`，增強 logger 使用的穩健性。

設計說明：
* 遵循 v3.4 設計準則。
* `libs_loaded` 更明確區分 `google.colab.userdata` 的導入狀態。
* `finally` 區塊中對 logger 的使用增加了更嚴格的檢查。

主要輸出 / 狀態變更：
* `global:PROJECT_CONFIG`, `global:EXECUTION_TRACKER`, `global:logger`
* `global:libs_loaded` (dict): 包含如 `yfinance`, `pandas`, `google.colab.userdata` 等的導入狀態。
* `global:target_tz` (datetime.tzinfo): 專案時區物件。
* `global:colab_userdata` (module or None): 若導入成功，則為 userdata 模組。
* 其他導入函式庫的別名。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import sys
import os
import subprocess
from datetime import datetime, timezone, timedelta
import importlib
import logging

# --- 1. 檢查 logging 導入與 logger 初始化 ---
_logging_ok = False
logger = None # 確保 logger 在任何情況下都有定義
try:
    _ = logging.INFO
    logger = logging.getLogger(__name__)
    _logging_ok = True
    print("[初始化檢查] logging 模組已成功導入，logger 已獲取。")
except NameError:
    print("❌ 嚴重錯誤：logging 模組未能正確導入！後續日誌功能可能受影響。")
except Exception as e_log_check:
    print(f"❌ 嚴重錯誤：初始化 logging 或獲取 logger 時發生意外錯誤: {e_log_check}")

# --- 2. 全局變數早期初始化 ---
libs_loaded = {}
target_tz = None
PROJECT_CONFIG = {}
EXECUTION_TRACKER = {}
colab_userdata = None # 用於存儲导入的 userdata 模塊
ALPHA_VANTAGE_API_KEY_VALUE = None
FRED_API_KEY_VALUE = None

# --- 3. 儲存格標識符 ---
_cell_identifier = "Cell 1: 專案初始化與全局設定 (v3.4.3)" # 更新版本號

# --- 4. 狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_error = None
_cell_traceback = None
_cell_notes = []
_cell_warnings = []
_cell_inputs = {'secrets_to_try': ['ALPHA_VANTAGE_API_KEY', 'FRED_API_KEY']}
_cell_outputs = {}
_cell_generated_files = []

# --- 5. 主要執行邏輯 ---
try:
    # --- 5.1. 安裝必要的第三方函式庫 ---
    print(f"\n--- {_cell_identifier}: 開始檢查/安裝必要的第三方函式庫 ---")
    _cell_notes.append("開始函式庫安裝流程。")
    _required_libs_install = [
        "pandas", "numpy", "requests", "requests-cache", "yfinance",
        "fredapi", "tenacity", "plotly", "ipywidgets", "pytz", "openpyxl"
    ]
    _install_command = [sys.executable, "-m", "pip", "install", "-q"] + _required_libs_install
    _install_log_details = []
    _pip_install_success = False
    try:
        print(f"執行安裝命令: {' '.join(_install_command)}")
        result = subprocess.run(
            _install_command, check=False, capture_output=True, text=True, encoding='utf-8'
        )
        if result.returncode == 0:
            _install_log_details.append(f"pip install 命令成功執行。\n標準輸出:\n{result.stdout[:1000]}...")
            print("必要的第三方函式庫已安裝或已是最新版本。")
            _pip_install_success = True
        else:
            _install_error_msg = f"pip install 命令失敗。返回碼: {result.returncode}"
            _install_log_details.append(f"錯誤: {_install_error_msg}\n標準錯誤輸出:\n{result.stderr}")
            print(f"\n❌ 錯誤：安裝函式庫時失敗！\n{_install_error_msg}\n錯誤詳情:\n{result.stderr}")
            _cell_warnings.append(f"部分或全部函式庫安裝可能失敗: {_install_error_msg}")
    except FileNotFoundError:
        _install_error_msg = f"找不到 pip 命令 ({sys.executable} -m pip)。請檢查 Python 環境。"
        _install_log_details.append(f"錯誤: {_install_error_msg}")
        print(f"\n❌ 錯誤：{_install_error_msg}")
        _cell_warnings.append(f"函式庫安裝失敗: {_install_error_msg}")
    except Exception as e_install:
        _install_error_msg = f"安裝函式庫時發生意外錯誤: {e_install.__class__.__name__}: {e_install}"
        _install_log_details.append(f"錯誤: {_install_error_msg}")
        print(f"\n❌ 錯誤：{_install_error_msg}")
        _cell_warnings.append(f"函式庫安裝失敗: {_install_error_msg}")
    _cell_notes.extend(_install_log_details)
    _cell_outputs['pip_install_successful'] = _pip_install_success
    print(f"--- {_cell_identifier}: 函式庫安裝嘗試結束 ---")

    # --- 5.2. 嘗試導入專案核心函式庫並記錄狀態 ---
    print(f"\n--- {_cell_identifier}: 開始導入專案核心函式庫並記錄狀態 ---")
    _cell_notes.append("開始核心函式庫導入流程。")
    _libs_to_import = {
        "pandas": "pd", "numpy": "np", "requests": "requests",
        "requests_cache": "requests_cache", "yfinance": "yf", "fredapi": "fredapi",
        "tenacity": "tenacity", "plotly": "plotly", "plotly.graph_objects": "go",
        "ipywidgets": "widgets", "pytz": "pytz", "openpyxl": "openpyxl",
        "google.colab": "colab" # 嘗試導入 google.colab 模組本身
    }

    # 首先單獨處理 userdata 的導入，因為它更關鍵
    try:
        from google.colab import userdata as colab_userdata_module
        colab_userdata = colab_userdata_module # 賦值給全局變數
        print(f"成功導入 google.colab.userdata。")
        libs_loaded['google.colab.userdata'] = True
    except ImportError:
        print("警告：導入 google.colab.userdata 失敗。Secrets 功能將不可用。")
        libs_loaded['google.colab.userdata'] = False
        _cell_warnings.append("導入 google.colab.userdata 失敗。")
    except Exception as e_userdata_other:
        print(f"警告：導入 google.colab.userdata 時發生意外錯誤：{e_userdata_other}。")
        libs_loaded['google.colab.userdata'] = False
        _cell_warnings.append(f"導入 google.colab.userdata 時意外錯誤: {e_userdata_other}")


    for lib_name, alias in _libs_to_import.items():
        if lib_name == "google.colab" and libs_loaded.get('google.colab.userdata'):
            # 如果 userdata 已成功導入，我們可能仍想嘗試導入 google.colab 本身作為一個模組
            # 但要避免覆蓋已經成功的 userdata 狀態
            pass # 下面的通用邏輯會處理 google.colab 模組的導入

        try:
            if '.' in lib_name:
                module_parts = lib_name.split('.')
                imported_module = importlib.import_module(module_parts[0])
                for part in module_parts[1:]:
                    imported_module = getattr(imported_module, part)
                globals()[alias] = imported_module
            else:
                globals()[alias] = importlib.import_module(lib_name)

            print(f"成功導入 {lib_name} 並命名為 {alias}。")
            libs_loaded[lib_name] = True # 記錄模組本身的導入狀態
            if hasattr(globals()[alias], '__version__'):
                _cell_notes.append(f"函式庫 {alias} (來自 {lib_name}) 版本: {globals()[alias].__version__}")
        except ImportError as e_import:
            print(f"警告：導入函式庫 {lib_name} (別名 {alias}) 失敗：{e_import}。")
            globals()[alias] = None
            libs_loaded[lib_name] = False # 標記模組導入失敗
            _cell_warnings.append(f"導入函式庫 {lib_name} 失敗。")
        except Exception as e_import_other:
            print(f"警告：導入函式庫 {lib_name} (別名 {alias}) 時發生非預期錯誤：{e_import_other}。")
            globals()[alias] = None
            libs_loaded[lib_name] = False
            _cell_warnings.append(f"導入函式庫 {lib_name} 時發生非預期錯誤: {e_import_other}")

    _cell_outputs['libs_loaded_status'] = libs_loaded.copy()
    print(f"\n[除錯] {_cell_identifier}: libs_loaded 狀態: {libs_loaded}")
    _cell_notes.append(f"核心函式庫導入嘗試結束。狀態: {libs_loaded}")
    print(f"--- {_cell_identifier}: 核心函式庫導入嘗試結束 ---")

    # --- 5.3. 初始化日誌記錄器 (如果之前失敗則重試) ---
    if not _logging_ok and logger is not None: # 只有在 logger 實例存在但未配置時才重試
        print(f"\n--- {_cell_identifier}: 嘗試重新配置日誌記錄器 ---")
        try: # 重新配置
            default_log_level_config_retry = logging.INFO
            logger.setLevel(default_log_level_config_retry)
            if logger.hasHandlers(): logger.handlers.clear()
            log_handler_retry = logging.StreamHandler(sys.stdout)
            log_formatter_retry = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
            log_handler_retry.setFormatter(log_formatter_retry)
            logger.addHandler(log_handler_retry)
            _logging_ok = True # 標記為已配置
            _log_level_name_retry = logging.getLevelName(logger.level)
            print(f"日誌記錄器已重新配置。級別：{_log_level_name_retry}。")
            logger.info(f"{_cell_identifier} - 日誌記錄器重新配置完成。")
            _cell_notes.append(f"記錄器已重新配置，級別為 {_log_level_name_retry}。")
        except Exception as e_log_reconfig:
            print(f"❌ 錯誤：重新配置 logger 失敗: {e_log_reconfig}")
            _cell_warnings.append("Logger 重新配置失敗。")
    elif _logging_ok and logger is not None: # 初次成功
        default_log_level_config = PROJECT_CONFIG.get('log_level', logging.INFO) # 從 PROJECT_CONFIG 獲取
        logger.setLevel(default_log_level_config)
        if logger.hasHandlers(): logger.handlers.clear(); print("已清除舊的日誌 handlers (若有)。")
        log_handler = logging.StreamHandler(sys.stdout)
        log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        log_handler.setFormatter(log_formatter)
        logger.addHandler(log_handler)
        _log_level_name = logging.getLevelName(logger.level)
        print(f"日誌記錄器已配置。級別：{_log_level_name}。")
        logger.info(f"{_cell_identifier} - 日誌記錄器配置完成。")
        _cell_notes.append(f"記錄器已配置，級別為 {_log_level_name}。")
    else: # logger is None or _logging_ok is False from the start
        print("警告: Logger 未能成功初始化或配置，日誌輸出可能不完整。")
        _cell_notes.append("Logger 未能成功初始化或配置。")


    # --- 5.4. 定義全局配置 PROJECT_CONFIG ---
    print(f"\n--- {_cell_identifier}: 定義全局配置 PROJECT_CONFIG ---")
    PROJECT_CONFIG.update({
      'project_name': '通用專案範本', 'project_version': '1.0.0', 'guideline_version': '3.4.3-zh-fc',
      'log_level': logger.level if _logging_ok and logger else logging.WARNING,
      'timezone': 'Asia/Taipei', 'output_dir': '/content/project_output',
      'cache_dir': '/content/project_cache', 'cache_name': 'api_request_cache',
      'cache_expire_after': timedelta(hours=1),
      'api_keys_info': {
          'alpha_vantage': {'secret_name': 'ALPHA_VANTAGE_API_KEY', 'description': 'Alpha Vantage API Key'},
          'fred': {'secret_name': 'FRED_API_KEY', 'description': 'FRED API Key'}
      },
      'api_access_status': {},
      'rate_limit_handler': {
            'wait_fixed_seconds': 10, 'stop_after_attempt': 3,
            'wait_fixed_seconds_yfinance': 30, 'stop_after_attempt_yfinance': 3
      },
      'user_agent': 'MyProject/1.0 (Colab; contact@example.com)',
    })
    _cell_notes.append("PROJECT_CONFIG 已定義 (不含敏感值)。")
    print("PROJECT_CONFIG 定義完成。")

    # --- 5.5. 初始化全局執行追蹤器 ---
    print(f"\n--- {_cell_identifier}: 初始化全局執行追蹤器 EXECUTION_TRACKER ---")
    EXECUTION_TRACKER.clear()
    print("EXECUTION_TRACKER 初始化為空字典。")
    if _logging_ok and logger: logger.info(f"{_cell_identifier} - EXECUTION_TRACKER 初始化完成。")
    _cell_notes.append("EXECUTION_TRACKER 初始化為空字典。")

    # --- 5.6. 設定時區 ---
    print(f"\n--- {_cell_identifier}: 設定時區 ---")
    _tz_name_config = PROJECT_CONFIG.get('timezone', 'Asia/Taipei')
    _tz_info_obj = None; _tz_source_log = "未知"
    try:
        from zoneinfo import ZoneInfo, ZoneInfoNotFoundError
        try: _tz_info_obj = ZoneInfo(_tz_name_config); _tz_source_log = "zoneinfo"; print(f"成功使用 zoneinfo 加載時區 '{_tz_name_config}'。")
        except ZoneInfoNotFoundError: print(f"zoneinfo 找不到時區 '{_tz_name_config}'。嘗試 pytz..."); raise ImportError
    except ImportError:
        if libs_loaded.get('pytz') and 'pytz' in globals() and globals()['pytz']:
            pytz_module = globals()['pytz']
            try: _tz_info_obj = pytz_module.timezone(_tz_name_config); _tz_source_log = "pytz"; print(f"成功使用 pytz 加載時區 '{_tz_name_config}'。")
            except pytz_module.UnknownTimeZoneError: _warn_msg_tz = f"pytz 找不到時區 '{_tz_name_config}'。回退到 UTC+8。"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (回退)"; _tz_source_log = "固定偏移"
            except Exception as e_pytz: _warn_msg_tz = f"使用 pytz 加載時區 '{_tz_name_config}' 時出錯：{e_pytz}。回退到 UTC+8。"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (回退)"; _tz_source_log = "錯誤時固定偏移"
        else: _warn_msg_tz = "未找到 zoneinfo 且 pytz 未成功導入。回退到 UTC+8。"; print(_warn_msg_tz); _cell_warnings.append(_warn_msg_tz); _tz_info_obj = timezone(timedelta(hours=8)); _tz_name_config = "UTC+8 (回退)"; _tz_source_log = "固定偏移 (pytz缺失)"
    target_tz = _tz_info_obj
    PROJECT_CONFIG['_tz_info_obj'] = target_tz; PROJECT_CONFIG['_tz_name'] = _tz_name_config; PROJECT_CONFIG['_tz_source'] = _tz_source_log
    if _logging_ok and logger: logger.info(f"最終使用的時區：{_tz_name_config} (來源：{_tz_source_log})")
    _cell_notes.append(f"時區設定為 {_tz_name_config} (透過 {_tz_source_log})。")
    print(f"[除錯] {_cell_identifier}: target_tz 狀態: {target_tz} (類型: {type(target_tz)})")
    print(f"--- {_cell_identifier}: 時區處理完成 ---")

    # --- 5.7. 嘗試從 Colab Secrets 讀取 API 金鑰 ---
    print(f"\n--- {_cell_identifier}: 嘗試從 Colab Secrets 讀取 API 金鑰 (僅記錄狀態) ---")
    _api_keys_info_config = PROJECT_CONFIG.get('api_keys_info', {})
    _api_access_status_log = {}
    if 'colab_userdata' in globals() and colab_userdata is not None: # 主要檢查 colab_userdata 是否有效
        _cell_notes.append("正在嘗試讀取 Colab Secrets (僅更新狀態)...")
        for api_name, key_info in _api_keys_info_config.items():
            secret_name_config = key_info.get('secret_name')
            if not secret_name_config: _warn_msg_secret = f"警告：PROJECT_CONFIG 中 API '{api_name}' 的 'secret_name' 未定義。"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "失敗 (缺少配置)"; continue
            try:
                key_value_temp = colab_userdata.get(secret_name_config)
                if key_value_temp:
                    _api_access_status_log[api_name] = "已獲取 (模擬)"
                    if api_name == 'alpha_vantage': ALPHA_VANTAGE_API_KEY_VALUE = key_value_temp
                    elif api_name == 'fred': FRED_API_KEY_VALUE = key_value_temp
                    print(f"模擬從 Colab Secrets 讀取 '{secret_name_config}' (用於 {api_name})。")
                    if _logging_ok and logger: logger.info(f"模擬讀取 {api_name} 的 API 金鑰。")
                else: _warn_msg_secret = f"警告：在 Colab Secrets 中找到 '{secret_name_config}' 但其值為空。"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "值為空"
            except colab_userdata.SecretNotFoundError: _warn_msg_secret = f"警告：未找到 Secret '{secret_name_config}' (用於 {api_name})。"; print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = "失敗 (未找到)"
            except Exception as e_secret: _warn_msg_secret = f"讀取 Secret '{secret_name_config}' 時出錯：{e_secret}"; print(f"錯誤：{_warn_msg_secret}"); _cell_warnings.append(_warn_msg_secret); _api_access_status_log[api_name] = f"讀取錯誤 ({e_secret.__class__.__name__})"
        _cell_notes.append("Colab Secrets 讀取嘗試完成。")
    else:
        _warn_msg_secret = "警告：google.colab.userdata 無法使用。無法讀取 API 金鑰。"
        print(_warn_msg_secret); _cell_warnings.append(_warn_msg_secret)
        if _logging_ok and logger: logger.warning(_warn_msg_secret)
        for api_name_cfg in _api_keys_info_config.keys(): _api_access_status_log[api_name_cfg] = "未嘗試 (userdata不可用)"
    PROJECT_CONFIG['api_access_status'] = _api_access_status_log
    print(f"--- {_cell_identifier}: API 金鑰讀取嘗試結束 ---")

    # --- 5.8. 打印最終初始化信息 ---
    print("\n" + "="*80); _project_name_log = PROJECT_CONFIG.get('project_name', '未知專案'); _project_version_log = PROJECT_CONFIG.get('project_version', '未知版本')
    print(f"** 專案 '{_project_name_log}' (v{_project_version_log}) 初始化 ({_cell_identifier}) 完成 **")
    if _logging_ok and logger: print(f"日誌級別：{logging.getLevelName(logger.level)}")
    else: print("日誌級別：未知 (Logger 未初始化/配置)")
    print(f"時區：{PROJECT_CONFIG.get('_tz_name', '未知')} (來源：{PROJECT_CONFIG.get('_tz_source', '未知')})")
    print("\n** 函式庫導入狀態 (libs_loaded)：**"); pprint.pprint(libs_loaded, indent=2, width=70)
    print("\n** API 金鑰讀取狀態 (PROJECT_CONFIG['api_access_status'])：**"); pprint.pprint(PROJECT_CONFIG.get('api_access_status', {}), indent=2, width=70)
    _config_for_print_final = {k: v for k, v in PROJECT_CONFIG.items() if k != '_tz_info_obj'}; print("\n** 最終全局配置 (PROJECT_CONFIG) 概覽 (不含敏感值)：**"); pprint.pprint(_config_for_print_final, indent=2, width=70, sort_dicts=False)
    print("\n** 執行追蹤器 (EXECUTION_TRACKER) 目前為空。 **")
    _failed_libs_final = [lib for lib, loaded_status in libs_loaded.items() if not loaded_status and lib not in ['google.colab', 'google.colab.userdata']]
    if _failed_libs_final: _warn_msg_libs = f"** 警告：** 以下核心函式庫未能成功導入：{', '.join(_failed_libs_final)}。"; print(f"\n{_warn_msg_libs}"); _cell_warnings.append(_warn_msg_libs)
    _key_issues_final = [f"{api} ({status})" for api, status in PROJECT_CONFIG.get('api_access_status', {}).items() if "已獲取" not in status and "模擬" not in status];
    if _key_issues_final: _warn_msg_keys = f"** 警告：** 以下 API 的金鑰存在問題或未配置：{', '.join(_key_issues_final)}。"; print(f"\n{_warn_msg_keys}"); _cell_warnings.append(_warn_msg_keys)
    print("="*80)

    if _cell_status == "處理中": _cell_status = "成功"; _cell_notes.append("初始化成功。")
    if _logging_ok and logger: logger.info(f"{_cell_identifier} 初始化過程成功完成。最終狀態: {_cell_status}")

except Exception as e_outer:
    if _cell_status != "失敗": _cell_status = "失敗"; _cell_error = f"嚴重錯誤：{_cell_identifier} 初始化頂層錯誤：{e_outer.__class__.__name__}: {e_outer}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try:
        if _logging_ok and logger: logger.critical(_cell_error, exc_info=True)
        else: print(f"嚴重錯誤（Logger {_logging_ok}, {logger}）：{_cell_identifier} 初始化：{_cell_error}\n{_cell_traceback}")
    except: print(f"記錄錯誤時也發生錯誤。原始錯誤：{_cell_error}\n原始 Traceback：{_cell_traceback}")
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict): PROJECT_CONFIG = {}
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER = {}
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict): libs_loaded = {}
    if 'target_tz' not in globals() or target_tz is None : target_tz = timezone(timedelta(hours=8))

finally:
    _cell_end_time = time.time(); _cell_duration = _cell_end_time - _cell_start_time
    _final_status_text_report = _cell_status
    if _cell_status == "失敗": _final_status_icon_report = "❌"
    elif _cell_status == "處理中": _final_status_icon_report = "⏳"; _final_status_text_report = "未完成"
    elif _cell_warnings: _final_status_icon_report = "⚠️"; _final_status_text_report = "成功（有警告）" if _cell_status == "成功" else _cell_status
    elif _cell_status == "成功": _final_status_icon_report = "✅"
    else: _final_status_icon_report = "❓"
    _current_time_str_report = "無法獲取"
    try:
        _report_tz_info_final = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8)))
        _current_time_str_report = datetime.now(_report_tz_info_final).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception: _current_time_str_report = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
    _cell_outputs['final_libs_loaded_summary'] = {k: ("成功" if v else "失敗") for k,v in libs_loaded.items()}
    _cell_outputs['final_target_tz_repr'] = repr(target_tz)
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon_report, 'status_text': _final_status_text_report,
        'timestamp': _current_time_str_report, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if isinstance(_cell_traceback, str) else "".join(_cell_traceback) if isinstance(_cell_traceback, list) else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs, 'generated_files': _cell_generated_files }
    try:
        if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER = {}
        EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err_final: print(f"錯誤：更新 EXECUTION_TRACKER 時異常：{tracker_update_err_final}")
    print("\n" + "="*80)
    _guideline_version_report = PROJECT_CONFIG.get('guideline_version', '未知')
    print(f"儲存格：{_cell_identifier} (v{_guideline_version_report}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon_report} {_final_status_text_report}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒"); print(f"** 完成時間：** {_current_time_str_report}")
    print("\n** \U0001F527 關鍵配置摘要：**")
    try:
        print(f"  - 專案名稱：{PROJECT_CONFIG.get('project_name', 'N/A')}")
        print(f"  - 日誌級別：{logging.getLevelName(PROJECT_CONFIG.get('log_level', logging.WARNING))}")
        print(f"  - 時區：{PROJECT_CONFIG.get('_tz_name', 'N/A')} (來源：{PROJECT_CONFIG.get('_tz_source', 'N/A')})")
        _api_status_summary_report = ", ".join([f"{api} ({status})" for api, status in PROJECT_CONFIG.get('api_access_status', {}).items()])
        print(f"  - API 金鑰狀態：{_api_status_summary_report or 'N/A'}")
    except Exception as config_print_err_final: print(f"  - (打印配置摘要時出錯：{config_print_err_final})")
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息：**"); pprint.pprint(_tracking_record['warnings'], indent=2, width=70)
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息：**\n{_tracking_record['error']}")
    if _tracking_record.get('traceback'): _tb_content = _tracking_record.get('traceback'); print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20 + f"\n<pre>{_tb_content}</pre>\n" + "-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))
    print("\n** \U0001F4CA 輸出 / 狀態變更：**"); pprint.pprint(_tracking_record.get('outputs', {}), indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")
    _vars_to_clean_final = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status', '_cell_error', '_cell_traceback',
        '_cell_notes', '_cell_warnings', '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon_report', '_final_status_text_report', '_current_time_str_report', '_tracking_record',
        '_report_tz_info_final', '_required_libs_install', '_install_command', '_install_log_details',
        '_pip_install_success', '_install_error_msg', 'result', '_libs_to_import', 'lib_name', 'alias',
        'module_parts', 'imported_module', 'part', 'e_import', 'e_import_other', '_logging_ok',
        'default_log_level_config', 'log_handler', 'log_formatter', '_log_level_name', '_tz_name_config',
        '_tz_info_obj', '_tz_source_log', 'pytz_module', 'ZoneInfo', 'ZoneInfoNotFoundError', '_warn_msg_tz',
        'e_pytz', '_api_keys_info_config', '_api_access_status_log', 'api_name', 'key_info',
        'secret_name_config', 'key_value_temp', '_warn_msg_secret', 'e_secret', '_project_name_log',
        '_project_version_log', '_config_for_print_final', '_failed_libs_final', '_warn_msg_libs',
        '_key_issues_final', '_warn_msg_keys', 'e_outer', 'e_log_check', 'e_log_retry', 'e_install',
        'time_err_report', 'time_err_local_report', '_warn_msg_tracker', 'tracker_update_err_final',
        '_err_msg_tracker', '_guideline_version_report', '_api_status_summary_report', 'config_print_err_final',
        '_tb_content', 'ALPHA_VANTAGE_API_KEY_VALUE', 'FRED_API_KEY_VALUE', 'colab_userdata_module'
    ]
    # 保留核心全局變數，其餘嘗試清理
    _core_globals_to_keep = ['PROJECT_CONFIG', 'EXECUTION_TRACKER', 'logger', 'libs_loaded', 'target_tz', 'pd', 'yf', 'requests', 'requests_cache', 'fredapi', 'tenacity', 'go', 'widgets', 'pytz', 'openpyxl', 'np', 'colab_userdata']
    for _var_final in _vars_to_clean_final:
        if _var_final in locals():
            try: del locals()[_var_final]
            except KeyError: pass
        elif _var_final in globals() and _var_final not in _core_globals_to_keep:
            try: del globals()[_var_final]
            except KeyError: pass
    try:
        if _logging_ok and logger and logger.hasHandlers(): logger.info(f"{_cell_identifier} finally 區塊完成。")
        else: print(f"{_cell_identifier} finally 區塊完成 (Logger 未完全配置或不可用)。")
    except Exception as e_final_log_print: print(f"{_cell_identifier} finally 區塊完成 (記錄最終日誌時發生錯誤: {e_final_log_print})。")

# ==================================================
# 頁尾註解 (v3.4.3-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 1: 專案初始化與全局設定 (初始化專用)
# 功能: 初始化專案，安裝並導入必要函式庫，定義全局配置和追蹤器。
# 版本: 3.4.3-zh-fc
# 日期: 2025-05-07
# 依賴: None
# 輸入: (可選 Colab Secrets)
# 輸出: ['global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', ...]
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 2: 環境檢查、目錄與快取設定 (工作流程從此開始)
# --------------------------------------------------
# 功能: 檢查 Cell 1 初始化狀態，創建輸出/快取目錄，並設定請求快取。
# 版本: 3.4-zh-fc (對應準則 v3.4，中文註解版，含頁尾註解)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger']
# 輸入: ['global:PROJECT_CONFIG']
# 輸出: ['Directory:PROJECT_CONFIG["output_dir"]', 'Directory:PROJECT_CONFIG["cache_dir"]', 'global:EXECUTION_TRACKER (updated)']
# --------------------------------------------------
# ==================================================
"""
執行環境準備工作，作為數據處理流程的第一步。

此儲存格執行以下步驟：
1.  執行必要全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 的先決條件檢查。
2.  檢查核心函式庫 (`os`, `requests_cache` - 如果需要) 是否可用。
3.  從 `PROJECT_CONFIG` 檢索輸出目錄 (`output_dir`) 和快取目錄 (`cache_dir`) 路徑。
4.  使用 `os.makedirs` 創建指定的目錄 (如果它們不存在)，包含錯誤處理。
5.  如果 `requests_cache` 函式庫可用且在 `PROJECT_CONFIG` 中配置了快取名稱和路徑，
    則使用 `requests_cache.install_cache` 設定全域請求快取。
6.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要並更新 `EXECUTION_TRACKER`。

設計說明：
* 作為工作流程的第一個儲存格，確保基礎設施（目錄、快取）準備就緒。
* 依賴 Cell 1 進行配置和追蹤器初始化。
* 使用 `PROJECT_CONFIG` 進行參數化。
* 包含針對目錄創建和快取設定錯誤的特定 `try-except` 區塊。

參數：
    無 (依賴來自 Cell 1 的全局變數 `PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`)。

返回：
    無 (創建目錄，可能設定快取，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 未定義。
    ValueError: 如果 `PROJECT_CONFIG` 中缺少必要的路徑鍵。
    ImportError: 如果 `requests_cache` 需要但未成功導入。
    OSError: 如果無法創建或訪問指定的目錄。
    Exception: 捕獲執行期間任何其他意外錯誤，例如快取設定失敗。

假設：
* Cell 1 已成功執行。
* `PROJECT_CONFIG` 包含 'output_dir' 和 'cache_dir' 鍵。
* 環境具有創建目錄的權限。

潛在問題 / 考量：
* 如果快取設定失敗，後續 API 請求將不會被快取，可能影響效能和 API 使用限制。
* 目錄權限問題可能導致 `OSError`。

下一步：
* 執行 Cell 3 開始具體的數據獲取任務。
* 執行 Cell Z 查看整體執行狀態。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
import os
from datetime import datetime, timezone, timedelta # 確保 datetime 組件可用

# --- 1. 獲取記錄器 ---
# 使用 __name__ 有助於區分來自不同儲存格/模組的日誌訊息
logger = logging.getLogger(__name__)

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 2: 環境檢查、目錄與快取設定" # 標識符本身建議 ASCII

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中" # 初始狀態
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # 記錄實際使用的輸入參數
_cell_outputs = {} # 記錄關鍵輸出信息/摘要
_cell_generated_files = [] # Cell 2 主要創建目錄

# --- 4. 主要腳本主體 ---
try:
    # --- 4.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4-zh-fc) 開始執行 ---")
    print(f"--- {_cell_identifier} (v3.4-zh-fc) 開始執行 ---")

    # 檢查來自 Cell 1 的基本全局變數
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("嚴重錯誤：全局變數 PROJECT_CONFIG 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("嚴重錯誤：全局變數 EXECUTION_TRACKER 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        # 嘗試重新獲取 logger，以防萬一
        logger = logging.getLogger(__name__)
        if not isinstance(logger, logging.Logger):
             raise NameError("嚴重錯誤：全局變數 logger 未定義或不是 Logger 實例。請確保 Cell 1 已成功運行。")
        else:
             logger.warning(f"{_cell_identifier}: Logger 在 Cell 1 可能未正確設置，已重新獲取。")
             _cell_warnings.append("Logger 在 Cell 1 可能未正確設置，已重新獲取。")

    # 檢查 os 模組 (理論上標準庫總是在)
    if 'os' not in globals() or not hasattr(os, 'makedirs'):
         raise ImportError("嚴重錯誤：Python 標準庫 'os' 模組不可用。")

    logger.info("先決條件檢查通過：PROJECT_CONFIG, EXECUTION_TRACKER, logger, os 均可用。")
    _cell_notes.append("先決條件檢查通過。")

    # --- 4.2. 獲取目錄路徑 ---
    logger.info("步驟 1：從 PROJECT_CONFIG 檢索目錄路徑...")
    _output_dir = PROJECT_CONFIG.get('output_dir')
    _cache_dir = PROJECT_CONFIG.get('cache_dir')

    _cell_inputs['輸出目錄路徑 (來自配置)'] = _output_dir
    _cell_inputs['快取目錄路徑 (來自配置)'] = _cache_dir

    # 驗證路徑是否為有效字符串
    if not isinstance(_output_dir, str) or not _output_dir:
        raise ValueError("嚴重錯誤：PROJECT_CONFIG 中的 'output_dir' 無效或缺失。")
    if not isinstance(_cache_dir, str) or not _cache_dir:
        raise ValueError("嚴重錯誤：PROJECT_CONFIG 中的 'cache_dir' 無效或缺失。")

    logger.info(f"目錄路徑已檢索：output='{_output_dir}', cache='{_cache_dir}'")
    print(f"目標目錄：輸出='{_output_dir}', 快取='{_cache_dir}'")
    _cell_notes.append(f"目標輸出目錄：{_output_dir}")
    _cell_notes.append(f"目標快取目錄：{_cache_dir}")

    # --- 4.3. 創建目錄 ---
    logger.info("步驟 2：創建輸出和快取目錄 (如果不存在)...")
    print("步驟 2：創建輸出和快取目錄 (如果不存在)...")
    _dirs_to_create = {'輸出目錄': _output_dir, '快取目錄': _cache_dir}
    _dirs_created_status = {}

    for dir_desc, dir_path in _dirs_to_create.items():
        try:
            os.makedirs(dir_path, exist_ok=True)
            # 可選：添加檢查以確認目錄現在確實存在
            if os.path.isdir(dir_path):
                create_note = f"已確保 {dir_desc} '{dir_path}' 存在。"
                _cell_notes.append(create_note)
                logger.info(create_note)
                print(f" - {create_note}")
                _dirs_created_status[dir_desc] = "已存在或已創建"
            else:
                # 雖然 makedirs 沒報錯，但目錄仍不存在，這很奇怪
                err_msg = f"創建 {dir_desc} '{dir_path}' 後未能確認其存在。"
                raise OSError(err_msg)
        except OSError as e:
            err_msg = f"無法創建或訪問 {dir_desc} '{dir_path}'：{e}"
            logger.error(err_msg, exc_info=True)
            # 決定是否要因為目錄創建失敗而停止
            # 對於輸出和快取目錄，通常是關鍵的，所以引發錯誤
            raise OSError(err_msg) from e
        except Exception as e:
            # 捕獲其他潛在錯誤
            err_msg = f"創建 {dir_desc} '{dir_path}' 時發生意外錯誤：{e}"
            logger.error(err_msg, exc_info=True)
            raise Exception(err_msg) from e

    _cell_outputs['目錄創建狀態'] = _dirs_created_status
    logger.info("目錄創建步驟完成。")
    _cell_notes.append("目錄創建檢查完成。")

    # --- 4.4. 設定請求快取 ---
    logger.info("步驟 3：設定請求快取 (requests-cache)...")
    print("步驟 3：設定請求快取 (requests-cache)...")
    _cache_status = "未嘗試 (函式庫不可用)"
    # 檢查 requests_cache 是否在 Cell 1 成功導入
    if 'requests_cache' in globals() and requests_cache:
        _cache_name = PROJECT_CONFIG.get('cache_name')
        _cache_expire_after = PROJECT_CONFIG.get('cache_expire_after')
        _cache_backend = 'sqlite' # 常用後端

        _cell_inputs['快取名稱 (來自配置)'] = _cache_name
        _cell_inputs['快取有效期 (來自配置)'] = str(_cache_expire_after) # 記錄為字串
        _cell_inputs['快取後端'] = _cache_backend

        if not _cache_name:
            warn_msg = "警告：PROJECT_CONFIG 中缺少 'cache_name'。跳過快取設定。"
            _cell_warnings.append(warn_msg)
            logger.warning(warn_msg)
            print(f" - {warn_msg}")
            _cache_status = "已跳過 (缺少配置)"
        else:
            try:
                # 構建快取文件的完整路徑
                _cache_path = os.path.join(_cache_dir, f"{_cache_name}.{_cache_backend}")
                _cell_inputs['完整快取路徑'] = _cache_path

                logger.info(f"嘗試安裝快取：名稱='{_cache_name}', 路徑='{_cache_path}', 後端='{_cache_backend}', 有效期={_cache_expire_after}")
                requests_cache.install_cache(
                    cache_name=_cache_path, # 提供完整路徑
                    backend=_cache_backend,
                    expire_after=_cache_expire_after,
                    # 可選：添加其他 requests-cache 選項
                    # allowable_methods=('GET', 'POST'), # 根據需要允許的方法
                    # filter_fn=lambda r: r.request.url.startswith('https://api.example.com') # 過濾特定 URL
                )
                # 檢查快取是否真的被啟用
                if requests_cache.is_installed():
                    cache_note = f"已成功安裝請求快取：路徑='{_cache_path}', 有效期={_cache_expire_after}。"
                    _cell_notes.append(cache_note)
                    logger.info(cache_note)
                    print(f" - {cache_note}")
                    _cache_status = "已啟用"
                else:
                    err_msg = "安裝請求快取後未能確認其已啟用。"
                    _cell_error = err_msg # 記錄為錯誤
                    logger.error(err_msg)
                    print(f" - \u274C {err_msg}")
                    _cache_status = "失敗 (未啟用)"

            except Exception as cache_err:
                err_msg = f"設定請求快取時發生錯誤：{cache_err.__class__.__name__}: {cache_err}"
                _cell_error = err_msg # 記錄為錯誤
                logger.error(err_msg, exc_info=True)
                print(f" - \u274C {err_msg}")
                _cache_status = f"失敗 ({cache_err.__class__.__name__})"
    else:
        warn_msg = "警告：requests-cache 函式庫未在 Cell 1 成功導入。跳過快取設定。"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(f" - {warn_msg}")
        # _cache_status 保持 "未嘗試 (函式庫不可用)"

    _cell_outputs['請求快取狀態'] = _cache_status
    logger.info("請求快取設定步驟完成。")
    _cell_notes.append("請求快取設定檢查完成。")

    # --- 標記成功 ---
    # 僅當所有步驟都無致命錯誤完成時才標記為成功
    if _cell_status == "處理中" and not _cell_error: # 檢查是否已有錯誤被記錄
        _cell_status = "成功"
        logger.info(f"{_cell_identifier} 執行成功。")
        print(f"--- {_cell_identifier} 執行成功 ---")
        _cell_notes.append("儲存格執行成功。")
    elif _cell_error: # 如果之前步驟記錄了非致命錯誤，但流程繼續了
         _cell_status = "失敗" # 將最終狀態標記為失敗
         logger.warning(f"{_cell_identifier} 執行期間遇到非致命錯誤，最終狀態標記為失敗。")
         print(f"--- {_cell_identifier} 執行完成但有錯誤記錄 ---")
         _cell_notes.append("儲存格執行完成但有錯誤記錄，狀態標記為失敗。")


# --- 5. 整個儲存格的異常處理 ---
except (NameError, ValueError, ImportError) as prereq_err:
    _cell_status = "失敗"
    _cell_error = f"配置或先決條件錯誤：{prereq_err.__class__.__name__}：{prereq_err}"
    _cell_traceback = traceback.format_exc()
    # 嘗試記錄錯誤，即使 logger 可能有問題
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")
except OSError as os_err:
    _cell_status = "失敗"
    # _cell_error 可能已在 try 塊中設置，如果沒有則設置
    if not _cell_error: _cell_error = f"文件系統錯誤：{os_err.__class__.__name__}：{os_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.error(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")
except Exception as e: # 捕獲所有其他意外錯誤
    # 僅當狀態仍為“處理中”時才更新為失敗，以避免覆蓋更具體的錯誤
    if _cell_status == "處理中":
        _cell_status = "失敗"
        _cell_error = f"意外錯誤：{e.__class__.__name__}：{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} 因意外錯誤而失敗：{_cell_error}", exc_info=True)
        except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
        print(f"\u274C 執行失敗：{_cell_error}")
    # 如果已記錄錯誤但未記錄 traceback，則捕獲它
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} 為錯誤捕獲了回退 traceback：{_cell_error}", exc_info=True)
         except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")


finally:
    # --- 6. 強制性的執行總結報告和追蹤器更新 ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # 根據狀態和警告確定最終狀態圖標和文本
    _final_status_text = _cell_status
    if _cell_status == "失敗":
        _final_status_icon = "❌"
    elif _cell_status == "已跳過": # 如果未來添加跳過邏輯
        _final_status_icon = "🚫"
    elif _cell_status == "處理中": # 不應發生，表示異常終止
        _final_status_icon = "⏳"
        _final_status_text = "未完成"
        if not _cell_error: _cell_error = "儲存格在完成前意外終止。"
        _cell_notes.append("警告：儲存格以 '處理中' 狀態結束。")
    elif _cell_warnings: # 成功或其他帶有警告的狀態
        _final_status_icon = "⚠️"
        if _cell_status == "成功":
             _final_status_text = "成功（有警告）"
    elif _cell_status == "成功": # 成功且無警告
        _final_status_icon = "✅"
    else: # 未知狀態的默認值
        _final_status_icon = "❓"
        _cell_notes.append(f"警告：儲存格以無法識別的狀態 '{_cell_status}' 結束。")

    # 安全地獲取當前時間戳
    _current_time_str = "無法獲取"
    try:
        _report_tz_info = PROJECT_CONFIG.get('_tz_info', timezone(timedelta(hours=8)))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"

    # 建構追蹤記錄
    _tracking_record = {
        'cell_id': _cell_identifier,
        'status_icon': _final_status_icon,
        'status_text': _final_status_text,
        'timestamp': _current_time_str,
        'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), # 去重並排序警告
        'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes,
        'inputs': _cell_inputs, # 包括記錄的輸入
        'outputs': _cell_outputs, # 包括記錄的輸出/摘要
        'generated_files': [] # 主要創建目錄，不生成常規文件
    }

    # 安全地更新全局追蹤器
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict):
            EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else:
            # 如果 EXECUTION_TRACKER 無效，記錄錯誤
            err_msg = f"錯誤：EXECUTION_TRACKER 不是字典或未定義。無法更新 {_cell_identifier} 的追蹤記錄。"
            print(err_msg)
            try: logger.error(err_msg)
            except: pass # logger 可能也無效
    except Exception as tracker_update_err:
        err_msg = f"錯誤：更新 EXECUTION_TRACKER 時發生異常：{tracker_update_err}"
        print(err_msg)
        try: logger.error(err_msg, exc_info=True)
        except: pass

    # --- 打印執行總結報告 (強制性) ---
    print("\n" + "="*80)
    # 嘗試從 PROJECT_CONFIG 獲取準則版本，如果失敗則回退
    _guideline_version_str = "未知準則版本"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本')
    except Exception:
        pass # 保持默認值

    print(f"儲存格：{_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon} {_final_status_text}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒")
    print(f"** 完成時間：** {_current_time_str}")

    # 打印輸入參數
    if _cell_inputs:
        print("\n** \U0001F527 輸入參數：**") # 齒輪表情符號
        pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)

    # 打印執行註記
    if _cell_notes:
      print("\n** \U0001F4DD 執行註記：**") # 備忘錄表情符號
      for note in _cell_notes: print(f"- {note}")

    # 打印警告（從追蹤記錄讀取以確保一致）
    if _tracking_record.get('warnings'):
        print("\n** \u26A0\uFE0F 警告訊息：**") # 警告標誌表情符號
        for warning in _tracking_record['warnings']: print(f"- {warning}")

    # 打印錯誤（從追蹤記錄讀取）
    if _tracking_record.get('error'):
        print("\n** \u274C 錯誤訊息：**") # 叉號表情符號
        print(f"** {_tracking_record['error']} **")

    # 打印 Traceback（從追蹤記錄讀取）
    if _tracking_record.get('traceback'):
        print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20)
        print(f"<pre>{_tracking_record['traceback']}</pre>")
        print("-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))

    # 打印輸出摘要（從追蹤記錄讀取）
    print("\n** \U0001F4CA 輸出 / 檢查結果摘要：**") # 條形圖表情符號
    tracked_outputs = _tracking_record.get('outputs')
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]:
         print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs:
         info_text = {"失敗": "因執行失敗，無輸出摘要。",
                      "已跳過": "儲存格已跳過，無輸出摘要。",
                      "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。")
         print(f"- {info_text}")
    else:
     pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)

    # Cell 2 不生成常規文件，無需打印 '生成/相關文件路徑'

    print("="*80 + "\n")

    # --- 7. 清理局部變數 ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_output_dir', '_cache_dir',
        '_dirs_to_create', '_dirs_created_status', 'dir_desc', 'dir_path',
        '_cache_status', '_cache_name', '_cache_expire_after', '_cache_backend',
        '_cache_path', 'create_note', 'cache_note', 'warn_msg', 'err_msg',
        'info_text', 'prereq_err', 'os_err', 'cache_err', 'e', 'time_err',
        'time_err_local', 'tracker_update_err', '_guideline_version_str'
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try:
                del locals()[_var]
            except KeyError:
                pass
    try:
        logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: # 如果 logger 初始化失敗
        print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 2: 環境檢查、目錄與快取設定 (工作流程從此開始)
# 功能: 檢查 Cell 1 初始化狀態，創建輸出/快取目錄，並設定請求快取。
# 版本: 3.4-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger']
# 輸入: ['global:PROJECT_CONFIG']
# 輸出: ['Directory:PROJECT_CONFIG["output_dir"]', 'Directory:PROJECT_CONFIG["cache_dir"]', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 3: yfinance 數據獲取 (TWD/USD, VIX) (含重試機制)
# --------------------------------------------------
# 功能: 使用 yfinance 獲取 TWD/USD 即期匯率和 VIX 指數的日頻歷史數據，增加對 YFRateLimitError 的重試機制。
# 版本: 3.4.2-zh-fc (對應準則 v3.4，中文註解版，增強重試和錯誤捕獲)
# 日期: 2025-05-07
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:yf', 'global:pd', 'global:tenacity', 'global:requests']
# 輸入: ['global:PROJECT_CONFIG'] (間接獲取時區和重試配置等信息)
# 輸出: ['global:df_twdusd', 'global:df_vix', 'global:EXECUTION_TRACKER (updated)'] # 將數據存為全局變數
# --------------------------------------------------
# ==================================================
"""
使用 yfinance 函式庫獲取基礎市場數據，並增加對 API 速率限制錯誤的自動重試功能。

此儲存格執行以下步驟：
1.  執行必要全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 和函式庫 (`yf`, `pd`, `tenacity`, `requests`) 的先決條件檢查。
2.  定義需要獲取的金融代碼 (tickers)：'TWD=X' (新台幣兌美元) 和 '^VIX' (波動率指數)。
3.  設定數據獲取的時間範圍。
4.  從 `PROJECT_CONFIG` 獲取重試參數 (等待時間、嘗試次數)。
5.  定義一個內部函數 `_fetch_yfinance_with_retry`，使用 `@tenacity.retry` 裝飾器：
    a. 該函數嘗試使用 `yf.Ticker(ticker_symbol).history()` 獲取數據。
    b. 重試條件包括 `yfinance.errors.YFRateLimitError` (如果能導入) 或基於錯誤訊息判斷的速率限制錯誤，以及其他可能的網路相關異常 (如 `requests.exceptions.RequestException`, `requests.exceptions.HTTPError` 狀態碼 429)。
    c. 在重試前記錄日誌。
6.  迭代處理每個 ticker，調用帶有重試邏輯的獲取函數。
7.  將成功獲取的數據儲存到對應的全局 Pandas DataFrame 變數中 (`df_twdusd`, `df_vix`)。
8.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要（例如獲取到的數據行數）並更新 `EXECUTION_TRACKER`。

設計說明：
* 引入 `tenacity` 實現對 yfinance API 請求的自動重試，以應對暫時的速率限制。
* 重試參數可通過 `PROJECT_CONFIG` 配置。
* 增強了對 yfinance 錯誤類型的判斷，即使 `yfinance.errors` 模塊不易直接導入。
* 其他邏輯與先前版本相似。

參數：
    無 (依賴來自 Cell 1 的全局變數和函式庫)。

返回：
    無 (創建或更新全局 DataFrame 變數 `df_twdusd`, `df_vix`，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數或函式庫未定義。
    AttributeError: 如果 `yf` 對象沒有預期的方法。
    tenacity.RetryError: 如果重試後仍然達到速率限制或發生其他持續性錯誤。
    Exception: 捕獲 `yfinance` 在數據獲取過程中可能引發的其他錯誤。

假設：
* Cell 1 已成功執行，且 `yfinance` (yf), `pandas` (pd), `tenacity`, `requests` 已成功導入。
* Colab 環境可以訪問 Yahoo Finance 的數據。
* `PROJECT_CONFIG` 中可以配置 `rate_limit_handler`。

潛在問題 / 考量：
* 即使有重試，如果速率限制非常嚴格或 Yahoo Finance API 服務本身有問題，請求仍可能最終失敗。
* `yfinance` 內部錯誤的多樣性，可能需要根據實際遇到的錯誤調整重試的異常類型。

下一步：
* 執行 Cell 4 (Alpha Vantage 數據獲取)。
* 執行 Cell Z 查看整體執行狀態。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timedelta # 用於設定日期範圍

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)
_YFINANCE_ERRORS_MODULE_AVAILABLE = False
try:
    # 嘗試導入 yfinance 可能拋出的特定錯誤類型，以便更精確地捕獲
    import yfinance.errors
    _YFINANCE_ERRORS_MODULE_AVAILABLE = True
except ImportError:
    logger.warning("無法直接導入 yfinance.errors 模塊，將主要依賴錯誤訊息字符串和 requests 異常進行重試判斷。")

try:
    import pandas as pd
    import yfinance as yf
    import tenacity
    import requests # yfinance 底層使用 requests，捕獲其異常有助於網路問題重試
    if 'libs_loaded' in globals():
        if not libs_loaded.get('tenacity', False):
            logger.warning("根據 libs_loaded，tenacity 可能未在 Cell 1 正確加載。")
        if not libs_loaded.get('requests', False):
            logger.warning("根據 libs_loaded，requests 可能未在 Cell 1 正確加載。")
except ImportError as e:
    logger.critical(f"Cell 3 執行所需的關鍵函式庫導入失敗: {e}")
    raise # 如果這些核心庫都無法導入，後續無法執行

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 3: yfinance 數據獲取 (TWD/USD, VIX) (含重試機制)"

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. 全局 DataFrame 變數初始化 ---
df_twdusd = None
df_vix = None
_tickers_to_fetch = {} # 初始化，以防 try 塊早期出錯

# --- 5. 主要腳本主體 ---
try:
    # --- 5.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4.2-zh-fc) 開始執行 ---")
    print(f"--- {_cell_identifier} (v3.4.2-zh-fc) 開始執行 ---")

    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("嚴重錯誤：全局變數 PROJECT_CONFIG 未定義或不是字典。")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("嚴重錯誤：全局變數 EXECUTION_TRACKER 未定義或不是字典。")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("嚴重錯誤：全局變數 logger 未定義或不是 Logger 實例。")
    if 'yf' not in globals() or not hasattr(yf, 'Ticker'):
        raise NameError("嚴重錯誤：yfinance 函式庫 (yf) 未成功導入。")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("嚴重錯誤：pandas 函式庫 (pd) 未成功導入。")
    if 'tenacity' not in globals() or not hasattr(tenacity, 'retry'):
        raise NameError("嚴重錯誤：tenacity 函式庫未成功導入（用於重試機制）。")
    if 'requests' not in globals() or not hasattr(requests, 'exceptions'): # 檢查 requests.exceptions 是否存在
        raise NameError("嚴重錯誤：requests 函式庫未成功導入（用於網路錯誤判斷）。")


    logger.info("先決條件檢查通過。")
    _cell_notes.append("先決條件檢查通過。")

    # --- 5.2. 定義 Tickers 和獲取參數 ---
    _tickers_to_fetch = {
        'TWD=X': 'df_twdusd',
        '^VIX': 'df_vix'
    }
    _start_date = (datetime.now() - timedelta(days=15*365)).strftime('%Y-%m-%d')
    _interval = '1d'

    _cell_inputs['Tickers'] = list(_tickers_to_fetch.keys())
    _cell_inputs['開始日期'] = _start_date
    _cell_inputs['時間間隔'] = _interval
    logger.info(f"準備獲取 Tickers: {list(_tickers_to_fetch.keys())}，從 {_start_date} 開始，間隔 {_interval}。")
    print(f"準備獲取 Tickers: {list(_tickers_to_fetch.keys())}")

    # --- 5.3. 設定重試參數 ---
    _retry_config = PROJECT_CONFIG.get('rate_limit_handler', {})
    _wait_seconds = _retry_config.get('wait_fixed_seconds_yfinance', _retry_config.get('wait_fixed_seconds', 30)) # 默認等待30秒
    _stop_attempts = _retry_config.get('stop_after_attempt_yfinance', _retry_config.get('stop_after_attempt', 3)) # 默認嘗試3次

    _cell_inputs['重試等待秒數'] = _wait_seconds
    _cell_inputs['最大重試次數'] = _stop_attempts
    logger.info(f"yfinance 請求重試設定：等待 {_wait_seconds} 秒，最多嘗試 {_stop_attempts} 次。")

    # --- 5.4. 定義帶重試的獲取函數 ---
    def _is_yfinance_specific_rate_limit_error(e):
        """檢查是否為 yfinance.errors.YFRateLimitError (如果模塊可用)"""
        if _YFINANCE_ERRORS_MODULE_AVAILABLE and isinstance(e, yfinance.errors.YFRateLimitError):
            return True
        # 有些情況下 yfinance 會拋出 yf.libs.yfinance.shared.YFinanceException
        if isinstance(e, yf.libs.yfinance.shared.YFinanceException):
            err_str = str(e).lower()
            if "rate limit" in err_str or "too many requests" in err_str:
                return True
        return False

    def _should_retry_yfinance_error(retry_state: tenacity.RetryCallState):
        """決定是否重試 yfinance 的特定錯誤。"""
        exc = retry_state.outcome.exception()
        attempt_number_str = f"(嘗試 {retry_state.attempt_number}/{_stop_attempts})"

        if _is_yfinance_specific_rate_limit_error(exc):
            logger.warning(f"yfinance 請求遇到 API 速率限制 {attempt_number_str}，將在 {_wait_seconds} 秒後重試：{exc}")
            return True
        # 檢查 requests 層級的 HTTP 錯誤，特別是 429
        if isinstance(exc, requests.exceptions.HTTPError):
            if exc.response is not None and exc.response.status_code == 429: # HTTP 429 Too Many Requests
                logger.warning(f"yfinance 請求返回 HTTP 429 (Too Many Requests) {attempt_number_str}，將在 {_wait_seconds} 秒後重試。")
                return True
            # 可以考慮重試其他如 5xx 的服務器錯誤
            # if exc.response is not None and 500 <= exc.response.status_code < 600:
            #     logger.warning(f"yfinance 請求返回 HTTP {exc.response.status_code} (服務器錯誤) {attempt_number_str}，將重試。")
            #     return True

        # 檢查常見的網路連線錯誤
        if isinstance(exc, (requests.exceptions.ConnectionError, requests.exceptions.Timeout, requests.exceptions.ChunkedEncodingError)):
            logger.warning(f"yfinance 請求遇到網路連線問題 {attempt_number_str}，將在 {_wait_seconds} 秒後重試：{exc}")
            return True

        # 對於其他類型的 yfinance 內部錯誤，或者錯誤訊息中明確提到速率限制的
        err_str_lower = str(exc).lower()
        if "too many requests" in err_str_lower or "rate limited" in err_str_lower:
            logger.warning(f"yfinance 請求遇到疑似速率限制的錯誤 {attempt_number_str} (基於錯誤訊息)，將在 {_wait_seconds} 秒後重試：{exc}")
            return True

        logger.error(f"yfinance 請求遇到不可重試的錯誤 {attempt_number_str}：{exc.__class__.__name__}: {exc}")
        return False # 對於其他未知錯誤，不重試

    @tenacity.retry(
        wait=tenacity.wait_fixed(_wait_seconds),
        stop=tenacity.stop_after_attempt(_stop_attempts),
        retry=_should_retry_yfinance_error,
        reraise=True
    )
    def _fetch_yfinance_with_retry(ticker_symbol: str, start_date: str, interval: str) -> pd.DataFrame:
        logger.debug(f"調用 yf.Ticker('{ticker_symbol}').history(start='{start_date}', interval='{interval}')")
        ticker_obj = yf.Ticker(ticker_symbol)
        # 增加 timeout 參數給 yfinance 的請求 (如果 yfinance 支持直接傳遞)
        # yfinance 的 history 方法本身不直接接受 timeout，它底層的 requests 會有默認值
        # 但我們可以通過 yf.set_proxy 或其他方式間接影響
        # 目前保持原樣，主要依賴 tenacity 處理超時 (requests.exceptions.Timeout)
        history_df = ticker_obj.history(start=start_date, interval=interval)

        if history_df.empty:
            try:
                info = ticker_obj.info # 嘗試獲取info判斷ticker是否有效
                # 簡陋檢查 info 是否真的有效，以及是否有價格數據
                if not info or (isinstance(info, dict) and info.get('regularMarketPrice') is None and info.get('previousClose') is None and not info.get('shortName')):
                    logger.warning(f"yf.Ticker('{ticker_symbol}').history 返回空 DataFrame，且 .info 看似無效。可能 Ticker '{ticker_symbol}' 不存在或無此時段數據。")
                else: # Info 有內容，但 history 為空
                    logger.info(f"yf.Ticker('{ticker_symbol}').history 返回空 DataFrame，但 .info 有數據。可能在指定時段 '{start_date}' 之後無交易數據。")
            except Exception as e_info:
                logger.warning(f"yf.Ticker('{ticker_symbol}').history 返回空 DataFrame，嘗試獲取 .info 也失敗: {e_info}。可能 Ticker '{ticker_symbol}' 無效。")
        return history_df

    # --- 5.5. 迭代獲取數據 ---
    _fetch_success_count = 0
    _fetch_error_count = 0

    for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
        logger.info(f"正在獲取 {ticker_symbol} 的數據 (含重試)...")
        print(f" - 正在獲取 {ticker_symbol} (含重試)...")
        try:
            history_df = _fetch_yfinance_with_retry(ticker_symbol, _start_date, _interval)

            if history_df.empty:
                warn_msg = f"警告：獲取 {ticker_symbol} 的數據為空 DataFrame (重試後)。可能 Ticker 無效、該時段無數據或持續的 API 問題。"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f"   - {warn_msg}")
                _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
                globals()[df_variable_name] = history_df.copy() # 賦值空 DataFrame 的副本
                _fetch_success_count += 1
            else:
                globals()[df_variable_name] = history_df.copy() # 賦值副本
                success_note = f"成功獲取 {ticker_symbol} 的數據 ({len(history_df):,} 行，重試後)。已存儲至全局變數 {df_variable_name}。"
                _cell_notes.append(success_note)
                logger.info(success_note)
                print(f"   - {success_note}")
                _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功'
                _cell_outputs[f'{df_variable_name}_行數'] = len(history_df)
                _cell_outputs[f'{df_variable_name}_列名'] = history_df.columns.tolist()
                _cell_outputs[f'{df_variable_name}_起始日期'] = history_df.index.min().strftime('%Y-%m-%d') if not history_df.empty else 'N/A'
                _cell_outputs[f'{df_variable_name}_結束日期'] = history_df.index.max().strftime('%Y-%m-%d') if not history_df.empty else 'N/A'
                _fetch_success_count += 1

        except tenacity.RetryError as e_retry:
            _fetch_error_count += 1
            original_exception = e_retry.last_attempt.exception()
            err_msg = f"獲取 {ticker_symbol} 數據失敗 (重試 {_stop_attempts} 次後)：{original_exception.__class__.__name__}: {original_exception}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_狀態'] = f'獲取失敗 (重試耗盡: {original_exception.__class__.__name__})'
            globals()[df_variable_name] = None
            if not _cell_error: _cell_error = err_msg # 記錄第一個主要錯誤
            if not _cell_traceback: _cell_traceback = traceback.format_exception(type(original_exception), original_exception, original_exception.__traceback__) # 獲取原始異常的traceback

        except Exception as e:
            _fetch_error_count += 1
            err_msg = f"獲取 {ticker_symbol} 數據時發生未預期錯誤：{e.__class__.__name__}: {e}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_狀態'] = f'獲取失敗 ({e.__class__.__name__})'
            globals()[df_variable_name] = None
            if not _cell_error: _cell_error = err_msg
            if not _cell_traceback: _cell_traceback = traceback.format_exc()

    logger.info(f"yfinance 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")
    _cell_notes.append(f"yfinance 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")

    if _fetch_error_count == len(_tickers_to_fetch) and _fetch_success_count == 0 : # 只有在所有都失敗時才設定cell error
        _cell_status = "失敗"
        if not _cell_error: _cell_error = "所有 yfinance Tickers 數據獲取均失敗 (重試後)。" # 更新錯誤信息
        logger.error(_cell_error)
    elif _fetch_success_count > 0 : # 只要有任何一個成功，Cell 就視為部分成功或完全成功
        _cell_status = "成功"
        if _fetch_error_count > 0: # 如果部分成功部分失敗
            _cell_notes.append("部分 Tickers 數據獲取失敗或返回空。")
            _cell_warnings.append("部分 Tickers 數據獲取失敗。") # 添加一個總體警告
        logger.info(f"{_cell_identifier} 執行成功（可能包含部分失敗或警告）。")
        print(f"--- {_cell_identifier} 執行成功 ---")
        _cell_notes.append("儲存格執行成功。")
    elif _fetch_success_count == 0 and _fetch_error_count > 0: # 所有嘗試都失敗了
        _cell_status = "失敗"
        if not _cell_error: _cell_error = "未能成功獲取任何 yfinance Ticker 的數據 (重試後)。"
        logger.error(_cell_error)
    # 如果 _cell_status 仍然是 "處理中"，說明邏輯有問題
    elif _cell_status == "處理中":
        _cell_status = "失敗" # 兜底
        _cell_error = "儲存格狀態未知，標記為失敗。"
        logger.error(_cell_error)


# --- 6. 整個儲存格的異常處理 ---
except (NameError, ImportError, AttributeError) as prereq_err:
    _cell_status = "失敗"
    _cell_error = f"配置或先決條件錯誤：{prereq_err.__class__.__name__}：{prereq_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False) # exc_info=False 因為traceback已捕獲
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")
except Exception as e:
    if _cell_status == "處理中":
        _cell_status = "失敗"
        _cell_error = f"意外錯誤：{e.__class__.__name__}：{e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 因意外錯誤而失敗：{_cell_error}", exc_info=True)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")


finally:
    # --- 7. 強制性的執行總結報告和追蹤器更新 ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    _final_status_text = _cell_status
    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "已跳過": _final_status_icon = "🚫"
    elif _cell_status == "處理中": _final_status_icon = "⏳"; _final_status_text = "未完成"; _cell_notes.append("警告：儲存格以 '處理中' 狀態結束。")
    elif _cell_warnings and _cell_status == "成功": _final_status_icon = "⚠️"; _final_status_text = "成功（有警告）"
    elif _cell_status == "成功": _final_status_icon = "✅"
    else: _final_status_icon = "❓"; _cell_notes.append(f"警告：儲存格以無法識別的狀態 '{_cell_status}' 結束。")

    _current_time_str = "無法獲取"
    try:
        _report_tz_info = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8))) if ('PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict)) else timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗": _cell_warnings.append(f"報告時間獲取錯誤: {time_err}")

    if '_tickers_to_fetch' in locals() and isinstance(_tickers_to_fetch, dict):
        for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df_val = globals()[df_variable_name] # 使用 df_val 避免與外部 df 衝突
                  if not df_val.empty:
                       if f'{df_variable_name}_行數' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_行數'] = len(df_val)
                       if f'{df_variable_name}_列名' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_列名'] = df_val.columns.tolist()
                       if f'{df_variable_name}_起始日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_起始日期'] = df_val.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_結束日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_結束日期'] = df_val.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_最新數據 ({df_val.index.max().strftime("%Y-%m-%d")})'] = df_val.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
             elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取失敗 (變數未創建)'
    else: _cell_notes.append("無法更新輸出摘要 (_tickers_to_fetch 未定義)。")

    # 確保 traceback 是字符串
    _final_traceback_str = None
    if isinstance(_cell_traceback, list): # traceback.format_exception 返回列表
        _final_traceback_str = "".join(_cell_traceback)
    elif isinstance(_cell_traceback, str):
        _final_traceback_str = _cell_traceback

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _final_traceback_str.strip() if _final_traceback_str else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"錯誤：EXECUTION_TRACKER 無效。"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"錯誤：更新 EXECUTION_TRACKER 時異常：{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知') if ('PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict)) else '未知'
    print(f"儲存格：{_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon} {_final_status_text}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒")
    print(f"** 完成時間：** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 輸入參數：**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記：**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息：**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息：**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))
    print("\n** \U0001F4CA 輸出 / 檢查結果摘要：**")
    tracked_outputs_display = _tracking_record.get('outputs', {})
    if not tracked_outputs_display and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs_display: info_text = {"失敗": "因執行失敗。", "已跳過": "已跳過。", "未完成": "未完成。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else:
     filtered_outputs_display = {k: v for k, v in tracked_outputs_display.items() if '列名' not in k and '最新數據' not in k}
     pprint.pprint(filtered_outputs_display, indent=2, width=70, sort_dicts=False)
     for k_disp, v_disp in tracked_outputs_display.items(): # 使用不同變數名避免衝突
         if '最新數據' in k_disp: print(f"- {k_disp}:"); pprint.pprint(v_disp, indent=4, width=65)
    print("="*80 + "\n")

    # --- 8. 清理局部變數 ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_tickers_to_fetch', '_start_date',
        '_interval', '_fetch_success_count', '_fetch_error_count', 'ticker_symbol',
        'df_variable_name', 'ticker_obj', 'history_df', 'warn_msg', 'err_msg', # history_df 已在循環中賦值給全局變數或None
        'success_note', 'prereq_err', 'e', 'time_err', 'time_err_local',
        'tracker_update_err', '_guideline_version_str', 'info_text',
        '_retry_config', '_wait_seconds', '_stop_attempts', '_fetch_yfinance_with_retry',
        '_is_yfinance_specific_rate_limit_error', '_should_retry_yfinance_error', 'e_retry', 'original_exception',
        '_YFINANCE_ERRORS_MODULE_AVAILABLE', 'e_info', 'attempt_number_str', 'exc', 'err_str_lower',
        'df_val', 'filtered_outputs_display', 'tracked_outputs_display', 'k_disp', 'v_disp', '_final_traceback_str'
    ]
    # 全局變數 df_twdusd, df_vix 不在此處清理，它們是此儲存格的預期輸出
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")

# ==================================================
# 頁尾註解 (v3.4.2-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 3: yfinance 數據獲取 (TWD/USD, VIX) (含重試機制)
# 功能: 使用 yfinance 獲取 TWD/USD 即期匯率和 VIX 指數的日頻歷史數據，增加對 YFRateLimitError 的重試機制。
# 版本: 3.4.2-zh-fc
# 日期: 2025-05-07
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:yf', 'global:pd', 'global:tenacity', 'global:requests']
# 輸入: ['global:PROJECT_CONFIG']
# 輸出: ['global:df_twdusd', 'global:df_vix', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 4: Alpha Vantage 數據獲取 (SPY, HYG, LQD)
# --------------------------------------------------
# 功能: 使用 Alpha Vantage API (免費 TIME_SERIES_DAILY 功能) 獲取 SPY, HYG, LQD 的日頻歷史價格與成交量數據。
# 版本: 3.4-zh-fc (對應準則 v3.4，中文註解版，含頁尾註解) - 改用免費 API
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 2', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:requests', 'global:pd', 'global:tenacity', 'global:colab_userdata']
# 輸入: ['Secret:ALPHA_VANTAGE_API_KEY', 'global:PROJECT_CONFIG']
# 輸出: ['global:df_spy', 'global:df_hyg', 'global:df_lqd', 'global:EXECUTION_TRACKER (updated)'] # 將數據存為全局變數
# --------------------------------------------------
# ==================================================
"""
使用 Alpha Vantage API (免費 TIME_SERIES_DAILY 功能) 獲取股票/ETF 市場數據。

此儲存格執行以下步驟：
1.  執行必要全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 和函式庫 (`requests`, `pd`, `tenacity`, `colab_userdata`) 的先決條件檢查。
2.  安全地從 Colab Secrets 載入 Alpha Vantage API Key (`ALPHA_VANTAGE_API_KEY`)，並存儲到大寫變數 `ALPHA_VANTAGE_API_KEY_VALUE` 中。
3.  定義需要獲取的金融代碼 (tickers)：'SPY', 'HYG', 'LQD'。
4.  定義一個帶有錯誤處理和重試邏輯的函數 (`fetch_alpha_vantage_data`)，用於：
    a. 構建 Alpha Vantage API URL (使用 **TIME_SERIES_DAILY** function)。
    b. 使用 `requests.get` 發送 API 請求，包含 User-Agent。
    c. 使用 `@tenacity.retry` 裝飾器處理網路連線錯誤和可能的超時。
    d. 檢查 HTTP 回應狀態碼。
    e. 解析 JSON 回應，並檢查 Alpha Vantage 返回的錯誤訊息或資訊訊息 (例如，達到請求限制)。
    f. 如果成功，將 JSON 數據轉換為結構化的 Pandas DataFrame，包含標準化的列名 (Date, Open, High, Low, Close, Volume)。**注意：不包含調整後收盤價。**
    g. 返回處理後的 DataFrame 或在失敗時返回 None。
5.  迭代處理每個 ticker，調用 `fetch_alpha_vantage_data` 函數。
6.  將成功獲取的數據儲存到對應的全局 Pandas DataFrame 變數中 (`df_spy`, `df_hyg`, `df_lqd`)。
7.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要（例如 API Key 狀態、獲取到的數據行數）並更新 `EXECUTION_TRACKER`。 **特別注意：在 finally 區塊中清理 API Key 變數。**

設計說明：
* **修改:** 改用免費的 `TIME_SERIES_DAILY` API 功能。
* 封裝 API 請求邏輯到一個可重用的函數中，並應用 `tenacity` 進行重試。
* 嚴格遵守 v3.4 的 API Key 命名和安全處理規範。
* 對 Alpha Vantage 的 JSON 回應進行仔細的錯誤檢查和解析。
* 將數據直接存儲為全局變數以便後續使用。

參數：
    無 (依賴全局變數、函式庫和 Colab Secrets)。

返回：
    無 (創建或更新全局 DataFrame 變數 `df_spy`, `df_hyg`, `df_lqd`，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數或函式庫未定義。
    userdata.SecretNotFoundError: 如果在 Colab Secrets 中找不到 `ALPHA_VANTAGE_API_KEY`。
    ValueError: 如果 API Key 為空或 PROJECT_CONFIG 配置不完整。
    requests.exceptions.RequestException: 如果發生網路連線錯誤且重試失敗。
    KeyError/TypeError: 如果 API JSON 回應結構不符合預期。
    Exception: 捕獲其他意外錯誤。

假設：
* Cell 1 和 Cell 2 已成功執行。
* `requests`, `pandas`, `tenacity`, `colab_userdata` 已成功導入。
* 名為 'ALPHA_VANTAGE_API_KEY' 的 Secret 已在 Colab 中設定且值有效。
* `PROJECT_CONFIG` 包含 'user_agent' 和 'rate_limit_handler' 配置。
* Colab 環境可以訪問 Alpha Vantage API。

潛在問題 / 考量：
* Alpha Vantage 的 API 請求限制（免費方案通常有限制）。`tenacity` 重試有助於緩解瞬時問題，但無法解決持續的限制。
* API 回應結構可能變更。
* 數據質量和延遲。
* **注意：** 使用 `TIME_SERIES_DAILY` 無法獲取調整後收盤價，對於需要考慮股息和拆分的分析可能不夠精確。

下一步：
* 執行 Cell 5 (FRED 數據獲取)。
* 執行 Cell 6 或之後的儲存格進行數據清洗與整合。
* 執行 Cell Z 查看整體執行狀態。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # 確保 datetime 組件可用
import json # 用於解析 JSON

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 4: Alpha Vantage 數據獲取 (SPY, HYG, LQD)" # 標識符本身建議 ASCII

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中" # 初始狀態
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # 記錄實際使用的輸入參數
_cell_outputs = {} # 記錄關鍵輸出信息/摘要
_cell_generated_files = [] # 此 Cell 不生成文件

# --- 4. API Key 變數 (遵循大寫規則) ---
ALPHA_VANTAGE_API_KEY_VALUE = None # 初始化為 None

# --- 5. 全局 DataFrame 變數初始化 ---
df_spy = None
df_hyg = None
df_lqd = None
_tickers_to_fetch = {} # 初始化為空字典

# --- 6. 主要腳本主體 ---
try:
    # --- 6.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4-zh-fc) 開始執行 ---")
    print(f"--- {_cell_identifier} (v3.4-zh-fc) 開始執行 ---")

    # 檢查來自 Cell 1 的基本全局變數和函式庫
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("嚴重錯誤：全局變數 PROJECT_CONFIG 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("嚴重錯誤：全局變數 EXECUTION_TRACKER 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("嚴重錯誤：全局變數 logger 未定義或不是 Logger 實例。請確保 Cell 1 已成功運行。")
    if 'requests' not in globals() or not hasattr(requests, 'get'):
        raise NameError("嚴重錯誤：requests 函式庫未成功導入。請檢查 Cell 1。")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("嚴重錯誤：pandas 函式庫 (pd) 未成功導入。請檢查 Cell 1。")
    if 'tenacity' not in globals() or not hasattr(tenacity, 'retry'):
        raise NameError("嚴重錯誤：tenacity 函式庫未成功導入。請檢查 Cell 1。")
    try:
        from google.colab import userdata
        _COLAB_USERDATA_AVAILABLE = True
    except ImportError:
        _COLAB_USERDATA_AVAILABLE = False
        userdata = None # 設置為 None 以便後續檢查
        warn_msg = "警告：無法導入 google.colab.userdata。將無法從 Secrets 載入 API Key。"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(warn_msg)
        # 如果 API Key 是必需的，這裡應該引發錯誤
        # raise EnvironmentError("無法訪問 Colab Secrets，無法繼續獲取 Alpha Vantage 數據。")

    logger.info("先決條件檢查通過。")
    _cell_notes.append("先決條件檢查通過。")

    # --- 6.2. 安全載入 Alpha Vantage API Key ---
    logger.info("步驟 1：安全載入 Alpha Vantage API Key...")
    print("步驟 1：安全載入 Alpha Vantage API Key...")
    _api_key_name = 'ALPHA_VANTAGE_API_KEY' # Secrets 中的名稱 (符合規範)
    _cell_inputs['請求的 Secret 名稱'] = _api_key_name
    _api_key_load_status = "未嘗試 (userdata 不可用)"

    if _COLAB_USERDATA_AVAILABLE:
        try:
            ALPHA_VANTAGE_API_KEY_VALUE = userdata.get(_api_key_name)
            if ALPHA_VANTAGE_API_KEY_VALUE:
                load_key_note = f"成功從 Colab Secrets 載入 '{_api_key_name}'。"
                _cell_notes.append(load_key_note)
                logger.info(load_key_note)
                print(f" - {load_key_note}")
                _api_key_load_status = '成功'
            else:
                # Key 存在但值為空
                warn_msg = f"警告：從 Colab Secrets 載入的 '{_api_key_name}' 值為空。Alpha Vantage API 將無法使用。"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f" - {warn_msg}")
                _api_key_load_status = '成功 (值為空)'
                # 引發錯誤，因為空 Key 無法使用
                raise ValueError(f"Alpha Vantage API Key '{_api_key_name}' 的值為空。")
        except userdata.SecretNotFoundError:
            err_msg = f"錯誤：在 Colab Secrets 中未找到名為 '{_api_key_name}' 的 Secret。請檢查是否已設定。"
            _cell_error = err_msg
            logger.error(err_msg)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = '失敗 (未找到)'
            # 引發錯誤，因為沒有 Key 無法繼續
            raise userdata.SecretNotFoundError(err_msg)
        except Exception as secret_err:
            err_msg = f"讀取 Colab Secret '{_api_key_name}' 時發生意外錯誤：{secret_err.__class__.__name__}: {secret_err}"
            _cell_error = err_msg
            logger.error(err_msg, exc_info=True)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = f'失敗 ({secret_err.__class__.__name__})'
            # 引發錯誤
            raise Exception(err_msg) from secret_err
    else:
        # userdata 不可用，無法獲取 Key
        _api_key_load_status = "失敗 (userdata 不可用)"
        # 引發錯誤，因為沒有 Key 無法繼續
        raise EnvironmentError("無法訪問 Colab Secrets，無法獲取 Alpha Vantage API Key。")

    _cell_outputs['API Key 載入狀態'] = _api_key_load_status
    logger.info("Alpha Vantage API Key 載入檢查完成。")

    # --- 6.3. 定義數據獲取函數 (含重試) ---
    logger.info("步驟 2：定義 Alpha Vantage 數據獲取函數...")

    # 從配置獲取重試參數
    _retry_wait = tenacity.wait_fixed(PROJECT_CONFIG.get('rate_limit_handler', {}).get('wait_fixed_seconds', 2))
    _retry_stop = tenacity.stop_after_attempt(PROJECT_CONFIG.get('rate_limit_handler', {}).get('stop_after_attempt', 5))
    _user_agent = PROJECT_CONFIG.get('user_agent', 'python-requests/unknown')

    # 定義哪些異常觸發重試
    @tenacity.retry(
        wait=_retry_wait,
        stop=_retry_stop,
        retry=tenacity.retry_if_exception_type((requests.exceptions.ConnectionError, requests.exceptions.Timeout)),
        before_sleep=tenacity.before_sleep_log(logger, logging.WARNING), # 重試前記錄日誌
        reraise=True # 如果重試耗盡，重新引發原始異常
    )
    def fetch_alpha_vantage_data(ticker_symbol: str, api_key: str) -> pd.DataFrame | None:
        """
        從 Alpha Vantage API (使用免費 TIME_SERIES_DAILY 功能) 獲取指定 ticker 的日頻數據。

        Args:
            ticker_symbol: 要獲取的股票/ETF 代碼。
            api_key: Alpha Vantage API 金鑰。

        Returns:
            包含歷史數據的 Pandas DataFrame，如果失敗則返回 None。
            DataFrame 索引為日期 (DatetimeIndex)，列名為標準化名稱 (Open, High, Low, Close, Volume)。
        """
        # **修改:** 改用免費的 TIME_SERIES_DAILY 功能
        function = "TIME_SERIES_DAILY"
        outputsize = "full" # 獲取完整歷史數據
        datatype = "json"
        base_url = "https://www.alphavantage.co/query"

        params = {
            "function": function,
            "symbol": ticker_symbol,
            "outputsize": outputsize,
            "datatype": datatype,
            "apikey": api_key
        }
        headers = {'User-Agent': _user_agent}

        logger.debug(f"向 Alpha Vantage 發送請求 ({function})：{ticker_symbol}")
        try:
            response = requests.get(base_url, params=params, headers=headers, timeout=30) # 設置超時
            response.raise_for_status() # 檢查 HTTP 錯誤 (例如 4xx, 5xx)

            data = response.json()

            # 檢查 Alpha Vantage 返回的特定錯誤或信息
            if "Error Message" in data:
                error_message = data["Error Message"]
                logger.error(f"Alpha Vantage API 錯誤 ({ticker_symbol}): {error_message}")
                return None
            if "Information" in data:
                # 處理速率限制信息
                info_message = data["Information"]
                logger.warning(f"Alpha Vantage API 信息 ({ticker_symbol}): {info_message}")
                if "call frequency" in info_message.lower():
                     # 記錄警告並返回 None，讓外層循環處理。
                    pass
                return None

            # 檢查核心數據是否存在
            if "Time Series (Daily)" not in data:
                logger.error(f"Alpha Vantage API 回應缺少 'Time Series (Daily)' 鍵 ({ticker_symbol})。回應: {str(data)[:500]}...") # 記錄部分回應
                return None

            # 解析時間序列數據
            time_series = data["Time Series (Daily)"]
            df = pd.DataFrame.from_dict(time_series, orient='index')

            # 轉換索引為日期時間對象
            df.index = pd.to_datetime(df.index)

            # **修改:** 重命名列以匹配 TIME_SERIES_DAILY 的輸出
            df.rename(columns={
                '1. open': 'Open',
                '2. high': 'High',
                '3. low': 'Low',
                '4. close': 'Close',
                '5. volume': 'Volume'
                # 不再有 adjusted close, dividend, split
            }, inplace=True)

            # 轉換數據類型為數值型
            numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce') # 無法轉換的設為 NaT

            # 按日期升序排序
            df.sort_index(ascending=True, inplace=True)

            # **新增:** 檢查是否只返回了少量數據點 (可能表示 API 問題或 Ticker 問題)
            if len(df) < 20: # 設置一個閾值，例如少於 20 個數據點就發出警告
                logger.warning(f"Alpha Vantage 為 {ticker_symbol} 返回的數據點過少 ({len(df)} 行)，請檢查數據是否完整。")
                _cell_warnings.append(f"警告：{ticker_symbol} 返回的數據點過少 ({len(df)} 行)。")


            logger.debug(f"成功解析 {ticker_symbol} 的數據。")
            return df

        except requests.exceptions.HTTPError as http_err:
            logger.error(f"HTTP 錯誤 ({ticker_symbol}): {http_err}。回應: {response.text[:500]}...")
            return None
        except requests.exceptions.RequestException as req_err:
            logger.error(f"請求錯誤 ({ticker_symbol})，重試後失敗: {req_err}")
            raise
        except json.JSONDecodeError as json_err:
            logger.error(f"JSON 解析錯誤 ({ticker_symbol}): {json_err}。回應: {response.text[:500]}...")
            return None
        except (KeyError, TypeError, ValueError) as parse_err:
            logger.error(f"解析 Alpha Vantage 回應時發生錯誤 ({ticker_symbol}): {parse_err}", exc_info=True)
            return None
        except Exception as e:
            logger.error(f"獲取或處理 {ticker_symbol} 數據時發生未預期錯誤: {e}", exc_info=True)
            raise

    logger.info("Alpha Vantage 數據獲取函數定義完成。")
    _cell_notes.append("已定義 Alpha Vantage 數據獲取函數 (使用免費 API，含重試)。")

    # --- 6.4. 定義 Tickers 並迭代獲取數據 ---
    _tickers_to_fetch = {
        'SPY': 'df_spy',
        'HYG': 'df_hyg',
        'LQD': 'df_lqd'
    }
    _fetch_success_count = 0
    _fetch_error_count = 0

    _cell_inputs['Tickers'] = list(_tickers_to_fetch.keys())
    logger.info(f"步驟 3：開始獲取 Alpha Vantage Tickers: {list(_tickers_to_fetch.keys())}...")
    print(f"步驟 3：開始獲取 Alpha Vantage Tickers: {list(_tickers_to_fetch.keys())}")

    # 檢查 API Key 是否有效
    if not ALPHA_VANTAGE_API_KEY_VALUE:
         raise ValueError("Alpha Vantage API Key 無效或未載入。")

    for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
        logger.info(f"正在獲取 {ticker_symbol} 的數據...")
        print(f" - 正在獲取 {ticker_symbol}...")
        try:
            # 調用獲取函數
            fetched_df = fetch_alpha_vantage_data(ticker_symbol, ALPHA_VANTAGE_API_KEY_VALUE)

            if fetched_df is not None and isinstance(fetched_df, pd.DataFrame):
                if fetched_df.empty:
                    warn_msg = f"警告：獲取 {ticker_symbol} 的數據為空 DataFrame (可能 API 返回空)。"
                    _cell_warnings.append(warn_msg)
                    logger.warning(warn_msg)
                    print(f"   - {warn_msg}")
                    _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
                    globals()[df_variable_name] = fetched_df # 存儲空 DataFrame
                    _fetch_success_count += 1
                else:
                    # 成功獲取數據
                    globals()[df_variable_name] = fetched_df
                    success_note = f"成功獲取 {ticker_symbol} 的數據 ({len(fetched_df):,} 行)。已存儲至全局變數 {df_variable_name}。"
                    _cell_notes.append(success_note)
                    logger.info(success_note)
                    print(f"   - {success_note}")
                    _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功'
                    _cell_outputs[f'{df_variable_name}_行數'] = len(fetched_df)
                    _cell_outputs[f'{df_variable_name}_列名'] = fetched_df.columns.tolist()
                    _cell_outputs[f'{df_variable_name}_起始日期'] = fetched_df.index.min().strftime('%Y-%m-%d')
                    _cell_outputs[f'{df_variable_name}_結束日期'] = fetched_df.index.max().strftime('%Y-%m-%d')
                    _fetch_success_count += 1
            else:
                # 獲取函數返回 None，表示失敗
                _fetch_error_count += 1
                err_msg = f"獲取 {ticker_symbol} 數據失敗 (詳見先前日誌)。"
                _cell_warnings.append(err_msg)
                logger.error(err_msg)
                print(f"   - \u274C {err_msg}")
                _cell_outputs[f'{df_variable_name}_狀態'] = '獲取失敗'
                globals()[df_variable_name] = None # 確保變數為 None

        except Exception as fetch_err:
            # 捕獲 fetch_alpha_vantage_data 中可能重新引發的錯誤
            _fetch_error_count += 1
            err_msg = f"處理 {ticker_symbol} 時發生嚴重錯誤：{fetch_err.__class__.__name__}: {fetch_err}"
            _cell_warnings.append(err_msg)
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_狀態'] = f'處理失敗 ({fetch_err.__class__.__name__})'
            globals()[df_variable_name] = None

    logger.info(f"Alpha Vantage 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")
    _cell_notes.append(f"Alpha Vantage 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")

    # --- 標記成功/失敗 ---
    if _fetch_error_count == len(_tickers_to_fetch):
        _cell_status = "失敗"
        if not _cell_error: _cell_error = "所有 Alpha Vantage Tickers 數據獲取均失敗。"
        logger.error(_cell_error)
    elif _fetch_success_count == 0 and _fetch_error_count > 0:
         _cell_status = "失敗"
         if not _cell_error: _cell_error = "未能成功獲取任何 Alpha Vantage Ticker 的數據。"
         logger.error(_cell_error)
    elif _cell_status == "處理中":
        _cell_status = "成功"
        logger.info(f"{_cell_identifier} 執行成功（可能包含部分失敗或警告）。")
        print(f"--- {_cell_identifier} 執行成功 ---")
        _cell_notes.append("儲存格執行成功。")

# --- 7. 整個儲存格的異常處理 ---
except (NameError, ValueError, ImportError, EnvironmentError, userdata.SecretNotFoundError) as prereq_err:
    _cell_status = "失敗"
    if not _cell_error: _cell_error = f"配置、環境或先決條件錯誤：{prereq_err.__class__.__name__}：{prereq_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")
except Exception as e: # 捕獲所有其他意外錯誤
    if _cell_status == "處理中":
        _cell_status = "失敗"
        _cell_error = f"意外錯誤：{e.__class__.__name__}：{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} 因意外錯誤而失敗：{_cell_error}", exc_info=True)
        except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
        print(f"\u274C 執行失敗：{_cell_error}")
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} 為錯誤捕獲了回退 traceback：{_cell_error}", exc_info=True)
         except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")


finally:
    # --- 8. 強制性的執行總結報告和追蹤器更新 ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # 根據狀態和警告確定最終狀態圖標和文本
    _final_status_text = _cell_status
    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "已跳過": _final_status_icon = "🚫"
    elif _cell_status == "處理中": _final_status_icon = "⏳"; _final_status_text = "未完成"; _cell_notes.append("警告：儲存格以 '處理中' 狀態結束。")
    elif _cell_warnings: _final_status_icon = "⚠️"; _final_status_text = "成功（有警告）" if _cell_status == "成功" else _cell_status
    elif _cell_status == "成功": _final_status_icon = "✅"
    else: _final_status_icon = "❓"; _cell_notes.append(f"警告：儲存格以無法識別的狀態 '{_cell_status}' 結束。")

    # 安全地獲取當前時間戳
    _current_time_str = "無法獲取"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict): _report_tz_info = PROJECT_CONFIG.get('_tz_info', timezone(timedelta(hours=8)))
        else: _report_tz_info = timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"

    # 更新輸出摘要
    if '_tickers_to_fetch' in locals() and isinstance(_tickers_to_fetch, dict):
        for ticker_symbol, df_variable_name in _tickers_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df = globals()[df_variable_name]
                  if not df.empty:
                       if f'{df_variable_name}_行數' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_行數'] = len(df)
                       if f'{df_variable_name}_列名' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_列名'] = df.columns.tolist()
                       if f'{df_variable_name}_起始日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_起始日期'] = df.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_結束日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_結束日期'] = df.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_最新數據 ({df.index.max().strftime("%Y-%m-%d")})'] = df.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
             elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取失敗 (變數未創建)'
    else: _cell_notes.append("無法更新輸出摘要，因為 _tickers_to_fetch 未定義。")

    # 建構追蹤記錄
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }

    # 安全地更新全局追蹤器
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"錯誤：EXECUTION_TRACKER 無效。無法更新 {_cell_identifier} 的追蹤記錄。"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"錯誤：更新 EXECUTION_TRACKER 時異常：{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    # --- 打印執行總結報告 ---
    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格：{_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon} {_final_status_text}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒")
    print(f"** 完成時間：** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 輸入參數：**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記：**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息：**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息：**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))
    print("\n** \U0001F4CA 輸出 / 檢查結果摘要：**")
    tracked_outputs = _tracking_record.get('outputs')
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else:
        filtered_outputs = {k: v for k, v in tracked_outputs.items() if '列名' not in k and '最新數據' not in k}; pprint.pprint(filtered_outputs, indent=2, width=70, sort_dicts=False)
        for k, v in tracked_outputs.items():
             if '最新數據' in k: print(f"- {k}:"); pprint.pprint(v, indent=4, width=65)
    print("="*80 + "\n")

    # --- 9. 清理局部變數 (包括 API Key！) ---
    logger.info(f"清理 {_cell_identifier} 的局部變數...")
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_api_key_name', '_api_key_load_status',
        '_tickers_to_fetch', '_fetch_success_count', '_fetch_error_count',
        'ticker_symbol', 'df_variable_name', 'fetched_df', 'warn_msg', 'err_msg',
        'success_note', 'load_key_note', 'prereq_err', 'secret_err', 'fetch_err', 'e',
        'time_err', 'time_err_local', 'tracker_update_err', '_guideline_version_str',
        'filtered_outputs', 'info_text', 'df', 'k', 'v', '_COLAB_USERDATA_AVAILABLE',
        '_retry_wait', '_retry_stop', '_user_agent', 'fetch_alpha_vantage_data',
        'function', 'outputsize', 'datatype', 'base_url', 'params', 'headers',
        'response', 'data', 'error_message', 'info_message', 'time_series',
        'numeric_cols', 'col', 'http_err', 'req_err', 'json_err', 'parse_err'
    ]
    # 清理大寫的 API Key 變數 (非常重要！)
    _vars_to_clean.append('ALPHA_VANTAGE_API_KEY_VALUE')

    # 清理可能從外部導入的 userdata
    if '_COLAB_USERDATA_AVAILABLE' in locals() and _COLAB_USERDATA_AVAILABLE:
        _vars_to_clean.append('userdata')

    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals(): # 也檢查全局，以防萬一
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 4: Alpha Vantage 數據獲取 (SPY, HYG, LQD)
# 功能: 使用 Alpha Vantage API (免費 TIME_SERIES_DAILY 功能) 獲取 SPY, HYG, LQD 的日頻歷史價格與成交量數據。
# 版本: 3.4-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 2', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:requests', 'global:pd', 'global:tenacity', 'global:colab_userdata']
# 輸入: ['Secret:ALPHA_VANTAGE_API_KEY', 'global:PROJECT_CONFIG']
# 輸出: ['global:df_spy', 'global:df_hyg', 'global:df_lqd', 'global:EXECUTION_TRACKER (updated)']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 5: FRED 數據獲取 (核心指標)
# --------------------------------------------------
# 功能: 使用 fredapi 函式庫獲取 FRED 經濟數據 (FEDFUNDS, INDPRO, SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD)。
# 版本: 3.4.1-zh-fc (對應準則 v3.4，擴充獲取序列)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:pd', 'global:fredapi', 'global:colab_userdata']
# 輸入: ['Secret:FRED_API_KEY', 'global:PROJECT_CONFIG']
# 輸出: ['global:df_fedfunds', 'global:df_indpro', 'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', 'global:df_wresbal', 'global:df_rrpontsyd', 'global:EXECUTION_TRACKER (updated)'] # 將數據存為全局變數
# --------------------------------------------------
# ==================================================
"""
使用 fredapi 函式庫獲取宏觀經濟數據。

此儲存格執行以下步驟：
1.  執行必要全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 和函式庫 (`pd`, `fredapi`, `colab_userdata`) 的先決條件檢查。
2.  安全地從 Colab Secrets 載入 FRED API Key (`FRED_API_KEY`)，並存儲到大寫變數 `FRED_API_KEY_VALUE` 中。
3.  定義需要獲取的 FRED Series IDs：'FEDFUNDS', 'INDPRO', 'SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'RRPONTSYD'。
4.  使用 API Key 實例化 `Fred` 客戶端。
5.  迭代處理每個 Series ID：
    a. 使用 `fred_client.get_series(series_id)` 獲取數據。
    b. 包含錯誤處理，以應對無效 API Key、無效 Series ID 或網路連線問題。
    c. 將成功獲取的 Pandas Series 轉換為 DataFrame，並儲存到對應的全局變數中 (例如 `df_fedfunds`, `df_sofr` 等)。
6.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要（例如 API Key 狀態、獲取到的數據行數）並更新 `EXECUTION_TRACKER`。 **特別注意：在 finally 區塊中清理 API Key 變數。**

設計說明：
* 使用 `fredapi` 函式庫簡化 FRED 數據的獲取。
* 嚴格遵守 v3.4 的 API Key 命名和安全處理規範。
* 對 `fredapi` 可能引發的錯誤進行處理。
* 將數據直接存儲為全局變數以便後續使用。
* **注意:** INDPRO 是工業生產指數，作為 ISM PMI 的代理，其經濟意義不同。
* **注意:** 未包含 MOVE 指數的獲取，因其通常無法透過免費 FRED API 取得。

參數：
    無 (依賴全局變數、函式庫和 Colab Secrets)。

返回：
    無 (創建或更新全局 DataFrame 變數，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數或函式庫未定義。
    userdata.SecretNotFoundError: 如果在 Colab Secrets 中找不到 `FRED_API_KEY`。
    ValueError: 如果 API Key 無效，或 Series ID 無效，或 fredapi 內部發生錯誤。
    Exception: 捕獲其他意外錯誤，例如網路問題。

假設：
* Cell 1 和 Cell 2 已成功執行。
* `pandas` (pd), `fredapi`, `colab_userdata` 已成功導入。
* 名為 'FRED_API_KEY' 的 Secret 已在 Colab 中設定且值有效。
* Colab 環境可以訪問 FRED API。
* 指定的 Series IDs 在 FRED 上是有效的。

潛在問題 / 考量：
* FRED API 的請求限制。
* Series ID 可能會變更或停用。
* 數據發布可能存在延遲。

下一步：
* 執行 Cell 6 (NY Fed 一級交易商數據獲取與處理)。
* 執行 Cell Z 查看整體執行狀態。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # 確保 datetime 組件可用

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 5: FRED 數據獲取 (核心指標)" # 更新標識符

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中" # 初始狀態
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {} # 記錄實際使用的輸入參數
_cell_outputs = {} # 記錄關鍵輸出信息/摘要
_cell_generated_files = [] # 此 Cell 不生成文件

# --- 4. API Key 變數 (遵循大寫規則) ---
FRED_API_KEY_VALUE = None # 初始化為 None

# --- 5. 全局 DataFrame 變數初始化 (包含新增的序列) ---
df_fedfunds = None
df_indpro = None
df_sofr = None
df_dgs10 = None
df_dgs2 = None
df_wresbal = None
df_rrpontsyd = None
_series_to_fetch = {} # 初始化為空字典

# --- 6. 主要腳本主體 ---
try:
    # --- 6.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4.1-zh-fc) 開始執行 ---") # 更新版本號
    print(f"\n--- {_cell_identifier} (v3.4.1-zh-fc) 開始執行 ---")

    # 檢查來自 Cell 1 的基本全局變數和函式庫
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        raise NameError("嚴重錯誤：全局變數 PROJECT_CONFIG 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        raise NameError("嚴重錯誤：全局變數 EXECUTION_TRACKER 未定義或不是字典。請確保 Cell 1 已成功運行。")
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        raise NameError("嚴重錯誤：全局變數 logger 未定義或不是 Logger 實例。請確保 Cell 1 已成功運行。")
    if 'pd' not in globals() or not hasattr(pd, 'DataFrame'):
        raise NameError("嚴重錯誤：pandas 函式庫 (pd) 未成功導入。請檢查 Cell 1。")
    if 'fredapi' not in globals() or not hasattr(fredapi, 'Fred'):
        raise NameError("嚴重錯誤：fredapi 函式庫未成功導入。請檢查 Cell 1。")
    try:
        from google.colab import userdata
        _COLAB_USERDATA_AVAILABLE = True
    except ImportError:
        _COLAB_USERDATA_AVAILABLE = False
        userdata = None # 設置為 None 以便後續檢查
        warn_msg = "警告：無法導入 google.colab.userdata。將無法從 Secrets 載入 API Key。"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(warn_msg)
        # 如果 API Key 是必需的，這裡應該引發錯誤
        # raise EnvironmentError("無法訪問 Colab Secrets，無法繼續獲取 FRED 數據。")

    logger.info("先決條件檢查通過。")
    _cell_notes.append("先決條件檢查通過。")

    # --- 6.2. 安全載入 FRED API Key ---
    logger.info("步驟 1：安全載入 FRED API Key...")
    print("步驟 1：安全載入 FRED API Key...")
    _api_key_name = 'FRED_API_KEY' # Secrets 中的名稱 (符合規範)
    _cell_inputs['請求的 Secret 名稱'] = _api_key_name
    _api_key_load_status = "未嘗試 (userdata 不可用)"

    if _COLAB_USERDATA_AVAILABLE:
        try:
            FRED_API_KEY_VALUE = userdata.get(_api_key_name)
            if FRED_API_KEY_VALUE:
                load_key_note = f"成功從 Colab Secrets 載入 '{_api_key_name}'。"
                _cell_notes.append(load_key_note)
                logger.info(load_key_note)
                print(f" - {load_key_note}")
                _api_key_load_status = '成功'
            else:
                # Key 存在但值為空
                warn_msg = f"警告：從 Colab Secrets 載入的 '{_api_key_name}' 值為空。FRED API 將無法使用。"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f" - {warn_msg}")
                _api_key_load_status = '成功 (值為空)'
                # 引發錯誤，因為空 Key 無法使用
                raise ValueError(f"FRED API Key '{_api_key_name}' 的值為空。")
        except userdata.SecretNotFoundError:
            err_msg = f"錯誤：在 Colab Secrets 中未找到名為 '{_api_key_name}' 的 Secret。請檢查是否已設定。"
            _cell_error = err_msg
            logger.error(err_msg)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = '失敗 (未找到)'
            # 引發錯誤，因為沒有 Key 無法繼續
            raise userdata.SecretNotFoundError(err_msg)
        except Exception as secret_err:
            err_msg = f"讀取 Colab Secret '{_api_key_name}' 時發生意外錯誤：{secret_err.__class__.__name__}: {secret_err}"
            _cell_error = err_msg
            logger.error(err_msg, exc_info=True)
            print(f" - \u274C {err_msg}")
            _api_key_load_status = f'失敗 ({secret_err.__class__.__name__})'
            # 引發錯誤
            raise Exception(err_msg) from secret_err
    else:
        # userdata 不可用，無法獲取 Key
        _api_key_load_status = "失敗 (userdata 不可用)"
        # 引發錯誤，因為沒有 Key 無法繼續
        raise EnvironmentError("無法訪問 Colab Secrets，無法獲取 FRED API Key。")

    _cell_outputs['API Key 載入狀態'] = _api_key_load_status
    logger.info("FRED API Key 載入檢查完成。")

    # --- 6.3. 實例化 Fred 客戶端 ---
    logger.info("步驟 2：實例化 Fred 客戶端...")
    print("步驟 2：實例化 Fred 客戶端...")
    fred_client = None # 初始化為 None
    try:
        if not FRED_API_KEY_VALUE:
            # 這個錯誤應該在步驟 6.2 被捕獲並引發，但再次檢查以防萬一
            raise ValueError("FRED API Key 無效或未載入。")

        fred_client = fredapi.Fred(api_key=FRED_API_KEY_VALUE)
        client_note = "Fred 客戶端實例化成功。"
        _cell_notes.append(client_note)
        logger.info(client_note)
        print(f" - {client_note}")
        _cell_outputs['Fred 客戶端狀態'] = '成功'

    except Exception as client_err:
        err_msg = f"實例化 Fred 客戶端時發生錯誤：{client_err.__class__.__name__}: {client_err}"
        _cell_error = err_msg
        logger.error(err_msg, exc_info=True)
        print(f" - \u274C {err_msg}")
        _cell_outputs['Fred 客戶端狀態'] = f'失敗 ({client_err.__class__.__name__})'
        # 如果客戶端實例化失敗，則無法繼續
        raise Exception(err_msg) from client_err

    # --- 6.4. 定義 Series IDs 並迭代獲取數據 (包含新增的序列) ---
    _series_to_fetch = {
        'FEDFUNDS': 'df_fedfunds',
        'INDPRO': 'df_indpro', # 工業生產指數 (PMI 代理)
        'SOFR': 'df_sofr',     # 擔保隔夜融資利率
        'DGS10': 'df_dgs10',   # 10年期美債固定期限利率
        'DGS2': 'df_dgs2',    # 2年期美債固定期限利率
        'WRESBAL': 'df_wresbal', # 聯準會銀行準備金餘額 (週頻)
        'RRPONTSYD': 'df_rrpontsyd' # 隔夜逆回購協議量 (日頻)
        # 注意: MOVE 指數通常不在 FRED API 中
    }
    _fetch_success_count = 0
    _fetch_error_count = 0

    _cell_inputs['Series IDs'] = list(_series_to_fetch.keys())
    logger.info(f"步驟 3：開始獲取 FRED Series IDs: {list(_series_to_fetch.keys())}...")
    print(f"步驟 3：開始獲取 FRED Series IDs: {list(_series_to_fetch.keys())}")

    if not fred_client:
        # 如果客戶端未成功創建，則無法繼續
        raise RuntimeError("Fred 客戶端未成功實例化。")

    for series_id, df_variable_name in _series_to_fetch.items():
        logger.info(f"正在獲取 {series_id} 的數據...")
        print(f" - 正在獲取 {series_id}...")
        try:
            # 獲取時間序列數據 (返回 Pandas Series)
            series_data = fred_client.get_series(series_id)

            if series_data.empty:
                warn_msg = f"警告：獲取 {series_id} 的數據為空 Series。請檢查 Series ID。"
                _cell_warnings.append(warn_msg)
                logger.warning(warn_msg)
                print(f"   - {warn_msg}")
                _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
                # 將空 Series 轉換為 DataFrame 存儲
                globals()[df_variable_name] = series_data.to_frame(name=series_id)
                globals()[df_variable_name].index.name = 'Date' # 確保索引名為 Date
                _fetch_success_count += 1
            else:
                # 成功獲取數據
                # 將 Series 轉換為 DataFrame，索引命名為 'Date'，列命名為 Series ID
                df = series_data.to_frame(name=series_id)
                df.index.name = 'Date' # 確保索引名為 Date
                globals()[df_variable_name] = df

                success_note = f"成功獲取 {series_id} 的數據 ({len(df):,} 行)。已存儲至全局變數 {df_variable_name}。"
                _cell_notes.append(success_note)
                logger.info(success_note)
                print(f"   - {success_note}")
                _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功'
                _cell_outputs[f'{df_variable_name}_行數'] = len(df)
                _cell_outputs[f'{df_variable_name}_列名'] = df.columns.tolist()
                _cell_outputs[f'{df_variable_name}_起始日期'] = df.index.min().strftime('%Y-%m-%d')
                _cell_outputs[f'{df_variable_name}_結束日期'] = df.index.max().strftime('%Y-%m-%d')
                _fetch_success_count += 1

        except ValueError as val_err:
             # fredapi 在找不到 series 或 key 無效時可能引發 ValueError
            _fetch_error_count += 1
            err_msg = f"獲取 {series_id} 數據時發生錯誤 (可能是無效 ID 或 Key): {val_err}"
            _cell_warnings.append(err_msg) # 記錄為警告
            logger.error(err_msg, exc_info=False)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_狀態'] = f'獲取失敗 (ValueError)'
            globals()[df_variable_name] = None # 確保變數為 None
        except Exception as e:
            # 捕獲其他潛在錯誤 (例如網路問題)
            _fetch_error_count += 1
            err_msg = f"獲取 {series_id} 數據時發生意外錯誤：{e.__class__.__name__}: {e}"
            _cell_warnings.append(err_msg) # 記錄為警告
            logger.error(err_msg, exc_info=True)
            print(f"   - \u274C {err_msg}")
            _cell_outputs[f'{df_variable_name}_狀態'] = f'獲取失敗 ({e.__class__.__name__})'
            globals()[df_variable_name] = None

    logger.info(f"FRED 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")
    _cell_notes.append(f"FRED 數據獲取完成。成功: {_fetch_success_count}, 失敗: {_fetch_error_count}。")

    # --- 標記成功/失敗 ---
    if _fetch_error_count == len(_series_to_fetch):
        # 如果所有 series 都獲取失敗
        _cell_status = "失敗"
        if not _cell_error: _cell_error = "所有 FRED Series 數據獲取均失敗。"
        logger.error(_cell_error)
    elif _fetch_success_count == 0 and _fetch_error_count > 0:
         # 沒有成功，但至少嘗試了
         _cell_status = "失敗"
         if not _cell_error: _cell_error = "未能成功獲取任何 FRED Series 的數據。"
         logger.error(_cell_error)
    elif _cell_status == "處理中": # 確保不是已被標記為失敗
        _cell_status = "成功" # 只要至少有一個成功
        logger.info(f"{_cell_identifier} 執行成功（可能包含部分失敗或警告）。")
        print(f"--- {_cell_identifier} 執行成功 ---")
        _cell_notes.append("儲存格執行成功。")

# --- 7. 整個儲存格的異常處理 ---
except (NameError, ValueError, ImportError, EnvironmentError, userdata.SecretNotFoundError) as prereq_err:
    _cell_status = "失敗"
    # 如果 _cell_error 已被設置 (例如 Secret 未找到 或 Client 實例化失敗)，則使用它
    if not _cell_error: _cell_error = f"配置、環境或先決條件錯誤：{prereq_err.__class__.__name__}：{prereq_err}"
    _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\u274C 執行失敗：{_cell_error}")
except Exception as e: # 捕獲所有其他意外錯誤
    if _cell_status == "處理中":
        _cell_status = "失敗"
        _cell_error = f"意外錯誤：{e.__class__.__name__}：{e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} 因意外錯誤而失敗：{_cell_error}", exc_info=True)
        except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
        print(f"\u274C 執行失敗：{_cell_error}")
    elif not _cell_traceback:
         _cell_traceback = traceback.format_exc()
         try: logger.error(f"{_cell_identifier} 為錯誤捕獲了回退 traceback：{_cell_error}", exc_info=True)
         except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")


finally:
    # --- 8. 強制性的執行總結報告和追蹤器更新 ---
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    # 根據狀態和警告確定最終狀態圖標和文本
    _final_status_text = _cell_status
    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "已跳過": _final_status_icon = "🚫"
    elif _cell_status == "處理中": _final_status_icon = "⏳"; _final_status_text = "未完成"; _cell_notes.append("警告：儲存格以 '處理中' 狀態結束。")
    elif _cell_warnings: _final_status_icon = "⚠️"; _final_status_text = "成功（有警告）" if _cell_status == "成功" else _cell_status
    elif _cell_status == "成功": _final_status_icon = "✅"
    else: _final_status_icon = "❓"; _cell_notes.append(f"警告：儲存格以無法識別的狀態 '{_cell_status}' 結束。")

    # 安全地獲取當前時間戳
    _current_time_str = "無法獲取"
    try:
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict): _report_tz_info = PROJECT_CONFIG.get('_tz_info_obj', timezone(timedelta(hours=8))) # 使用 _tz_info_obj
        else: _report_tz_info = timezone(timedelta(hours=8))
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗": _cell_warnings.append(f"報告時間獲取錯誤: {time_err}")

    # 更新輸出摘要 (包含新序列的狀態)
    if '_series_to_fetch' in locals() and isinstance(_series_to_fetch, dict):
        for series_id, df_variable_name in _series_to_fetch.items():
             if df_variable_name in globals() and isinstance(globals()[df_variable_name], pd.DataFrame):
                  df = globals()[df_variable_name]
                  if not df.empty:
                       if f'{df_variable_name}_行數' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_行數'] = len(df)
                       if f'{df_variable_name}_列名' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_列名'] = df.columns.tolist()
                       if f'{df_variable_name}_起始日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_起始日期'] = df.index.min().strftime('%Y-%m-%d')
                       if f'{df_variable_name}_結束日期' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_結束日期'] = df.index.max().strftime('%Y-%m-%d')
                       try: _cell_outputs[f'{df_variable_name}_最新數據 ({df.index.max().strftime("%Y-%m-%d")})'] = df.iloc[-1].to_dict()
                       except: pass
                  elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取成功 (數據為空)'
             elif f'{df_variable_name}_狀態' not in _cell_outputs: _cell_outputs[f'{df_variable_name}_狀態'] = '獲取失敗 (變數未創建)'
    else: _cell_notes.append("無法更新輸出摘要，因為 _series_to_fetch 未定義。")

    # 建構追蹤記錄
    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }

    # 安全地更新全局追蹤器
    try:
        if 'EXECUTION_TRACKER' in globals() and isinstance(EXECUTION_TRACKER, dict): EXECUTION_TRACKER[_cell_identifier] = _tracking_record
        else: err_msg = f"錯誤：EXECUTION_TRACKER 無效。無法更新 {_cell_identifier} 的追蹤記錄。"; print(err_msg); logger.error(err_msg)
    except Exception as tracker_update_err: err_msg = f"錯誤：更新 EXECUTION_TRACKER 時異常：{tracker_update_err}"; print(err_msg); logger.error(err_msg, exc_info=True)

    # --- 打印執行總結報告 ---
    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格：{_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon} {_final_status_text}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒")
    print(f"** 完成時間：** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 輸入參數：**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記：**"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息：**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息：**\n** {_tracking_record['error']} **")
    if _tracking_record.get('traceback'): print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20 + f"\n<pre>{_tracking_record['traceback']}</pre>\n" + "-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))
    print("\n** \U0001F4CA 輸出 / 檢查結果摘要：**")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else:
        # 過濾掉可能過長的預覽信息
        filtered_outputs = {k: v for k, v in tracked_outputs.items() if '列名' not in k and '最新數據' not in k}
        pprint.pprint(filtered_outputs, indent=2, width=70, sort_dicts=False)
        # 單獨打印最新數據預覽（如果存在且不過長）
        # for k, v in tracked_outputs.items():
        #      if '最新數據' in k: print(f"- {k}:"); pprint.pprint(v, indent=4, width=65) # 可選
    print("="*80 + "\n")

    # --- 9. 清理局部變數 (包括 API Key！) ---
    logger.info(f"清理 {_cell_identifier} 的局部變數...")
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_warnings', '_cell_notes', '_cell_error', '_cell_traceback',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_api_key_name', '_api_key_load_status',
        '_series_to_fetch', '_fetch_success_count', '_fetch_error_count',
        'series_id', 'df_variable_name', 'series_data', 'df', 'warn_msg', 'err_msg',
        'success_note', 'load_key_note', 'client_note', 'prereq_err', 'secret_err',
        'client_err', 'val_err', 'e', 'time_err', 'time_err_local',
        'tracker_update_err', '_guideline_version_str', 'filtered_outputs',
        'info_text', 'k', 'v', '_COLAB_USERDATA_AVAILABLE', 'fred_client'
    ]
    # 清理大寫的 API Key 變數 (非常重要！)
    _vars_to_clean.append('FRED_API_KEY_VALUE')

    # 清理可能從外部導入的 userdata
    if '_COLAB_USERDATA_AVAILABLE' in locals() and _COLAB_USERDATA_AVAILABLE:
        _vars_to_clean.append('userdata')

    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals(): # 也檢查全局，以防萬一
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4.1-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 5: FRED 數據獲取 (核心指標)
# 功能: 使用 fredapi 函式庫獲取 FRED 經濟數據 (FEDFUNDS, INDPRO, SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD)。
# 版本: 3.4.1-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:EXECUTION_TRACKER', 'global:logger', 'global:pd', 'global:fredapi', 'global:colab_userdata']
# 輸入: ['Secret:FRED_API_KEY', 'global:PROJECT_CONFIG']
# 輸出: ['global:df_fedfunds', 'global:df_indpro', 'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', 'global:df_wresbal', 'global:df_rrpontsyd', 'global:EXECUTION_TRACKER (updated)']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 6: NY Fed 一級交易商數據獲取與處理 (已修正 KeyError & NameError & TZ)
# --------------------------------------------------
# 功能: 從 NY Fed 網站下載多個 Excel 文件，解析一級交易商公債持有量數據，
#       根據 SBN/SBP 規則加總，並合併成單一時間序列。
# 版本: 3.4.4-zh-fc (對應準則 v3.4，中文註解版，修正 finally TZ 讀取)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# 輸入: ['global:PROJECT_CONFIG'] (讀取 URLs 和 SBP 加總欄位)
# 輸出: ['global:nyfed_positions_series', 'global:EXECUTION_TRACKER (updated)'] # 持有量數據 Series
# --------------------------------------------------
# ==================================================
"""
從紐約聯儲 (NY Fed) 獲取並處理一級交易商的美國公債持有量數據。

此儲存格執行以下步驟：
1.  執行必要全局變數 (`PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger`) 和函式庫 (`pd`, `requests`, `io`, `openpyxl`) 的先決條件檢查。
2.  從 `PROJECT_CONFIG` 獲取 NY Fed Excel 文件的 URL 列表以及 SBP 文件需要加總的欄位列表。
3.  初始化 `requests.Session` 以便複用連線和設定 User-Agent。
4.  循環遍歷 URL 列表：
    a. **下載文件:** 使用 `session.get` 下載 Excel 文件內容至記憶體 (`io.BytesIO`)，處理請求錯誤。
    b. **解析 Excel:** 嘗試使用 `pd.read_excel` 讀取數據，包含自動檢測表頭和日期列的邏輯，處理讀取和解析錯誤。
    c. **數據清理 (長格式):**
        i.  嘗試將索引轉換為 DatetimeIndex，無法轉換的設為 NaT。
        ii. **修正:** 移除索引為 NaT 的行。
        iii.標準化日期索引 (移除時間)。
        iv. 檢查必要的 'Time Series' 和 'Value' 欄位是否存在。
        v.  轉換 Value 列為數值型，移除 Value 或 Time Series 為 NaN 的行。
    d. **轉換格式 (寬格式):** 使用 `pd.pivot_table` 將數據從長格式轉為寬格式，處理可能的重複項。
    e. **識別加總欄位:** 根據 URL 中是否包含 'SBN' 或 'SBP' 以及年份（從 URL 推斷），確定需要加總的欄位。
    f. **執行加總:** 僅加總 DataFrame 中實際存在的目標欄位，確保數據為數值型，計算行總和。
    g. **清理加總結果:** 移除結果中的 NaN 和 0 值。
    h. **儲存單檔結果:** 將有效的加總 Series 添加到列表中。
5.  **合併所有結果:** 使用 `pd.concat` 合併所有成功處理的文件的 Series。
6.  **排序與去重:** 按日期索引升序排序，並使用 `groupby(level=0).last()` 處理可能重疊的日期（保留最新下載文件的數據）。
7.  將最終的持有量時間序列賦值給全局變數 `nyfed_positions_series`。若無有效數據，則賦值一個空的 Series。
8.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要（例如處理的文件數、失敗的文件列表、最終序列的信息）並更新 `EXECUTION_TRACKER`。**修正:** 調整了 finally 區塊中讀取時區物件的鍵名，使用 `_tz_info_obj`。

設計說明：
* 將 NY Fed 數據的複雜獲取和處理邏輯封裝在此儲存格。
* 採用了來自先前分析 (一級交易pro.py) 的成熟邏輯，並根據 v3.4 準則進行了調整和錯誤處理強化。
* **修正:** 修改了清理長格式數據的邏輯，避免因錯誤使用 `dropna(subset=[index.name])` 導致的 KeyError。現在直接檢查並移除索引中的 NaT 值。
* **修正:** 再次修正了 finally 區塊中打印 Traceback 和失敗文件列表的邏輯，避免 NameError。
* **修正:** 修正了 finally 區塊讀取時區物件時使用的鍵名，確保報告時間戳使用正確時區。
* 包含了對下載、解析、轉換、加總各步驟的詳細錯誤處理和日誌記錄。
* **重要警告:** 此流程合併了定義可能不同的 SBN (Gross?) 和 SBP (Net?) 數據。合併後的序列代表一種混合的總量概念，在解釋最終結果時需要特別注意這一點，並在儀表板或報告中明確說明。

參數：
    無 (依賴全局變數 `PROJECT_CONFIG`, `EXECUTION_TRACKER`, `logger` 和已載入的函式庫)。

返回：
    無 (創建或更新全局 Pandas Series 變數 `nyfed_positions_series`，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    (同上一版本)

假設：
    (同上一版本)

潛在問題 / 考量：
    (同上一版本)

下一步：
* 執行 Cell 7 (合併所有數據源)。
* 執行 Cell Z 查看整體執行狀態，確認 `nyfed_positions_series` 是否已成功生成。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
import io
import os
from datetime import datetime, timezone, timedelta # 添加 timedelta

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    import requests
    import openpyxl
    print("NY Fed 數據處理所需函式庫 (pandas, numpy, requests, openpyxl, io) 看似可用。")
    _libs_ok = True
except ImportError as import_err:
    print(f"警告：導入 NY Fed 數據處理所需函式庫失敗({import_err})。")
    pd = None; np = None; requests = None; openpyxl = None
    _libs_ok = False

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 6: NY Fed 一級交易商數據獲取與處理 (已修正 KeyError & NameError & TZ)" # 更新標識符

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. 全局變數定義 (此 Cell 的主要輸出) ---
global nyfed_positions_series
nyfed_positions_series = None

# --- 5. 主要腳本主體 ---
try:
    # --- 5.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4.4-zh-fc) 開始執行 ---") # 更新版本號
    print(f"\n--- {_cell_identifier} (v3.4.4-zh-fc) 開始執行 ---")
    print("*** \u26A0\uFE0F 警告：此步驟將合併定義可能不同的 SBN(Gross?) 和 SBP(Net?) 數據！解釋需謹慎！ ***")
    _cell_warnings.append("合併了定義可能不同的 SBN(Gross?) 和 SBP(Net?) 數據，解釋需謹慎。")

    if not _libs_ok:
        _cell_status = "失敗"; _cell_error = "依賴錯誤：缺少必要函式庫 (pandas, numpy, requests, openpyxl)。"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "失敗"; _cell_error = "依賴錯誤：Cell 1 的 libs_loaded 變數未找到。"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('requests') or not libs_loaded.get('openpyxl'):
         warn_msg = "警告：根據 Cell 1 記錄，pandas, requests 或 openpyxl 可能未完全初始化。"
         _cell_warnings.append(warn_msg); logger.warning(warn_msg)

    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        _cell_status = "失敗"; _cell_error = "依賴錯誤：找不到有效的 PROJECT_CONFIG。"; raise NameError(_cell_error)
    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        _cell_status = "失敗"; _cell_error = "依賴錯誤：找不到有效的 EXECUTION_TRACKER。"; raise NameError(_cell_error)
    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        logger = logging.getLogger(__name__)
        if not isinstance(logger, logging.Logger):
             _cell_status = "失敗"; _cell_error = "依賴錯誤：無法獲取有效的 logger 實例。"; raise NameError(_cell_error)
        else:
             logger.warning(f"{_cell_identifier}: Logger 在 Cell 1 可能未正確設置，已重新獲取。")
             _cell_warnings.append("Logger 在 Cell 1 可能未正確設置，已重新獲取。")

    ny_fed_urls = PROJECT_CONFIG.get('ny_fed_positions_urls', [])
    sbp2013_cols = PROJECT_CONFIG.get('sbp2013_cols_to_sum', [])
    sbp2001_cols = PROJECT_CONFIG.get('sbp2001_cols_to_sum', [])

    if not ny_fed_urls or not isinstance(ny_fed_urls, list):
        _cell_status = "失敗"; _cell_error = "配置錯誤：PROJECT_CONFIG 中未找到有效的 'ny_fed_positions_urls' 列表。"; raise ValueError(_cell_error)
    if not sbp2013_cols or not isinstance(sbp2013_cols, list):
        _cell_warnings.append("配置警告：PROJECT_CONFIG 中未找到有效的 SBP 2013 欄位加總配置 ('sbp2013_cols_to_sum')。將無法處理 SBP 2013 文件。")
        logger.warning("未找到有效的 sbp2013_cols_to_sum 配置。"); sbp2013_cols = []
    if not sbp2001_cols or not isinstance(sbp2001_cols, list):
        _cell_warnings.append("配置警告：PROJECT_CONFIG 中未找到有效的 SBP 2001 欄位加總配置 ('sbp2001_cols_to_sum')。將無法處理 SBP 2001 文件。")
        logger.warning("未找到有效的 sbp2001_cols_to_sum 配置。"); sbp2001_cols = []

    _cell_inputs['ny_fed_urls_count'] = len(ny_fed_urls)
    _cell_inputs['sbp2013_cols_config'] = sbp2013_cols
    _cell_inputs['sbp2001_cols_config'] = sbp2001_cols
    _cell_notes.append(f"準備處理 {len(ny_fed_urls)} 個 NY Fed Excel 文件。")
    logger.info("先決條件和配置檢查通過。")
    print(f"  - 步驟 0: 依賴檢查通過。準備處理 {len(ny_fed_urls)} 個 NY Fed 文件。")

    # --- 5.2. 循環處理每個 URL ---
    all_positions_data = []
    positions_fetch_success = False
    processed_files_count = 0
    failed_files = []
    session = requests.Session()
    session.headers.update({'User-Agent': PROJECT_CONFIG.get('user_agent', 'TWD-Risk-Dashboard-Colab/1.0')})

    print("  - 步驟 1: 開始循環處理 NY Fed 文件...")
    logger.info("步驟 1: 開始循環處理 NY Fed 文件...")
    for i, url in enumerate(ny_fed_urls):
        try: file_source_name = url.split('/')[-3] if len(url.split('/')) > 2 else f"File_{i+1}"
        except: file_source_name = f"File_{i+1}"

        print(f"\n    處理文件 {i+1}/{len(ny_fed_urls)} ({file_source_name})... URL: {url}")
        logger.info(f"處理文件 {i+1}/{len(ny_fed_urls)}: {url}")
        file_processed_successfully = False

        try:
            # --- 5.2.1. 下載 Excel 文件 ---
            print("      - 正在下載...", end="")
            logger.debug(f"開始下載文件：{url}")
            response_excel = session.get(url, timeout=180)
            response_excel.raise_for_status()
            excel_content = io.BytesIO(response_excel.content)
            print(" 完成.")
            logger.info(f"文件 {file_source_name}: 下載成功。")
            _cell_notes.append(f"文件 {file_source_name}: 下載成功 ({len(response_excel.content)/1024:.1f} KB)。")

            # --- 5.2.2. 解析 Excel (自動檢測表頭) ---
            print("      - 正在解析 (嘗試自動檢測表頭)...", end="")
            logger.debug(f"文件 {file_source_name}: 開始解析 Excel...")
            header_row = None; date_col_name = None; data_positions_long = None
            possible_headers = [3, 4, 0, 1, 2, 5, 6]
            parse_error_detail = ""

            for h in possible_headers:
                try:
                    excel_content.seek(0)
                    df_peek = pd.read_excel(excel_content, header=h, nrows=5, engine='openpyxl')
                    cols_lower = [str(c).lower().strip() for c in df_peek.columns]
                    time_series_col = None; value_col = None; date_col_candidate = None
                    for ts_name in ['time series', 'series id', 'series name']:
                        if ts_name in cols_lower: time_series_col = df_peek.columns[cols_lower.index(ts_name)]; break
                    for val_name in ['value (millions)', 'value', 'amount']:
                        if val_name in cols_lower: value_col = df_peek.columns[cols_lower.index(val_name)]; break
                    if 'as of date' in cols_lower: date_col_candidate = df_peek.columns[cols_lower.index('as of date')]
                    elif 'effective date' in cols_lower: date_col_candidate = df_peek.columns[cols_lower.index('effective date')]
                    elif len(df_peek.columns) > 0 and ('date' in cols_lower[0] or 'period' in cols_lower[0]): date_col_candidate = df_peek.columns[0]

                    if time_series_col and value_col and date_col_candidate:
                        header_row = h; date_col_name = date_col_candidate
                        excel_content.seek(0)
                        data_positions_long = pd.read_excel(excel_content, header=header_row, index_col=date_col_name, parse_dates=True, engine='openpyxl')
                        print(f" (檢測到有效表頭在第 {header_row+1} 行, 日期列為索引: '{date_col_name}')")
                        logger.info(f"文件 {file_source_name}: 成功檢測到表頭行 {header_row}, 日期列 '{date_col_name}' 已設為索引。")
                        _cell_notes.append(f"文件 {file_source_name}: 成功檢測到表頭行 {header_row}, 日期列 '{date_col_name}' 設為索引。")
                        break
                except Exception as peek_err:
                    parse_error_detail += f"嘗試 header={h} 失敗: {peek_err}; "; excel_content.seek(0); continue

            if data_positions_long is None:
                warn_msg = f"文件 {file_source_name}: 無法自動檢測有效的表頭行或日期/數值列。跳過此文件。詳情: {parse_error_detail}"
                _cell_warnings.append(warn_msg); print(f"\n      - 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (解析失敗)"); logger.warning(warn_msg); continue

            # --- 5.2.3. 清理長格式數據 ---
            print("      - 正在清理長格式數據...", end="")
            logger.debug(f"文件 {file_source_name}: 開始清理長格式數據...")

            # 檢查和清理索引
            if not isinstance(data_positions_long.index, pd.DatetimeIndex):
                 try:
                     original_index_name = data_positions_long.index.name
                     original_index_values = data_positions_long.index
                     data_positions_long.index = pd.to_datetime(original_index_values, errors='coerce')
                     data_positions_long.index.name = original_index_name
                 except Exception as date_parse_err:
                     warn_msg = f"文件 {file_source_name}: 無法將索引轉換為日期。跳過。錯誤: {date_parse_err}"
                     _cell_warnings.append(warn_msg); print(f" 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (日期解析失敗)"); logger.error(warn_msg); continue

            initial_rows_before_nat_drop = len(data_positions_long)
            data_positions_long = data_positions_long[pd.notna(data_positions_long.index)]
            nat_dropped_count = initial_rows_before_nat_drop - len(data_positions_long)
            if nat_dropped_count > 0: logger.debug(f"文件 {file_source_name}: 移除了 {nat_dropped_count} 行無效日期 (NaT in index)。")

            if data_positions_long.empty:
                warn_msg = f"文件 {file_source_name}: 移除無效日期後無數據。跳過。"; _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); failed_files.append(f"{file_source_name} (日期清理後無數據)"); logger.warning(warn_msg); continue

            data_positions_long.index = data_positions_long.index.normalize()

            actual_ts_col = None; actual_val_col = None
            cols_lower_full = [str(c).lower().strip() for c in data_positions_long.columns]
            for ts_name in ['time series', 'series id', 'series name']:
                if ts_name in cols_lower_full: actual_ts_col = data_positions_long.columns[cols_lower_full.index(ts_name)]; break
            for val_name in ['value (millions)', 'value', 'amount']:
                if val_name in cols_lower_full: actual_val_col = data_positions_long.columns[cols_lower_full.index(val_name)]; break

            if not actual_ts_col or not actual_val_col:
                warn_msg = f"文件 {file_source_name}: 清理後缺少 '{actual_ts_col or 'Time Series'}' 或 '{actual_val_col or 'Value'}' 欄位。跳過。"
                _cell_warnings.append(warn_msg); print(f" 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (欄位缺失)"); logger.error(warn_msg); continue

            data_positions_long[actual_val_col] = pd.to_numeric(data_positions_long[actual_val_col], errors='coerce')
            initial_rows = len(data_positions_long)
            data_positions_long.dropna(subset=[actual_val_col, actual_ts_col], inplace=True)
            rows_dropped = initial_rows - len(data_positions_long)
            print(f" 完成 (移除 {rows_dropped} 行無效 Value/TS 數據)。")
            logger.debug(f"文件 {file_source_name}: 清理完成，移除了 {rows_dropped} 行無效 Value/TS 數據。")

            if data_positions_long.empty:
                warn_msg = f"文件 {file_source_name}: 清理 Value/TS 後無有效數據。跳過。"; _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); failed_files.append(f"{file_source_name} (無有效 Value/TS 數據)"); logger.warning(warn_msg); continue

            # --- 5.2.4. 轉換為寬格式 ---
            print("      - 正在轉換為寬格式...", end="")
            logger.debug(f"文件 {file_source_name}: 開始轉換為寬格式...")
            try:
                data_positions_long.reset_index(inplace=True)
                date_col_actual = data_positions_long.columns[0]

                data_positions_long = data_positions_long.groupby([date_col_actual, actual_ts_col])[actual_val_col].mean().reset_index()
                data_positions_wide = pd.pivot_table(data_positions_long, index=date_col_actual, columns=actual_ts_col, values=actual_val_col, aggfunc='mean')
                print(f" 成功 ({len(data_positions_wide)} 行 x {len(data_positions_wide.columns)} 欄)。")
                logger.info(f"文件 {file_source_name}: 成功轉換為寬格式 ({data_positions_wide.shape})。")
                _cell_notes.append(f"文件 {file_source_name}: 成功轉換為寬格式。")
            except Exception as e_pivot:
                warn_msg = f"文件 {file_source_name}: 轉換寬格式失敗: {e_pivot}。跳過。"; _cell_warnings.append(warn_msg); print(f" 錯誤：{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (Pivot失敗)"); logger.error(f"文件 {file_source_name} Pivot 失敗: {e_pivot}", exc_info=True); continue

            # --- 5.2.5. 加總持有量 ---
            if not data_positions_wide.empty:
                target_cols = []; source_type = "未知"; url_lower = url.lower()
                if 'sbn' in url_lower: source_type = "SBN"; target_cols = [c for c in data_positions_wide.columns if isinstance(c, str) and c.startswith('PDPOSGSC-')]
                elif 'sbp2013' in url_lower: source_type = "SBP2013"; target_cols = sbp2013_cols
                elif 'sbp2001' in url_lower: source_type = "SBP2001"; target_cols = sbp2001_cols
                else:
                    warn_msg = f"文件 {file_source_name}: 無法從 URL 識別 SBN/SBP 類型。嘗試通用規則。"
                    _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); logger.warning(warn_msg)
                    target_cols = [c for c in data_positions_wide.columns if isinstance(c, str) and (c.startswith('PDPOSGSC-') or c.startswith('PDPUSGCS'))]
                    source_type = "未知 (嘗試通用規則)"

                if not target_cols:
                     warn_msg = f"文件 {file_source_name}: 未找到用於加總的目標欄位規則 ({source_type})。跳過加總。"
                     _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); failed_files.append(f"{file_source_name} (無加總規則)"); logger.warning(warn_msg); continue

                cols_to_sum_actual = [c for c in target_cols if c in data_positions_wide.columns]
                if not cols_to_sum_actual:
                     warn_msg = f"文件 {file_source_name}: 在 DataFrame 中未找到任何預期的目標欄位 ({source_type})。跳過加總。預期: {target_cols}"
                     _cell_warnings.append(warn_msg); print(f"      - 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (無目標欄位)"); logger.error(warn_msg); continue
                if len(cols_to_sum_actual) < len(target_cols):
                     missing_cols = set(target_cols) - set(cols_to_sum_actual)
                     warn_msg = f"文件 {file_source_name}: 部分目標欄位未找到: {missing_cols}。將僅加總存在的欄位。"
                     _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); logger.warning(warn_msg)

                print(f"      - 正在加總 {len(cols_to_sum_actual)} 個欄位 ({source_type}, 單位: 百萬美元)...", end="")
                logger.debug(f"文件 {file_source_name}: 準備加總欄位: {cols_to_sum_actual}")
                try:
                    for col in cols_to_sum_actual: data_positions_wide[col] = pd.to_numeric(data_positions_wide[col], errors='coerce')
                    daily_total_millions = data_positions_wide[cols_to_sum_actual].sum(axis=1, skipna=True)
                    original_count_before_drop = len(daily_total_millions)
                    daily_total_millions = daily_total_millions.dropna(); daily_total_millions = daily_total_millions[daily_total_millions != 0]
                    dropped_count = original_count_before_drop - len(daily_total_millions)

                    if not daily_total_millions.empty:
                         all_positions_data.append(daily_total_millions); positions_fetch_success = True; file_processed_successfully = True; processed_files_count += 1
                         print(f" 完成 ({len(daily_total_millions)} 筆有效數據, 移除 {dropped_count} 筆 NaN/零值).")
                         logger.info(f"文件 {file_source_name}: 成功加總，獲得 {len(daily_total_millions)} 筆有效數據。")
                         _cell_notes.append(f"文件 {file_source_name}: 成功加總並清理，獲得 {len(daily_total_millions)} 筆數據。")
                    else:
                        warn_msg = f"文件 {file_source_name}: 加總後未能計算出有效的非零數據。跳過。"
                        _cell_warnings.append(warn_msg); print(f" 警告：{warn_msg}"); failed_files.append(f"{file_source_name} (加總後無數據)"); logger.warning(warn_msg); continue
                except Exception as e_sum:
                    warn_msg = f"文件 {file_source_name}: 加總欄位時出錯: {e_sum}。跳過。"
                    _cell_warnings.append(warn_msg); print(f" 錯誤：{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (加總失敗)"); logger.error(f"文件 {file_source_name} 加總失敗: {e_sum}", exc_info=True); continue
            else:
                warn_msg = f"文件 {file_source_name}: 寬格式數據為空，無法進行加總。跳過。"
                _cell_warnings.append(warn_msg); print(f"      - 警告：{warn_msg}"); failed_files.append(f"{file_source_name} (寬表為空)"); logger.warning(warn_msg); continue

        except requests.exceptions.RequestException as e_req:
            warn_msg = f"文件 {file_source_name}: 下載失敗: {e_req.__class__.__name__}: {e_req}。跳過。"
            _cell_warnings.append(warn_msg); print(f"\n      - 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (下載失敗)"); logger.error(f"文件 {file_source_name} 下載失敗: {e_req}", exc_info=False)
        except (pd.errors.ParserError, ValueError, KeyError, AttributeError, TypeError, IndexError, openpyxl.utils.exceptions.InvalidFileException) as e_parse:
            warn_msg = f"文件 {file_source_name}: 解析或處理數據時出錯: {e_parse.__class__.__name__}: {e_parse}。跳過。"
            _cell_warnings.append(warn_msg); print(f"\n      - 錯誤：{warn_msg}"); failed_files.append(f"{file_source_name} (處理失敗)"); logger.error(f"文件 {file_source_name} 處理失敗: {e_parse}", exc_info=True); _cell_traceback = _cell_traceback or traceback.format_exc()
        except Exception as e_file:
            warn_msg = f"文件 {file_source_name}: 處理時發生未預期錯誤: {e_file.__class__.__name__}: {e_file}。跳過。"
            _cell_warnings.append(warn_msg); print(f"\n      - 錯誤：{warn_msg}"); _cell_traceback = _cell_traceback or traceback.format_exc(); failed_files.append(f"{file_source_name} (未知錯誤)"); logger.error(f"文件 {file_source_name} 未知錯誤: {e_file}", exc_info=True)

        if not file_processed_successfully and f"{file_source_name}" not in " ".join(failed_files):
             failed_files.append(f"{file_source_name} (處理未完成)")


    print("\n  - 步驟 1: 文件處理循環結束。")
    logger.info(f"文件處理循環結束。成功處理 {processed_files_count}/{len(ny_fed_urls)} 個文件。失敗文件列表: {failed_files}")

    # --- 5.3. 合併所有文件的持有量數據 ---
    print("  - 步驟 2: 合併所有成功處理的文件數據...")
    logger.info("步驟 2: 開始合併所有成功的 Series...")
    if all_positions_data:
        try:
            combined_positions = pd.concat(all_positions_data); combined_positions = combined_positions.sort_index()
            final_series = combined_positions.groupby(level=0).last(); final_series.name = 'Total_Gross_Positions_Millions'
            final_series = final_series.dropna(); final_series = final_series[final_series != 0]

            if not final_series.empty:
                nyfed_positions_series = final_series
                _cell_outputs['output_series_shape'] = nyfed_positions_series.shape
                _cell_outputs['output_series_start'] = nyfed_positions_series.index.min().strftime('%Y-%m-%d')
                _cell_outputs['output_series_end'] = nyfed_positions_series.index.max().strftime('%Y-%m-%d')
                _cell_outputs['output_series_valid_points'] = int(nyfed_positions_series.count())
                _cell_outputs['output_series_mean_value'] = round(nyfed_positions_series.mean(), 2)
                _cell_notes.append(f"成功合併 {processed_files_count} 個文件的持有量數據，最終得到 {len(nyfed_positions_series)} 筆有效數據。")
                print(f"    > 合併完成，最終序列包含 {len(nyfed_positions_series)} 筆數據 (從 {nyfed_positions_series.index.min().date()} 到 {nyfed_positions_series.index.max().date()})。")
                logger.info(f"數據合併完成，最終序列長度: {len(nyfed_positions_series)}")
                positions_fetch_success = True
            else:
                warn_msg = "警告：合併所有文件數據後，最終序列為空或全為零值。"
                _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.warning(warn_msg)
                nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
                _cell_outputs['output_series_valid_points'] = 0
        except Exception as e_concat:
            _cell_status = "失敗"; _cell_error = f"合併持有量數據時出錯: {e_concat.__class__.__name__}: {e_concat}"; _cell_traceback = _cell_traceback or traceback.format_exc(); logger.error(_cell_error, exc_info=True)
            print(f"    > \u274C 合併數據時出錯: {_cell_error}")
            nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
            _cell_outputs['output_series_valid_points'] = 0
    else:
        warn_msg = "錯誤：未能成功處理任何 NY Fed 持有量數據文件。最終序列為空。"
        _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.error(warn_msg)
        nyfed_positions_series = pd.Series(dtype='float64'); positions_fetch_success = False
        _cell_outputs['output_series_valid_points'] = 0

    _cell_outputs['processed_files_count'] = processed_files_count
    _cell_outputs['failed_files_count'] = len(failed_files)
    _cell_outputs['failed_files_list'] = failed_files
    _cell_outputs['final_series_is_valid'] = positions_fetch_success and nyfed_positions_series is not None and not nyfed_positions_series.empty

    # --- 標記 Cell 6 執行狀態 ---
    if _cell_status == "處理中":
        if not positions_fetch_success or nyfed_positions_series is None or nyfed_positions_series.empty:
             _cell_status = "成功 (有警告)"; _cell_notes.append("最終狀態警告：未能獲取有效的 NY Fed 數據。")
             if "最終未能獲取有效的 NY Fed 持有量數據。" not in _cell_warnings: _cell_warnings.append("最終未能獲取有效的 NY Fed 持有量數據。")
             logger.warning("最終未能獲取有效的 NY Fed 持有量數據。")
        elif _cell_warnings: _cell_status = "成功 (有警告)"
        else: _cell_status = "成功"

    logger.info(f"{_cell_identifier} - NY Fed 數據處理完成，最終狀態: {_cell_status}")
    print(f"--- {_cell_identifier} 執行結束，狀態: {_cell_status} ---")


# --- 6. 整個儲存格的異常處理 ---
# (異常處理邏輯不變)
except (NameError, ValueError, ImportError, RuntimeError) as prereq_err:
    _cell_status = "失敗"
    if not _cell_error: _cell_error = f"配置、環境或先決條件錯誤：{prereq_err.__class__.__name__}：{prereq_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=False)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\n\u274C {_cell_identifier} 執行失敗：{_cell_error}")
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')

except requests.exceptions.RequestException as req_fatal_err:
    _cell_status = "失敗"
    if not _cell_error: _cell_error = f"網絡請求錯誤：{req_fatal_err.__class__.__name__}：{req_fatal_err}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    try: logger.critical(f"{_cell_identifier} 失敗：{_cell_error}", exc_info=True)
    except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
    print(f"\n\u274C {_cell_identifier} 執行失敗：{_cell_error}")
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')

except Exception as e:
    if _cell_status == "處理中":
        _cell_status = "失敗"; _cell_error = f"意外錯誤：{e.__class__.__name__}：{e}"
        if not _cell_traceback: _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} 因意外錯誤而失敗：{_cell_error}", exc_info=True)
        except: print(f"記錄錯誤時也發生錯誤: {_cell_error}")
        print(f"\n\u274C {_cell_identifier} 執行失敗：{_cell_error}")
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    if 'nyfed_positions_series' not in globals() or nyfed_positions_series is None: nyfed_positions_series = pd.Series(dtype='float64')


# --- 7. finally 區塊：執行總結報告 (已修正時區讀取) ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time

    _final_status_text = _cell_status
    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "已跳過": _final_status_icon = "🚫"
    elif _cell_status == "處理中": _final_status_icon = "⏳"; _final_status_text = "未完成"; _cell_notes.append("警告：儲存格以 '處理中' 狀態結束。")
    elif _cell_warnings: _final_status_icon = "⚠️"; _final_status_text = "成功（有警告）" if _cell_status == "成功" else _cell_status
    elif _cell_status == "成功": _final_status_icon = "✅"
    else: _final_status_icon = "❓"; _cell_notes.append(f"警告：儲存格以無法識別的狀態 '{_cell_status}' 結束。")

    _current_time_str = "無法獲取"
    try:
        _report_tz_info = timezone(timedelta(hours=8)) # 預設回退
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             # **修正:** 使用正確的鍵名 '_tz_info_obj'
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'):
                 _report_tz_info = tz_obj
             else:
                 # 只有在確實找不到有效的配置時才記錄警告
                 if PROJECT_CONFIG.get('_tz_source') != '錯誤時回退' and PROJECT_CONFIG.get('_tz_source') != '固定偏移':
                      logger.warning("PROJECT_CONFIG 中的 _tz_info_obj 無效或未找到，報告時間戳將回退到 UTC+8。")
                      if "時區配置無效，報告時間可能不準確。" not in _cell_warnings:
                         _cell_warnings.append("時區配置無效，報告時間可能不準確。")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗":
             time_warn_msg = f"報告時間獲取錯誤: {time_err}"
             if time_warn_msg not in _cell_warnings: _cell_warnings.append(time_warn_msg)
             logger.warning(time_warn_msg)

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "警告：EXECUTION_TRACKER 未正確初始化。已創建回退追蹤器。";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    _processed_count = locals().get('processed_files_count', 0)
    _failed_list = locals().get('failed_files', [])
    _failed_count = len(_failed_list) if isinstance(_failed_list, list) else 0
    _final_series_valid = False
    if 'nyfed_positions_series' in globals() and isinstance(nyfed_positions_series, pd.Series) and not nyfed_positions_series.empty:
        _final_series_valid = True; _cell_outputs['output_series_shape'] = nyfed_positions_series.shape
        _cell_outputs['output_series_start'] = nyfed_positions_series.index.min().strftime('%Y-%m-%d')
        _cell_outputs['output_series_end'] = nyfed_positions_series.index.max().strftime('%Y-%m-%d')
        _cell_outputs['output_series_valid_points'] = int(nyfed_positions_series.count())
    else: _cell_outputs['output_series_valid_points'] = 0

    _cell_outputs['processed_files_count'] = _processed_count
    _cell_outputs['failed_files_count'] = _failed_count
    _cell_outputs['failed_files_list'] = _failed_list
    _cell_outputs['final_series_is_valid'] = _final_series_valid

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _final_status_text,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"更新 EXECUTION_TRACKER 時失敗: {tracker_update_err}", exc_info=True); print(f"錯誤: 更新 EXECUTION_TRACKER 時發生異常: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格：{_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態：** {_final_status_icon} {_final_status_text}")
    print(f"** 執行時間：** {_cell_duration:.2f} 秒")
    print(f"** 完成時間：** {_current_time_str}") # 現在應顯示正確時區
    if _cell_inputs: print("\n** \U0001F527 輸入參數：**"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記：**"); max_notes_to_show = 15; notes_to_show = _cell_notes[-max_notes_to_show:]; [print(f"- {note}") for note in notes_to_show];
    if len(_cell_notes) > max_notes_to_show: print(f"- ... (還有 {len(_cell_notes) - max_notes_to_show} 條註記未顯示)")
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息：**"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息：**\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback 過長，已截斷)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))

    print("\n** \U0001F4CA 輸出 / 檢查結果摘要：**")
    tracked_outputs = _tracking_record.get('outputs');
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else:
        summary_output = {'processed_files_count': tracked_outputs.get('processed_files_count'),'failed_files_count': tracked_outputs.get('failed_files_count'),'final_series_is_valid': tracked_outputs.get('final_series_is_valid'),'output_series_valid_points': tracked_outputs.get('output_series_valid_points'),'output_series_start': tracked_outputs.get('output_series_start'),'output_series_end': tracked_outputs.get('output_series_end'),}
        summary_output_filtered = {k: v for k, v in summary_output.items() if v is not None}; pprint.pprint(summary_output_filtered, indent=2, width=70, sort_dicts=False);
        failed_list = tracked_outputs.get('failed_files_list', [])
        if failed_list:
            print("\n  失敗的文件列表:")
            max_failed_to_show = 10
            for idx, failed_item in enumerate(failed_list):
                if idx < max_failed_to_show: print(f"  - {failed_item}")
                elif idx == max_failed_to_show: print(f"  - ... (還有 {len(failed_list) - max_failed_to_show} 個失敗文件未顯示)"); break
    print("="*80 + "\n")

    # --- 8. 清理局部變數 ---
    # (清理列表保持不變)
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'ny_fed_urls', 'sbp2013_cols', 'sbp2001_cols', 'all_positions_data',
        'positions_fetch_success', 'processed_files_count', 'failed_files', 'session',
        'i', 'url', 'file_source_name', 'file_processed_successfully', 'response_excel', 'excel_content',
        'header_row', 'date_col_name', 'data_positions_long', 'possible_headers', 'h', 'df_peek',
        'cols_lower', 'time_series_col', 'value_col', 'date_col_candidate', 'parse_error_detail',
        'actual_ts_col', 'actual_val_col', 'initial_rows_before_nat_drop', 'nat_dropped_count',
        'initial_rows', 'rows_dropped', 'data_positions_wide', 'date_col_actual', 'e_pivot',
        'target_cols', 'source_type', 'url_lower', 'cols_to_sum_actual', 'missing_cols', 'col',
        'daily_total_millions', 'original_count_before_drop', 'dropped_count', 'e_sum',
        'combined_positions', 'final_series', 'e_concat', 'e_req', 'e_parse', 'e_file',
        'prereq_err', 'req_fatal_err', 'e', 'import_err', 'peek_err', 'date_parse_err',
        'tracker_update_err', 'time_err', 'time_err_local', 'tz_obj', 'tracker_warn_msg',
        'time_warn_msg', 'warn_msg', 'err_msg', 'info_text', '_processed_count', '_failed_list',
        '_failed_count', '_final_series_valid', 'summary_output', 'summary_output_filtered',
        'failed_list', 'idx', 'failed_item', 'max_notes_to_show', 'notes_to_show',
        'max_traceback_lines', 'traceback_lines', 'traceback_to_display', 'max_failed_to_show',
        'original_index_name', 'original_index_values', 'initial_valid_dates', 'final_valid_dates', 'traceback_content'
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4.4-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 6: NY Fed 一級交易商數據獲取與處理 (已修正 KeyError & NameError & TZ)
# 功能: 從 NY Fed 網站下載多個 Excel 文件，解析一級交易商公債持有量數據，
#       根據 SBN/SBP 規則加總，並合併成單一時間序列。
# 版本: 3.4.4-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# 輸入: ['global:PROJECT_CONFIG']
# 輸出: ['global:nyfed_positions_series', 'global:EXECUTION_TRACKER (updated)']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 7: 數據合併與初步清洗 (已修正合併邏輯 + 新增序列)
# --------------------------------------------------
# 功能: 將來自 Cell 3, 4, 5, 6 的所有數據源 (DataFrame/Series) 合併到一個
#       主 DataFrame 中。基於共同的日期索引進行對齊，明確處理欄位命名衝突，
#       並對低頻數據進行向前填充 (ffill)。
# 版本: 3.4.4-zh-fc (對應準則 v3.4，修正合併邏輯，加入新 FRED 序列)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 3', 'Cell 4', 'Cell 5', 'Cell 6']
# 輸入: ['global:df_twdusd', 'global:df_vix', 'global:df_spy', 'global:df_hyg',
#        'global:df_lqd', 'global:df_fedfunds', 'global:df_indpro',
#        'global:df_sofr', 'global:df_dgs10', 'global:df_dgs2', # 新增
#        'global:df_wresbal', 'global:df_rrpontsyd',           # 新增
#        'global:nyfed_positions_series', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# 輸出: ['global:merged_data_df'] (包含所有合併和初步清洗後數據的 DataFrame)
#       (更新 EXECUTION_TRACKER)
# --------------------------------------------------
# ==================================================
"""
合併來自所有先前數據獲取儲存格的數據，並進行初步清洗。

此儲存格執行以下步驟：
1.  執行必要全局變數和數據變數的先決條件檢查。
2.  選擇 `df_spy` 作為合併的基礎 DataFrame，並準備其索引。
3.  **準備待合併數據列表**:
    a. 創建一個空列表 `dfs_to_join`。
    b. 逐一處理其他數據源 (`df_twdusd`, `df_vix`, `df_hyg`, `df_lqd`, `df_fedfunds`, `df_indpro`, `df_sofr`, `df_dgs10`, `df_dgs2`, `df_wresbal`, `df_rrpontsyd`, `nyfed_positions_series`)。
    c. 對每個數據源:
        i.  檢查是否存在且非空。
        ii. 確保索引為 DatetimeIndex 且無時區。
        iii.**明確重命名衝突欄位**: 對於 `df_twdusd`, `df_vix`, `df_hyg`, `df_lqd`，將 'Open', 'High', 'Low', 'Close', 'Volume' 等欄位重命名 (例如，添加 'TWDUSD_', 'VIX_' 前綴)。只保留需要的欄位 (例如，'Close' 和 'Volume')。
        iv. 將處理後的 DataFrame (或轉換後的 Series) 添加到 `dfs_to_join` 列表。
4.  **執行合併**: 使用 `base_df.join(dfs_to_join, how='left')` 將列表中的所有 DataFrame 合併到基礎 DataFrame。
5.  **初步清洗與填充**:
    a. 對於來自 FRED 的月/週/日頻數據 (`FEDFUNDS`, `INDPRO`, `SOFR`, `DGS10`, `DGS2`, `WRESBAL`, `RRPONTSYD`) 和 NY Fed 的週頻數據 (`Total_Gross_Positions_Millions`)，使用帶 `limit` 的向前填充 (`ffill`)。 **(已更新 ffill_config)**
6.  **最終 DataFrame**: 將合併並初步清洗後的 DataFrame 賦值給全局變數 `merged_data_df`。
7.  包含一個強制性的 `finally` 區塊，用於報告執行狀態、摘要並更新 `EXECUTION_TRACKER`。

設計說明：
* **修正:** 放棄了依賴 `suffixes` 和後續刪除 `_dup` 列的策略，改為在合併前對已知衝突的數據源進行明確的欄位重命名，並使用 `.join()` 進行合併，更為穩健可靠。
* **新增:** 將 Cell 5 新獲取的 FRED 序列加入合併流程。
* **更新:** 擴展了 `ffill_config` 以包含新的 FRED 序列，並根據其頻率設定了填充限制。
* 保留了對低頻數據使用帶 `limit` 的 `ffill`。
* 確保輸出 DataFrame 結構完整。

參數：
    無 (依賴來自先前儲存格的全局變數)。

返回：
    無 (創建或更新全局 DataFrame 變數 `merged_data_df`，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數或數據變數未定義。
    ValueError/TypeError: 如果輸入數據格式不符。
    KeyError: 如果 PROJECT_CONFIG 缺少必要的鍵。
    Exception: 捕獲其他未預期的合併或清洗錯誤。

假設：
* Cell 1, 3, 4, 5 (已修正), 6 已成功執行。
* `pandas` 和 `numpy` 函式庫已成功載入。
* 所有輸入的 DataFrame/Series 均存在且包含數據（或已被正確處理為 None）。

潛在問題 / 考量：
    * `ffill` 的合理性與 `limit` 設置仍需根據數據特性仔細考慮。
    * 需要明確決定從 TWD/USD, VIX, HYG, LQD 中保留哪些欄位。目前保留重命名後的 'Close' 和 'Volume'。

下一步：
* 執行 Cell 8 (計算衍生指標與壓力指數)。
* 執行 Cell Z 查看整體執行狀態，確認 `merged_data_df` 的內容。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    print("數據合併所需函式庫 (pandas, numpy) 看似可用。")
    _libs_ok = True
except ImportError as import_err:
    print(f"警告：導入數據合併所需函式庫失敗({import_err})。")
    pd = None; np = None
    _libs_ok = False

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 7: 數據合併與初步清洗 (已修正合併邏輯 + 新增序列)" # 更新標識符

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. 全局變數定義 (此 Cell 的主要輸出) ---
global merged_data_df
merged_data_df = None

# --- 5. 主要腳本主體 ---
try:
    # --- 5.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4.4-zh-fc) 開始執行 ---") # 更新版本號
    print(f"\n--- {_cell_identifier} (v3.4.4-zh-fc) 開始執行 ---")

    if not _libs_ok:
        _cell_status = "失敗"; _cell_error = "依賴錯誤: 缺少必要函式庫 (pandas, numpy)。"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "失敗"; _cell_error = "依賴錯誤: Cell 1 的 libs_loaded 變數未找到。"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('numpy'):
         _cell_status = "失敗"; _cell_error = f"依賴錯誤: Cell 1 未能成功載入 pandas 或 numpy。"; raise ImportError(_cell_error)

    # 擴展檢查列表以包含新的 FRED 序列
    required_data_vars = [
        'df_twdusd', 'df_vix', 'df_spy', 'df_hyg', 'df_lqd',
        'df_fedfunds', 'df_indpro',
        'df_sofr', 'df_dgs10', 'df_dgs2', 'df_wresbal', 'df_rrpontsyd', # 新增
        'nyfed_positions_series'
    ]
    missing_vars = [var for var in required_data_vars if var not in globals() or globals()[var] is None]
    if missing_vars:
        # 如果有缺失變數，記錄警告而不是直接失敗，因為部分缺失可能仍可合併
        warn_msg = f"警告: 缺少來自先前儲存格的部分數據變數: {', '.join(missing_vars)}。合併結果可能不完整。"
        _cell_warnings.append(warn_msg)
        logger.warning(warn_msg)
        print(f"*** {warn_msg} ***")
        # 移除缺失變數，繼續處理存在的變數
        required_data_vars = [var for var in required_data_vars if var not in missing_vars]


    # 基礎 DataFrame 檢查
    if 'df_spy' not in globals() or not isinstance(df_spy, pd.DataFrame) or df_spy.empty:
         _cell_status = "失敗"; _cell_error = "輸入錯誤: 基礎 DataFrame (df_spy) 無效或為空。"; raise ValueError(_cell_error)
    if not isinstance(df_spy.index, pd.DatetimeIndex):
        try:
            df_spy.index = pd.to_datetime(df_spy.index); _cell_notes.append("已將 df_spy 的索引轉換為 DatetimeIndex。")
            if not isinstance(df_spy.index, pd.DatetimeIndex): raise TypeError("轉換後仍非 DatetimeIndex")
        except Exception as e_spy_index:
             _cell_status = "失敗"; _cell_error = f"輸入錯誤: 無法將 df_spy 的索引轉換為 DatetimeIndex: {e_spy_index}"; raise TypeError(_cell_error) from e_spy_index

    # 記錄所有嘗試處理的數據源的形狀
    for var_name in required_data_vars:
        if var_name in globals(): # 再次檢查，因為可能已被移除
            data_obj = globals()[var_name];
            if isinstance(data_obj, (pd.DataFrame, pd.Series)): _cell_inputs[f'{var_name}_shape'] = data_obj.shape
            else: _cell_inputs[f'{var_name}_type'] = str(type(data_obj))

    logger.info("先決條件檢查通過。所有必需的輸入數據變數存在（或已記錄警告）。")
    print(f"  - 步驟 0: 依賴檢查通過。")

    # --- 5.2. 準備基礎 DataFrame 和待合併數據列表 ---
    print("  - 步驟 1: 準備合併基礎和數據列表...")
    logger.info("步驟 1: 準備合併基礎和數據列表...")
    base_df = df_spy.copy()
    if base_df.index.tz is not None:
        base_df.index = base_df.index.tz_localize(None)
        _cell_notes.append("已移除基礎 DataFrame (df_spy) 索引的時區信息。")
    # 僅保留 SPY 的基礎價格和成交量
    base_df = base_df[['Open', 'High', 'Low', 'Close', 'Volume']]
    _cell_notes.append("基礎 DataFrame (df_spy) 已準備就緒 (保留 OHLCV)。")


    dfs_to_join = [] # 儲存準備好合併的 DataFrame
    # 更新字典以包含新的 FRED 序列
    data_sources_to_process = {
        'twdusd': df_twdusd if 'df_twdusd' in globals() else None,
        'vix': df_vix if 'df_vix' in globals() else None,
        'hyg': df_hyg if 'df_hyg' in globals() else None,
        'lqd': df_lqd if 'df_lqd' in globals() else None,
        'fedfunds': df_fedfunds if 'df_fedfunds' in globals() else None,
        'indpro': df_indpro if 'df_indpro' in globals() else None,
        'sofr': df_sofr if 'df_sofr' in globals() else None,           # 新增
        'dgs10': df_dgs10 if 'df_dgs10' in globals() else None,         # 新增
        'dgs2': df_dgs2 if 'df_dgs2' in globals() else None,           # 新增
        'wresbal': df_wresbal if 'df_wresbal' in globals() else None,     # 新增
        'rrpontsyd': df_rrpontsyd if 'df_rrpontsyd' in globals() else None, # 新增
        'nyfed_pos': nyfed_positions_series if 'nyfed_positions_series' in globals() else None
    }
    # 保留需要的欄位及其新名稱
    rename_mapping = {
        # 'Open': 'Open', # 決定是否保留 Open 等
        # 'High': 'High',
        # 'Low': 'Low',
        'Close': 'Close',
        'Volume': 'Volume'
    }

    print("  - 步驟 2: 處理並準備各數據源...")
    logger.info("步驟 2: 處理並準備各數據源...")
    for name, data_obj in data_sources_to_process.items():
        print(f"    - 正在處理: {name}...", end="")
        if data_obj is None or data_obj.empty:
            print(" 跳過 (數據為空或缺失)")
            # 不需要記錄警告，因為已在步驟 5.1 記錄
            # _cell_warnings.append(f"數據源 '{name}' 為空或 None，跳過處理。");
            logger.info(f"數據源 '{name}' 為空或缺失，跳過處理。"); continue

        try:
            # 複製以避免修改原始數據
            current_data = data_obj.copy()

            # 確保索引是 DatetimeIndex 且無時區
            if not isinstance(current_data.index, pd.DatetimeIndex):
                current_data.index = pd.to_datetime(current_data.index, errors='coerce')
            if current_data.index.tz is not None:
                 current_data.index = current_data.index.tz_localize(None)
            # 移除無效索引
            current_data = current_data[pd.notna(current_data.index)]
            if current_data.empty:
                 print(" 跳過 (索引處理後為空)")
                 _cell_warnings.append(f"數據源 '{name}' 索引處理後為空，跳過。"); continue

            # 如果是 Series，轉換為 DataFrame 並命名
            if isinstance(current_data, pd.Series):
                # 為 Series 確定列名
                series_col_name = name.upper() # 默認使用大寫名稱
                if name == 'nyfed_pos':
                    series_col_name = 'Total_Gross_Positions_Millions'
                elif name == 'fedfunds':
                    series_col_name = 'FEDFUNDS'
                elif name == 'indpro':
                    series_col_name = 'INDPRO'
                elif name == 'sofr':
                    series_col_name = 'SOFR'
                elif name == 'dgs10':
                    series_col_name = 'DGS10'
                elif name == 'dgs2':
                    series_col_name = 'DGS2'
                elif name == 'wresbal':
                    series_col_name = 'WRESBAL' # 使用 WRESBAL 作為列名
                elif name == 'rrpontsyd':
                    series_col_name = 'RRPONTSYD' # 使用 RRPONTSYD 作為列名

                current_data = current_data.to_frame(name=series_col_name)
                _cell_notes.append(f"已將 Series '{name}' 轉換為 DataFrame，列名為 '{series_col_name}'。")


            # 對需要重命名的數據源進行處理 (TWDUSD, VIX, HYG, LQD)
            if name in ['twdusd', 'vix', 'hyg', 'lqd']:
                prefix = name.upper() + '_' # 例如 TWDUSD_, VIX_
                # 根據 rename_mapping 選擇並重命名列
                cols_to_select = [col for col in rename_mapping.keys() if col in current_data.columns]
                if cols_to_select:
                    current_data = current_data[cols_to_select] # 先選擇需要的列
                    cols_rename_dict = {col: prefix + rename_mapping[col] for col in cols_to_select}
                    current_data = current_data.rename(columns=cols_rename_dict)
                    _cell_notes.append(f"已選擇並重命名 '{name}' 的欄位 (前綴: {prefix})。保留: {current_data.columns.tolist()}")
                else:
                    print(f" 跳過重命名 (未找到 '{name}' 中的目標欄位: {list(rename_mapping.keys())})")
                    _cell_warnings.append(f"數據源 '{name}' 未找到預期的欄位進行重命名。")
                    continue # 如果連需要的列都沒有，跳過

            # 對於 FRED 數據和 NY Fed 數據，它們的列名應該已經是唯一的了
            # 無需額外處理列選擇或重命名，因為上一步已將 Series 轉換為單列 DataFrame

            # 將處理好的 DataFrame 添加到列表中
            if not current_data.empty:
                # 檢查是否存在重複的列名（不應發生，但作為安全檢查）
                if any(col in base_df.columns for col in current_data.columns):
                     warn_msg = f"數據源 '{name}' 處理後仍與基礎 DataFrame 存在列名衝突: {current_data.columns.tolist()}。跳過此數據源。"
                     _cell_warnings.append(warn_msg); print(f" 錯誤: {warn_msg}"); continue
                if any(existing_df.columns.isin(current_data.columns).any() for existing_df in dfs_to_join):
                     conflicting_cols = [col for col in current_data.columns if any(col in existing_df.columns for existing_df in dfs_to_join)]
                     warn_msg = f"數據源 '{name}' 處理後與已準備好的其他數據源存在列名衝突: {conflicting_cols}。跳過此數據源。"
                     _cell_warnings.append(warn_msg); print(f" 錯誤: {warn_msg}"); continue

                dfs_to_join.append(current_data)
                print(" 完成準備.")
                _cell_notes.append(f"已準備好合併數據源: {name} (欄位: {current_data.columns.tolist()})")
            else:
                 print(" 跳過 (處理後數據為空)")
                 _cell_warnings.append(f"數據源 '{name}' 處理後為空，跳過。")


        except Exception as e_prepare:
            warn_msg = f"處理數據源 '{name}' 時出錯: {e_prepare}。已跳過此數據源。"
            _cell_warnings.append(warn_msg); print(f" 錯誤: {warn_msg}")
            logger.warning(f"處理數據源 '{name}' 失敗", exc_info=True); _cell_traceback = _cell_traceback or traceback.format_exc()

    # --- 5.3. 執行合併 ---
    print(f"  - 步驟 3: 執行合併 (將 {len(dfs_to_join)} 個數據源合併到基礎)...")
    logger.info(f"步驟 3: 執行合併...")
    try:
        if dfs_to_join: # 只有當有數據需要合併時才執行 join
            # 使用 left join，以 base_df (來自 SPY) 的索引為主
            merged_df_temp = base_df.join(dfs_to_join, how='left')
            join_note = f"已成功將 {len(dfs_to_join)} 個數據源合併到基礎 DataFrame。"
            _cell_notes.append(join_note); print(f"    > {join_note}")
            logger.info(join_note)
        else:
            merged_df_temp = base_df # 如果沒有其他數據源，結果就是基礎 DataFrame
            _cell_notes.append("沒有額外的數據源成功準備好進行合併。")
            print("    > 沒有額外的數據源成功準備好進行合併。")
            _cell_warnings.append("警告：沒有額外的數據源被合併。")

    except Exception as e_join:
         _cell_status = "失敗"; _cell_error = f"執行 DataFrame join 操作時出錯: {e_join}"; _cell_traceback = _cell_traceback or traceback.format_exc()
         logger.error(f"DataFrame join 失敗: {e_join}", exc_info=True)
         raise Exception(_cell_error) from e_join # 合併是關鍵步驟，失敗則終止

    # --- 5.4. 初步清洗與填充 (Forward Fill) ---
    print("  - 步驟 4: 對低頻數據執行向前填充 (ffill)...")
    logger.info("步驟 4: 對低頻數據執行向前填充...")

    # 更新 ffill_config 以包含新的 FRED 序列及其頻率對應的限制
    # 假設：FEDFUNDS/INDPRO 月頻，WRESBAL 週頻，其他日頻
    ffill_config = {
        'FEDFUNDS': 35,  # 月頻，填充約一個月多一點
        'INDPRO': 35,    # 月頻
        'SOFR': 3,       # 日頻，填充週末/假日
        'DGS10': 3,      # 日頻
        'DGS2': 3,       # 日頻
        'WRESBAL': 10,   # 週頻，填充約一週多一點
        'RRPONTSYD': 3,  # 日頻
        'Total_Gross_Positions_Millions': 10 # 週頻
    }
    _cell_inputs['ffill_config'] = ffill_config

    for col, limit_days in ffill_config.items():
        if col in merged_df_temp.columns:
            initial_nulls = merged_df_temp[col].isnull().sum()
            if initial_nulls > 0 and initial_nulls < len(merged_df_temp):
                # 確保數據是數值型，否則 ffill 可能行為異常或報錯
                if pd.api.types.is_numeric_dtype(merged_df_temp[col]):
                    merged_df_temp[col] = merged_df_temp[col].ffill(limit=limit_days)
                    filled_count = initial_nulls - merged_df_temp[col].isnull().sum()
                    if filled_count > 0:
                         fill_note = f"已對欄位 '{col}' 向前填充 (最多 {limit_days} 天)，填充了 {filled_count} 個 NaN。"
                         _cell_notes.append(fill_note); print(f"    - {fill_note}"); logger.info(fill_note)
                    else: _cell_notes.append(f"欄位 '{col}' 無需向前填充或填充無效。"); print(f"    - 欄位 '{col}' 無需向前填充或填充無效。")
                else:
                     warn_msg = f"欄位 '{col}' 非數值類型，跳過向前填充。"
                     _cell_warnings.append(warn_msg); print(f"    - 警告: {warn_msg}"); logger.warning(warn_msg)
            elif initial_nulls == len(merged_df_temp): _cell_notes.append(f"欄位 '{col}' 全部為 NaN，跳過填充。"); print(f"    - 欄位 '{col}' 全部為 NaN，跳過填充。")
            else: _cell_notes.append(f"欄位 '{col}' 無缺失值，無需填充。"); print(f"    - 欄位 '{col}' 無缺失值，無需填充。")
        else: _cell_notes.append(f"欄位 '{col}' 不在合併後的 DataFrame 中，跳過填充。"); print(f"    - 欄位 '{col}' 不存在，跳過填充。")

    # --- 5.5. 設定最終輸出 ---
    print("  - 步驟 5: 完成合併與初步清洗...")
    logger.info("步驟 5: 完成合併與初步清洗...")
    if merged_df_temp.empty:
        warn_msg = "警告：最終合併後的 DataFrame 為空！"; _cell_warnings.append(warn_msg); print(f"    > {warn_msg}"); logger.warning(warn_msg)
        merged_data_df = pd.DataFrame()
    else:
        merged_data_df = merged_df_temp
        _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
        _cell_outputs['merged_dataframe_columns'] = merged_data_df.columns.tolist()
        _cell_outputs['merged_dataframe_valid_points'] = int(merged_data_df.count().sum())
        _cell_outputs['merged_start_date'] = merged_data_df.index.min().strftime('%Y-%m-%d')
        _cell_outputs['merged_end_date'] = merged_data_df.index.max().strftime('%Y-%m-%d')
        _cell_outputs['merged_dataframe_nan_counts'] = merged_data_df.isnull().sum().to_dict()
        logger.info(f"數據合併與清洗完成，最終 DataFrame 維度: {merged_data_df.shape}")
        print(f"    > 合併與清洗完成，最終 DataFrame 維度: {merged_data_df.shape}")
        # 打印最終欄位列表以供確認
        print(f"    > 最終欄位列表: {merged_data_df.columns.tolist()}")


    # --- 標記 Cell 7 執行狀態 ---
    if _cell_status == "處理中":
        _cell_status = "成功";
        if _cell_warnings: _cell_status = "成功 (有警告)"
    logger.info(f"{_cell_identifier} - 數據合併完成，狀態: {_cell_status}")

# --- 6. 整個儲存格的異常處理 ---
except (NameError, ValueError, ImportError, TypeError, KeyError) as e:
    if _cell_status != "失敗": _cell_status = "失敗"; _cell_error = f"執行過程中發生錯誤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗。")
except Exception as e:
    if _cell_status != "失敗":
        _cell_status = "失敗"; _cell_error = f"執行時發生未預期錯誤 ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        logger.critical(f"{_cell_identifier} 失敗: {_cell_error}", exc_info=True)
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗 (未預期錯誤)。")

# --- 7. finally 區塊：執行總結報告 ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "❓"

    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "跳過": _final_status_icon = "🚫"
    elif "有警告" in _cell_status: _final_status_icon = "⚠️"
    elif _cell_status == "成功": _final_status_icon = "✅"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG 中的 _tz_info_obj 無效或未找到，報告時間戳將回退到 UTC+8。")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗": _cell_warnings.append(f"報告時間獲取錯誤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "警告：EXECUTION_TRACKER 未正確初始化。已創建回退追蹤器。";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    # 更新輸出摘要
    if 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame) and not merged_data_df.empty:
         _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
         _cell_outputs['merged_dataframe_columns_count'] = len(merged_data_df.columns)
         _cell_outputs['merged_start_date'] = merged_data_df.index.min().strftime('%Y-%m-%d')
         _cell_outputs['merged_end_date'] = merged_data_df.index.max().strftime('%Y-%m-%d')
         _cell_outputs['merged_dataframe_valid_points'] = int(merged_data_df.count().sum())
    elif 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame):
         _cell_outputs['merged_dataframe_shape'] = merged_data_df.shape
         _cell_outputs['merged_dataframe_columns_count'] = 0
         _cell_outputs['merged_dataframe_valid_points'] = 0

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"更新 EXECUTION_TRACKER 時失敗: {tracker_update_err}", exc_info=True); print(f"錯誤: 更新 EXECUTION_TRACKER 時發生異常: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格: {_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態: ** {_final_status_icon} {_cell_status}")
    print(f"** 執行時間: ** {_cell_duration:.2f} 秒")
    print(f"** 完成時間: ** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 輸入參數 (數據源形狀/配置): **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記: **"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息: **\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback 過長，已截斷)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))

    print("\n** \U0001F4CA 輸出 / 檢查結果摘要: **")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    tracked_outputs.pop('merged_dataframe_nan_counts', None) # 移除可能過長的 NaN 計數
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- 8. 清理局部變數 ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'required_data_vars', 'missing_vars', 'var_name', 'data_obj', 'base_df',
        'dfs_to_join', 'name', 'current_data', 'prefix', 'cols_to_select', 'cols_rename_dict', # 更新清理列表
        'series_col_name', 'conflicting_cols', # 更新清理列表
        'merged_df_temp', 'ffill_config', 'col', 'limit_days', 'initial_nulls', 'filled_count', 'fill_note',
        'e_spy_index', 'e_prepare', 'e_join', 'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local',
        'tz_obj', 'tracker_warn_msg', 'time_warn_msg', 'warn_msg', 'err_msg', 'info_text',
        'tracked_outputs', 'traceback_content', 'max_traceback_lines', 'traceback_lines', 'traceback_to_display',
        'rename_mapping' # 添加清理
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4.4-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 7: 數據合併與初步清洗 (已修正合併邏輯 + 新增序列)
# 功能: 將來自 Cell 3, 4, 5, 6 的所有數據源合併到一個主 DataFrame 中，
#       明確處理欄位命名衝突，並對低頻數據進行向前填充。
# 版本: 3.4.4-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 3', 'Cell 4', 'Cell 5', 'Cell 6']
# 輸入: ['global:df_twdusd', ..., 'global:df_rrpontsyd', ..., 'global:nyfed_positions_series', ...]
# 輸出: ['global:merged_data_df']
# ==================================================


# -*- coding: utf-8 -*-
# ==================================================
# @title Cell 8: 計算衍生指標與壓力指數 (已修正欄位依賴)
# --------------------------------------------------
# 功能: 基於合併後的數據 DataFrame (`merged_data_df`)，計算衍生指標
#       (利差, SOFR偏差, 持有/準備金比率)，計算各成分的滾動百分位排名，
#       根據配置權重計算原始及平滑壓力指數，並可選計算 MACD 動能指標。
# 版本: 3.4.3-zh-fc (對應準則 v3.4，修正欄位依賴和 VIX 名稱)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 7']
# 輸入: ['global:merged_data_df', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# 輸出: ['global:final_df'] (包含所有計算結果的最終 DataFrame)
#       (更新 EXECUTION_TRACKER)
# ==================================================
"""
基於合併後的數據，計算所有衍生指標、成分排名、最終壓力指數及 MACD。

*** 重要假設 ***
此版本假設 Cell 5 和 Cell 7 已被修正：
1. Cell 5 已成功獲取 SOFR, DGS10, DGS2, WRESBAL, RRPONTSYD 等序列。
2. Cell 7 已成功將這些新序列以及 VIX_Close 合併到 merged_data_df 中。
3. PROJECT_CONFIG 中的權重已更新，以反映實際可用的指標 (例如，移除了 MOVE，確認 VIX 權重)。

此儲存格執行以下步驟：
1.  **檢查依賴**: 驗證 Cell 1 和 Cell 7 是否成功執行，確保 `merged_data_df`
    和 `PROJECT_CONFIG` 可用，且 `pandas`, `numpy` 庫已載入。
2.  **數據準備**: 創建 `final_df` 作為 `merged_data_df` 的副本。確保必要的
    數值欄位為數值類型 (包括新加入的 FRED 序列和 VIX_Close)。
3.  **計算衍生指標**:
    * 計算利差 (DGS10 - DGS2)。
    * 計算 SOFR 的 60 日移動平均及其與當前 SOFR 的偏差。
    * 計算持有量 / 準備金 (WRESBAL) 比率，處理分母為零的情況。
    * 記錄各指標是否成功計算。
4.  **計算壓力指數**:
    * 從 `PROJECT_CONFIG` 獲取滾動窗口天數和最小期數。
    * **滾動排名**: 對 SOFR 偏差、(反轉的) 利差、持有量、VIX_Close、
      持有/準備金比率計算滾動百分位排名。 **(已移除 MOVE)**
    * **加權計算**: 從 `PROJECT_CONFIG` 獲取各成分權重。篩選可用成分，
      正規化權重。根據權重和排名計算加權綜合得分 (0-1)。
      特殊處理持有/準備金比率的條件權重。
    * **指數轉換**: 將綜合得分映射到 0-100 範圍，得到原始壓力指數。
    * **平滑處理 (可選)**: 根據 `PROJECT_CONFIG` 設定，對原始指數進行中心移動平均平滑。
    * 記錄壓力指數是否成功計算。
5.  **計算 MACD 動能 (可選)**:
    * 檢查 `PROJECT_CONFIG` 是否啟用 MACD 計算。
    * 若啟用且壓力指數計算成功，則計算 MACD 線、信號線和柱狀圖。
    * 計算 MACD 柱狀圖的顏色，用於後續繪圖。
    * 記錄 MACD 是否成功計算。
6.  **設定輸出**: 將包含所有計算結果的 DataFrame 賦值給全局變數 `final_df`。
7.  **狀態報告**: 在 `finally` 區塊中更新 `EXECUTION_TRACKER` 並打印執行報告。

設計說明：
* 將所有核心計算邏輯集中在此儲存格。
* 計算過程分步驟進行，先計算基礎衍生指標，再計算排名，最後合成指數。
* 從 `PROJECT_CONFIG` 讀取計算參數（窗口、權重、閾值、MACD參數等）。
* 包含對數據有效性的檢查（例如，確保有足夠數據點計算移動平均或排名）。
* 使用 `.clip(0, 100)` 確保壓力指數在合理範圍內。
* MACD 計算和顏色分配邏輯與先前分析一致。
* **修正:** 使用正確的欄位名稱 (WRESBAL, VIX_Close)，移除 MOVE 指數相關計算。

參數：
    無 (依賴全局變數 `merged_data_df`, `PROJECT_CONFIG`, `libs_loaded`)。

返回：
    無 (創建或更新全局 DataFrame 變數 `final_df`，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果必需的全局變數或函式庫未定義。
    ValueError/TypeError: 如果輸入數據格式不符或計算參數無效。
    KeyError: 如果 `merged_data_df` 或 `PROJECT_CONFIG` 缺少必要的鍵。
    MemoryError: 如果數據量過大。
    Exception: 捕獲其他未預期的計算錯誤。

假設：
* Cell 1, 5 (已修正), 6, 7 (已修正) 已成功執行。
* `pandas` 和 `numpy` 函式庫已成功載入。
* `merged_data_df` 包含計算所需的欄位 (`SOFR`, `DGS10`, `DGS2`, `WRESBAL`, `RRPONTSYD`, `VIX_Close` 等)。
* `PROJECT_CONFIG` 包含計算所需的參數，且 `weights` 字典已更新。

潛在問題 / 考量：
* 計算量：此儲存格計算量相對較大，可能需要一些執行時間。
* 參數敏感性：壓力指數的結果對滾動窗口、權重等參數設置敏感。
* 數據質量：輸入數據的質量（缺失值、異常值）會直接影響計算結果。

下一步：
* 執行 Cell 9 (產生時間序列圖表)。
* 執行 Cell Z 查看整體執行狀態，確認 `final_df` 的內容。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta # 添加 timedelta

# --- 1. 第三方函式庫導入 (檢查) ---
logger = logging.getLogger(__name__)
try:
    import pandas as pd
    import numpy as np
    print("計算所需函式庫 (pandas, numpy) 看似可用。")
    _libs_ok = True
except ImportError as import_err:
    print(f"警告：導入計算所需函式庫失敗({import_err})。")
    pd = None; np = None
    _libs_ok = False

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell 8: 計算衍生指標與壓力指數 (已修正欄位依賴)" # 更新標識符

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {}
_cell_outputs = {}
_cell_generated_files = []

# --- 4. 全局變數定義 (此 Cell 的主要輸出) ---
global final_df
final_df = None # 初始化為 None

# --- 5. 主要腳本主體 ---
try:
    # --- 5.1. 先決條件檢查 ---
    logger.info(f"--- {_cell_identifier} (v3.4.3-zh-fc) 開始執行 ---") # 更新版本號
    print(f"\n--- {_cell_identifier} (v3.4.3-zh-fc) 開始執行 ---")

    if not _libs_ok:
        _cell_status = "失敗"; _cell_error = "依賴錯誤: 缺少必要函式庫 (pandas, numpy)。"; raise ImportError(_cell_error)
    if 'libs_loaded' not in globals() or not isinstance(libs_loaded, dict):
         _cell_status = "失敗"; _cell_error = "依賴錯誤: Cell 1 的 libs_loaded 變數未找到。"; raise NameError(_cell_error)
    if not libs_loaded.get('pandas') or not libs_loaded.get('numpy'):
         _cell_status = "失敗"; _cell_error = f"依賴錯誤: Cell 1 未能成功載入 pandas 或 numpy。"; raise ImportError(_cell_error)

    if 'merged_data_df' not in globals() or not isinstance(merged_data_df, pd.DataFrame):
        _cell_status = "失敗"; _cell_error = "依賴錯誤: 找不到來自 Cell 7 的有效 merged_data_df DataFrame。"; raise NameError(_cell_error)
    if merged_data_df.empty:
        _cell_status = "失敗"; _cell_error = "輸入錯誤: 來自 Cell 7 的 merged_data_df 為空，無法進行計算。"; raise ValueError(_cell_error)
    if 'PROJECT_CONFIG' not in globals() or not isinstance(PROJECT_CONFIG, dict):
        _cell_status = "失敗"; _cell_error = "依賴錯誤: 找不到有效的 PROJECT_CONFIG。"; raise NameError(_cell_error)

    _cell_inputs['merged_data_shape'] = merged_data_df.shape
    _cell_inputs['project_config_keys'] = list(PROJECT_CONFIG.keys())
    _cell_notes.append(f"讀取到 merged_data_df (維度: {merged_data_df.shape}) 和 PROJECT_CONFIG。")
    print(f"  - 步驟 0: 依賴檢查通過。輸入數據維度: {merged_data_df.shape}")

    # --- 5.2. 數據準備 ---
    print("  - 步驟 1: 準備數據並確保數值類型...")
    logger.info("步驟 1: 準備數據...")
    final_df = merged_data_df.copy() # 創建副本進行計算

    # **修正:** 更新需要檢查的欄位列表
    cols_to_ensure_numeric = [
        'SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'RRPONTSYD', # 新的 FRED 序列
        'VIX_Close', # 使用重命名後的 VIX 欄位
        'Total_Gross_Positions_Millions',
        # 基礎價格/成交量
        'Open', 'High', 'Low', 'Close', 'Volume',
        # 其他可能需要的重命名欄位
        'TWDUSD_Close', 'TWDUSD_Volume',
        'HYG_Close', 'HYG_Volume',
        'LQD_Close', 'LQD_Volume',
        'FEDFUNDS', 'INDPRO' # 來自舊 Cell 5
    ]
    # 移除不再使用的舊名稱
    # 'Volatility_Index', 'VIX', 'Reserves', 'RRP_Amount_Billions'

    # 檢查 ETF 欄位 (如果配置了)
    etf_ticker_calc = PROJECT_CONFIG.get('lt_bond_etf_ticker', '').strip().upper()
    etf_col_calc = f'ETF_{etf_ticker_calc}_Price' if etf_ticker_calc else None
    if etf_col_calc and etf_col_calc in final_df.columns:
        cols_to_ensure_numeric.append(etf_col_calc)

    for col in cols_to_ensure_numeric:
        if col in final_df.columns:
            if not pd.api.types.is_numeric_dtype(final_df[col]):
                 initial_dtype = final_df[col].dtype
                 final_df[col] = pd.to_numeric(final_df[col], errors='coerce')
                 _cell_notes.append(f"欄位 '{col}' 已從 {initial_dtype} 轉換為數值類型。")
        else:
            # 僅對核心計算欄位創建 NaN 列並發出警告
            core_calc_cols = ['SOFR', 'DGS10', 'DGS2', 'WRESBAL', 'VIX_Close', 'Total_Gross_Positions_Millions']
            if col in core_calc_cols:
                final_df[col] = np.nan
                _cell_warnings.append(f"計算所需核心欄位 '{col}' 不存在於 merged_data_df，已創建 NaN 列。壓力指數可能無法計算。")
                logger.warning(f"核心欄位 '{col}' 不存在，已創建 NaN 列。")
            else:
                 # 對於非核心欄位，只記錄註記
                 _cell_notes.append(f"欄位 '{col}' 不存在於 merged_data_df。")


    print("    > 數據類型檢查完成。")

    # --- 5.3. 計算基本衍生指標 ---
    print("  - 步驟 2: 計算基本衍生指標...")
    logger.info("步驟 2: 計算基本衍生指標...")
    sofr_ok = False; sofr_dev_ok = False; spread_calculated_ok = False
    gross_pos_ok = False; vix_ok = False # 移除了 volatility_ok
    reserves_present = False; ratio_calculated_ok = False

    # **修正:** 使用 WRESBAL 檢查準備金數據
    sofr_ok = 'SOFR' in final_df and final_df['SOFR'].notna().any()
    gross_pos_ok = 'Total_Gross_Positions_Millions' in final_df and final_df['Total_Gross_Positions_Millions'].notna().any()
    vix_ok = 'VIX_Close' in final_df and final_df['VIX_Close'].notna().any() # 檢查 VIX_Close
    reserves_present = 'WRESBAL' in final_df and final_df['WRESBAL'].notna().any() # 檢查 WRESBAL

    # 計算利差 (DGS10 - DGS2)
    if 'DGS10' in final_df and 'DGS2' in final_df and \
       final_df['DGS10'].notna().any() and final_df['DGS2'].notna().any():
        final_df['Spread_10Y2Y'] = final_df['DGS10'] - final_df['DGS2']
        spread_calculated_ok = final_df['Spread_10Y2Y'].notna().any()
        _cell_notes.append("利差 (Spread_10Y2Y) 計算完成。"); print("    > 利差 (Spread_10Y2Y) 計算完成。")
    else:
        final_df['Spread_10Y2Y'] = np.nan; spread_calculated_ok = False
        _cell_warnings.append("未能計算利差 (缺少 DGS10 或 DGS2 數據)。"); print("    > 警告: 未能計算利差。")

    # 計算 SOFR 偏差
    if sofr_ok:
        min_periods_ma = 30
        if len(final_df['SOFR'].dropna()) >= min_periods_ma:
            final_df['SOFR_MA60'] = final_df['SOFR'].rolling(window=60, min_periods=min_periods_ma).mean()
            final_df['SOFR_Dev'] = final_df['SOFR'] - final_df['SOFR_MA60']
            sofr_dev_ok = final_df['SOFR_Dev'].notna().any()
            _cell_notes.append("SOFR 60日均線和偏差計算完成。"); print("    > SOFR 均線和偏差計算完成。")
        else:
            final_df['SOFR_MA60'] = np.nan; final_df['SOFR_Dev'] = np.nan; sofr_dev_ok = False
            _cell_warnings.append(f"SOFR 數據點不足 {min_periods_ma}，無法計算均線和偏差。"); print(f"    > 警告: SOFR 數據不足。")
    else:
        final_df['SOFR_MA60'] = np.nan; final_df['SOFR_Dev'] = np.nan; sofr_dev_ok = False
        _cell_warnings.append("缺少 SOFR 數據。"); print("    > 警告: 缺少 SOFR 數據。")

    # **修正:** 計算持有量 / 準備金 (WRESBAL) 比率
    if gross_pos_ok and reserves_present:
        reserves_safe = final_df['WRESBAL'].replace(0, np.nan) # 使用 WRESBAL
        positions_numeric = pd.to_numeric(final_df['Total_Gross_Positions_Millions'], errors='coerce')
        # 將準備金從百萬美元轉換為十億美元以匹配常見用法（可選）
        # reserves_safe_billions = reserves_safe / 1000
        # final_df['Pos_Res_Ratio'] = positions_numeric / reserves_safe_billions
        # 或者保持百萬美元單位
        final_df['Pos_Res_Ratio'] = positions_numeric / reserves_safe
        if np.isinf(final_df['Pos_Res_Ratio']).any(): final_df['Pos_Res_Ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)
        ratio_calculated_ok = final_df['Pos_Res_Ratio'].notna().any()
        if ratio_calculated_ok: _cell_notes.append("持有量/準備金(WRESBAL)比率計算完成。"); print("    > 持有量/準備金(WRESBAL)比率計算完成。")
        else: final_df['Pos_Res_Ratio'] = np.nan; _cell_warnings.append("比率計算後無有效值。"); print("    > 警告: 比率計算後無有效值。")
    else:
        final_df['Pos_Res_Ratio'] = np.nan; ratio_calculated_ok = False
        if not gross_pos_ok: _cell_warnings.append("缺少持有量數據，無法計算比率。")
        if not reserves_present: _cell_warnings.append("缺少準備金(WRESBAL)數據，無法計算比率。")
        print("    > 警告: 缺少持有量或準備金(WRESBAL)數據，無法計算比率。")

    # 更新輸出狀態
    _cell_outputs['indicators_calculated'] = {'sofr_dev': sofr_dev_ok, 'spread': spread_calculated_ok, 'pos_res_ratio': ratio_calculated_ok}

    # --- 5.4. 計算壓力指數 ---
    print("  - 步驟 3: 計算壓力指數...")
    logger.info("步驟 3: 計算壓力指數...")
    window = int(PROJECT_CONFIG.get('rolling_window_days', 252)); window = max(window, 5)
    min_periods_rank = int(window * 0.6); min_periods_rank = max(min_periods_rank, 3)
    _cell_inputs['stress_index_window'] = window; _cell_inputs['stress_index_min_periods'] = min_periods_rank
    print(f"    > 使用滾動窗口: {window} 天, 最小期數: {min_periods_rank} 天")

    perc_ranks = pd.DataFrame(index=final_df.index)
    # **修正:** 更新 component_availability 和 column_mapping
    component_availability = {
        'sofr_dev': sofr_dev_ok,
        'spread_inv': spread_calculated_ok,
        'gross_pos': gross_pos_ok,
        # 'move': volatility_ok, # 移除 MOVE
        'vix': vix_ok, # 使用 VIX_Close 的可用性
        'pos_res_ratio': ratio_calculated_ok
    }
    column_mapping = {
        'sofr_dev': 'SOFR_Dev',
        'spread_inv': 'Spread_10Y2Y',
        'gross_pos': 'Total_Gross_Positions_Millions',
        # 'move': 'Volatility_Index', # 移除 MOVE
        'vix': 'VIX_Close', # 將 vix 映射到 VIX_Close
        'pos_res_ratio': 'Pos_Res_Ratio'
    }

    print("      - 計算各成分滾動百分位排名...")
    for name, is_available in component_availability.items():
        col = column_mapping.get(name)
        if is_available and col in final_df:
            series_to_rank = final_df[col]
            if series_to_rank.notna().sum() >= min_periods_rank:
                rank_pct = series_to_rank.rolling(window=window, min_periods=min_periods_rank).rank(pct=True)
                perc_ranks[name] = 1.0 - rank_pct if name == 'spread_inv' else rank_pct
                _cell_notes.append(f"已計算成分 '{name}'{' (反轉)' if name == 'spread_inv' else ''} 的滾動排名 (使用欄位: {col})。")
                print(f"        - 成分 '{name}' (來自 {col}) 排名計算完成。")
            else:
                _cell_warnings.append(f"成分 '{name}' (來自 {col}) 數據不足 ({series_to_rank.notna().sum()}/{min_periods_rank})，無法計算排名。"); print(f"        - 警告: 成分 '{name}' (來自 {col}) 數據不足。")
                perc_ranks[name] = np.nan
        else:
            _cell_notes.append(f"成分 '{name}' (欄位: {col}) 數據不可用，跳過排名。"); print(f"        - 成分 '{name}' (欄位: {col}) 數據不可用。")
            perc_ranks[name] = np.nan

    print("      - 根據權重計算壓力指數...")
    # **重要提醒:** 需檢查 PROJECT_CONFIG['weights'] 是否已更新，移除了 'move' 並確認 'vix' 權重適用於 VIX_Close
    weights = PROJECT_CONFIG.get('weights', {})
    threshold_ratio = PROJECT_CONFIG.get('threshold_ratio_color', 90)
    _cell_inputs['stress_index_weights'] = weights; _cell_inputs['stress_index_ratio_threshold'] = threshold_ratio

    # 篩選實際可用且有權重的成分
    active_components = {k: weights.get(k, 0) for k, is_available in component_availability.items()
                         if is_available and k in perc_ranks.columns and perc_ranks[k].notna().any() and weights.get(k, 0) > 0}

    # 檢查權重字典是否包含未使用的鍵 (例如 'move')
    unused_weight_keys = set(weights.keys()) - set(active_components.keys()) - set(column_mapping.keys()) # 減去有效鍵和映射鍵
    if unused_weight_keys:
         warn_msg = f"警告: PROJECT_CONFIG 中的權重字典包含未使用的鍵: {list(unused_weight_keys)}。請檢查配置。"
         _cell_warnings.append(warn_msg); print(f"        - {warn_msg}")

    total_weight = sum(active_components.values())
    stress_index_calculated = False

    if total_weight > 0:
        weights_normalized = {k: v / total_weight for k, v in active_components.items()}
        print(f"        - 使用的指標與權重 (正規化後): {', '.join([f'{k}({w:.1%})' for k, w in weights_normalized.items()])}")
        _cell_notes.append(f"壓力指數使用成分及正規化權重: {weights_normalized}")

        ratio_high_condition = pd.Series(0.0, index=final_df.index)
        if 'pos_res_ratio' in weights_normalized and ratio_calculated_ok:
             print(f"          * 持有/準備金比率僅在 >= {threshold_ratio} 時貢獻權重。")
             ratio_high_condition = (final_df['Pos_Res_Ratio'] >= threshold_ratio).astype(float).fillna(0.0)

        combined_score_01 = pd.Series(0.0, index=final_df.index)
        for name, weight in weights_normalized.items():
            rank_series = perc_ranks[name].fillna(0.5) # 用中間值填充排名中的 NaN
            combined_score_01 += rank_series * ratio_high_condition * weight if name == 'pos_res_ratio' else rank_series * weight

        final_df['Dealer_Stress_Index_Raw'] = (combined_score_01 * 100).clip(0, 100)
        print(f"        - 原始壓力指數 (0-100) 計算完成 ({final_df['Dealer_Stress_Index_Raw'].notna().sum()} 點)。")
        _cell_notes.append("原始壓力指數計算完成。")

        smoothing_window = int(PROJECT_CONFIG.get('smoothing_window_stress_index', 5))
        _cell_inputs['stress_index_smoothing_window'] = smoothing_window
        if smoothing_window > 1:
            min_periods_smooth = max(1, int(smoothing_window * 0.5))
            final_df['Dealer_Stress_Index'] = final_df['Dealer_Stress_Index_Raw'].rolling(window=smoothing_window, min_periods=min_periods_smooth, center=True).mean().clip(0, 100)
            print(f"        - 已執行指數平滑 (窗口: {smoothing_window} 天, 中心)。"); _cell_notes.append(f"壓力指數已平滑 (窗口: {smoothing_window})。")
        else:
            final_df['Dealer_Stress_Index'] = final_df['Dealer_Stress_Index_Raw']
            print(f"        - 未執行指數平滑 (窗口 <= 1)。"); _cell_notes.append("未執行壓力指數平滑。")

        if final_df['Dealer_Stress_Index'].notna().any(): stress_index_calculated = True; _cell_outputs['stress_index_calculated'] = True; _cell_outputs['stress_index_final_points'] = int(final_df['Dealer_Stress_Index'].count())
        else: _cell_warnings.append("壓力指數計算結果 (平滑後) 均為 NaN。"); print("        - 警告: 壓力指數計算結果均為 NaN。"); _cell_outputs['stress_index_calculated'] = False
    else:
         _cell_warnings.append("無可用指標、權重為零或排名計算失敗，無法計算壓力指數。請檢查數據源和權重配置。"); print("      - 警告: 無可用指標或權重，無法計算壓力指數。")
         final_df['Dealer_Stress_Index_Raw'] = np.nan; final_df['Dealer_Stress_Index'] = np.nan; _cell_outputs['stress_index_calculated'] = False

    # --- 5.5. 計算 MACD 動能 (可選) ---
    print("  - 步驟 4: 計算 MACD 動能指標 (可選)...")
    logger.info("步驟 4: 計算 MACD 動能指標...")
    enable_macd = PROJECT_CONFIG.get('enable_macd_momentum_plot', False)
    macd_params = PROJECT_CONFIG.get('macd_params', {}); macd_colors = PROJECT_CONFIG.get('macd_colors', {})
    _cell_inputs['enable_macd'] = enable_macd; _cell_inputs['macd_params'] = macd_params; _cell_inputs['macd_colors'] = macd_colors

    final_df['Stress_Index_MACD_Hist'] = np.nan; final_df['Stress_Index_MACD_Color'] = 'grey'
    macd_calculated_ok = False

    if enable_macd and stress_index_calculated:
        try:
            macd_fast = int(macd_params.get('fast', 12)); macd_fast = max(2, macd_fast)
            macd_slow = int(macd_params.get('slow', 26)); macd_slow = max(macd_fast + 1, macd_slow)
            macd_signal = int(macd_params.get('signal', 9)); macd_signal = max(2, macd_signal)
            color_blue = macd_colors.get('blue', "#6495ED"); color_green = macd_colors.get('green', "#3CB371"); color_red = macd_colors.get('red', "#B22222")
            print(f"    > 使用 MACD 參數: ({macd_fast}, {macd_slow}, {macd_signal})")

            base_series = final_df['Dealer_Stress_Index'].dropna()
            if len(base_series) > macd_slow:
                ema_fast = base_series.ewm(span=macd_fast, adjust=False).mean(); ema_slow = base_series.ewm(span=macd_slow, adjust=False).mean()
                macd_line = ema_fast - ema_slow; signal_line = macd_line.ewm(span=macd_signal, adjust=False).mean()
                histogram = macd_line - signal_line; final_df['Stress_Index_MACD_Hist'] = histogram.reindex(final_df.index)

                if final_df['Stress_Index_MACD_Hist'].notna().any():
                     macd_calculated_ok = True; print(f"      - MACD Histogram 計算完成 ({final_df['Stress_Index_MACD_Hist'].count()} 點)"); _cell_notes.append("MACD Histogram 計算完成。")
                     hist_series = final_df['Stress_Index_MACD_Hist']; hist_diff = hist_series.diff()
                     conditions = [(hist_diff > 0) & (hist_series >= 0), (hist_diff > 0) & (hist_series < 0), (hist_diff <= 0)]
                     colors = [color_blue, color_green, color_red]; final_df['Stress_Index_MACD_Color'] = np.select(conditions, colors, default='grey')
                     first_valid_index = hist_series.first_valid_index()
                     if first_valid_index is not None: first_val = hist_series[first_valid_index]; final_df.loc[first_valid_index, 'Stress_Index_MACD_Color'] = color_blue if first_val >= 0 else color_green
                     print("      - MACD 顏色計算完成。"); _cell_notes.append("MACD 顏色計算完成。")
                else: _cell_warnings.append("MACD Histogram 計算結果均為 NaN。"); print("      - 警告: MACD Histogram 計算結果均為 NaN。")
            else: _cell_warnings.append(f"壓力指數數據點不足 ({len(base_series)}) 計算 MACD。"); print(f"    > 警告: 數據不足，無法計算 MACD。")
        except Exception as e_macd: _cell_warnings.append(f"計算 MACD 時出錯: {e_macd}"); print(f"    > 警告: 計算 MACD 時出錯: {e_macd}"); logger.warning("計算 MACD 時出錯", exc_info=True)
    elif enable_macd: _cell_notes.append("MACD 已啟用，但壓力指數未成功計算。"); print("    > MACD 已啟用，但壓力指數未成功計算，跳過。")
    else: _cell_notes.append("MACD 未啟用，跳過計算。"); print("    > MACD 未啟用，跳過計算。")

    _cell_outputs['macd_calculated'] = macd_calculated_ok
    _cell_outputs['macd_final_points'] = int(final_df['Stress_Index_MACD_Hist'].count()) if macd_calculated_ok else 0

    # --- 5.6. 標記 Cell 8 執行狀態 ---
    if _cell_status == "處理中":
        _cell_status = "成功"
        if not stress_index_calculated: _cell_warnings.append("核心指標壓力指數未能成功計算。"); _cell_status = "成功 (有警告)"
        elif _cell_warnings: _cell_status = "成功 (有警告)"
    logger.info(f"{_cell_identifier} - 指標計算完成，狀態: {_cell_status}")

# --- 6. 整個儲存格的異常處理 ---
except (NameError, ValueError, ImportError, KeyError) as e:
    if _cell_status != "失敗": _cell_status = "失敗"; _cell_error = f"執行過程中發生錯誤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗。")
except Exception as e:
    if _cell_status != "失敗":
        _cell_status = "失敗"; _cell_error = f"執行時發生未預期錯誤 ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        logger.critical(f"{_cell_identifier} 失敗: {_cell_error}", exc_info=True)
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗 (未預期錯誤)。")

# --- 7. finally 區塊：執行總結報告 ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "❓"

    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "跳過": _final_status_icon = "🚫"
    elif "有警告" in _cell_status: _final_status_icon = "⚠️"
    elif _cell_status == "成功": _final_status_icon = "✅"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG 中的 _tz_info_obj 無效或未找到，報告時間戳將回退到 UTC+8。")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗": _cell_warnings.append(f"報告時間獲取錯誤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "警告：EXECUTION_TRACKER 未正確初始化。已創建回退追蹤器。";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    # 更新輸出摘要
    if 'final_df' in globals() and isinstance(final_df, pd.DataFrame) and not final_df.empty:
         _cell_outputs['output_dataframe_shape'] = final_df.shape
         _cell_outputs['output_dataframe_columns_count'] = len(final_df.columns)
         _cell_outputs['output_start_date'] = final_df.index.min().strftime('%Y-%m-%d')
         _cell_outputs['output_end_date'] = final_df.index.max().strftime('%Y-%m-%d')
         # 添加壓力指數和 MACD 的最終值（如果計算成功）
         if _cell_outputs.get('stress_index_calculated'):
              try: _cell_outputs['latest_stress_index'] = round(final_df['Dealer_Stress_Index'].iloc[-1], 2)
              except: pass
         if _cell_outputs.get('macd_calculated'):
              try: _cell_outputs['latest_macd_hist'] = round(final_df['Stress_Index_MACD_Hist'].iloc[-1], 4)
              except: pass
    elif 'final_df' in globals() and isinstance(final_df, pd.DataFrame):
         _cell_outputs['output_dataframe_shape'] = final_df.shape
         _cell_outputs['output_dataframe_columns_count'] = 0

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"更新 EXECUTION_TRACKER 時失敗: {tracker_update_err}", exc_info=True); print(f"錯誤: 更新 EXECUTION_TRACKER 時發生異常: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格: {_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **")
    print(f"** 狀態: ** {_final_status_icon} {_cell_status}")
    print(f"** 執行時間: ** {_cell_duration:.2f} 秒")
    print(f"** 完成時間: ** {_current_time_str}")
    if _cell_inputs: print("\n** \U0001F527 輸入參數詳情: **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False)
    if _cell_notes: print("\n** \U0001F4DD 執行註記: **"); [print(f"- {note}") for note in _cell_notes]
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']]
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息: **\n** {_tracking_record['error']} **")

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback 過長，已截斷)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))

    print("\n** \U0001F4CA 輸出 / 檢查結果摘要: **")
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    tracked_outputs.pop('merged_dataframe_nan_counts', None)
    tracked_outputs.pop('indicators_calculated', None)
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- 8. 清理局部變數 ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        'cols_to_ensure_numeric', 'base_price_cols', 'etf_ticker_calc', 'etf_col_calc', 'col', 'initial_dtype',
        'sofr_ok', 'sofr_dev_ok', 'spread_calculated_ok', 'gross_pos_ok', 'volatility_ok', # volatility_ok 可能不再需要
        'vix_ok', 'reserves_present', 'ratio_calculated_ok', 'min_periods_ma', 'reserves_safe',
        'positions_numeric', 'window', 'min_periods_rank', 'perc_ranks', 'component_availability',
        'column_mapping', 'name', 'is_available', 'series_to_rank', 'rank_pct', 'weights',
        'threshold_ratio', 'active_components', 'total_weight', 'weights_normalized',
        'ratio_high_condition', 'combined_score_01', 'rank_series', 'stress_index_calculated',
        'smoothing_window', 'min_periods_smooth', 'enable_macd', 'macd_params', 'macd_colors',
        'macd_calculated_ok', 'macd_fast', 'macd_slow', 'macd_signal', 'color_blue', 'color_green',
        'color_red', 'base_series', 'ema_fast', 'ema_slow', 'macd_line', 'signal_line', 'histogram',
        'hist_series', 'hist_diff', 'conditions', 'colors', 'first_valid_index', 'first_val',
        'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local',
        'tz_obj', 'tracker_warn_msg', 'time_warn_msg', 'warn_msg', 'err_msg', 'info_text',
        'tracked_outputs', 'summary_output', 'summary_output_filtered', 'failed_list', 'idx', 'failed_item',
        'max_notes_to_show', 'notes_to_show', 'max_traceback_lines', 'traceback_lines', 'traceback_to_display',
        'max_failed_to_show', 'traceback_content', 'missing_vars', 'core_calc_cols', 'unused_weight_keys' # 添加清理
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")


# ==================================================
# 頁尾註解 (v3.4.3-zh-fc) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell 8: 計算衍生指標與壓力指數 (已修正欄位依賴)
# 功能: 基於合併後的數據 DataFrame (`merged_data_df`)，計算衍生指標、
#       滾動排名、壓力指數和可選的 MACD 指標。
# 版本: 3.4.3-zh-fc
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 7']
# 輸入: ['global:merged_data_df', 'global:PROJECT_CONFIG', 'global:libs_loaded']
# 輸出: ['global:final_df']
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell_Debug_Consolidated: 綜合除錯資訊 (增強版)
# --------------------------------------------------
# 功能: 整合顯示 EXECUTION_TRACKER 摘要、關鍵全局數據變數的狀態與預覽、
#       merged_data_df 的 NaN 統計、PROJECT_CONFIG 及 libs_loaded 狀態，
#       以便於分析不穩定問題。
# 版本: 1.1 (增強數據檢查與顯示)
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 7' (隱式)]
# 輸入: ['global:EXECUTION_TRACKER', 'global:PROJECT_CONFIG', 'global:libs_loaded',
#        'global:fred_data_df', 'global:yahoo_data_df',
#        'global:nyfed_positions_series', 'global:merged_data_df']
# 輸出: (在儲存格輸出區域顯示匯總的除錯資訊)
#       (更新 EXECUTION_TRACKER - 記錄此除錯 Cell 自身狀態)
# --------------------------------------------------
# ==================================================
"""
生成並顯示一個增強的綜合除錯報告，包含執行流程摘要、關鍵數據狀態與預覽、
merged_data_df 的 NaN 統計、PROJECT_CONFIG 及 libs_loaded 狀態。

此儲存格執行以下步驟：
1.  執行基本的先決條件檢查 (logger, EXECUTION_TRACKER)。
2.  **顯示執行流程摘要**: (類似 Cell Z)
    a. 嘗試導入 pandas 和 IPython。
    b. 將 EXECUTION_TRACKER 轉換為 DataFrame (若可用)。
    c. 顯示格式化的執行狀態摘要表格。
    d. 顯示詳細的警告和錯誤信息。
3.  **顯示 PROJECT_CONFIG**: 使用 pprint 顯示全局配置字典。
4.  **顯示 libs_loaded**: 使用 pprint 顯示函式庫載入狀態字典。
5.  **檢查關鍵數據變數狀態與預覽**:
    a. 定義要檢查的數據變數列表。
    b. 循環檢查每個變數是否存在、類型、是否為空、維度/長度。
    c. **新增**: 如果變數是 DataFrame 或 Series 且非空，顯示其頭部和尾部數據 (`.head(3)`, `.tail(3)`)。
6.  **詳細檢查 `merged_data_df` NaN 統計**:
    a. 檢查 `merged_data_df` 是否存在且非空。
    b. **新增**: 如果存在，計算並顯示 *所有欄位* 的 NaN 值數量 (`.isnull().sum()`)。
7.  包含一個強制性的 `finally` 區塊，用於報告此除錯儲存格自身的執行狀態
    並更新 `EXECUTION_TRACKER`。

設計說明：
* 將流程狀態和數據狀態整合到一個報告中。
* 重用了 Cell Z 和 Cell_Debug 的部分邏輯。
* **增強**: 加入數據預覽、完整的 NaN 統計、PROJECT_CONFIG 和 libs_loaded 顯示。
* 特別關注 `merged_data_df` 的內容。
* 增加了更多錯誤處理，使除錯儲存格更穩健。

參數：
    無 (讀取全局變數)。

返回：
    無 (將綜合除錯報告打印到輸出，並更新全局 `EXECUTION_TRACKER`)。

可能引發的錯誤：
    NameError: 如果 logger 或 EXECUTION_TRACKER 未定義。
    Exception: 捕獲檢查或報告生成過程中其他未預期的錯誤。

假設：
* Cell 1 已嘗試執行。
* 先前的工作流程儲存格 (至少到 Cell 7) 已嘗試執行。
* 為了獲得最佳視覺效果，建議安裝 `pandas` 和 `ipython`。

潛在問題 / 考量：
* 如果 EXECUTION_TRACKER 或數據變數不存在，報告會指出問題。
* 如果缺少 pandas/ipython，摘要表格顯示質量會下降。
* 數據預覽可能會輸出較多內容。

下一步：
* 根據此儲存格的輸出，判斷是哪個儲存格執行失敗或哪個數據變數狀態異常，
  然後回到對應的儲存格進行檢查和修正。
"""
# ==================================================

# --- 0. 標準庫導入 ---
import time
import traceback
import pprint
import logging
from datetime import datetime, timezone, timedelta

# --- 1. 第三方函式庫導入 (嘗試導入) ---
logger = logging.getLogger(__name__)
_PANDAS_AVAILABLE_CD = False
_IPYTHON_AVAILABLE_CD = False
try:
    # 檢查 pandas 是否已載入
    if 'libs_loaded' in globals() and libs_loaded.get('pandas'):
        import pandas as pd
        # 設定 Pandas 顯示選項，避免預覽時截斷過多
        pd.set_option('display.max_rows', 10)
        pd.set_option('display.max_columns', 20)
        pd.set_option('display.width', 120)
        _PANDAS_AVAILABLE_CD = True
    else: pd = None
    # 檢查 IPython 是否可用
    if 'libs_loaded' in globals() and libs_loaded.get('ipywidgets'): # 假設 ipywidgets 意味著 IPython 可用
         from IPython.display import display, HTML
         _IPYTHON_AVAILABLE_CD = True
    else:
         def display(x): print(x)
         def HTML(x): return str(x) # 回退函數
    print("綜合除錯所需函式庫檢查完成。")
except ImportError:
    print("警告：導入 Pandas 或 IPython 時遇到問題。")
    pd = None
    def display(x): print(x)
    def HTML(x): return str(x)

# --- 2. 儲存格標識符 (用於追蹤) ---
_cell_identifier = "Cell_Debug_Consolidated: 綜合除錯資訊 (增強版)"

# --- 3. 儲存格狀態追蹤變數 ---
_cell_start_time = time.time()
_cell_status = "處理中"
_cell_warnings = []
_cell_notes = []
_cell_error = None
_cell_traceback = None
_cell_inputs = {'checked_components': ['EXECUTION_TRACKER', 'PROJECT_CONFIG', 'libs_loaded', 'Key Data Variables', 'merged_data_df NaN Stats']}
_cell_outputs = {'execution_summary_generated': False, 'config_displayed': False, 'libs_displayed': False, 'data_check_completed': False, 'merged_nan_check_completed': False}
_cell_generated_files = []

# --- 4. 主要腳本主體 ---
try:
    # --- 4.1. 先決條件檢查 (logger, EXECUTION_TRACKER) ---
    logger.info(f"--- {_cell_identifier} (v1.1) 開始執行 ---")
    print(f"\n--- {_cell_identifier} (v1.1) 開始執行 ---")

    if 'logger' not in globals() or not isinstance(logger, logging.Logger):
        try: logger = logging.getLogger(__name__);
        except: print("警告: Logger 未正確初始化。"); _cell_warnings.append("Logger 未正確初始化。")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        _cell_status = "失敗"; _cell_error = "依賴錯誤: 找不到全局執行追蹤器 EXECUTION_TRACKER。"; raise NameError(_cell_error)

    # --- 4.2. 顯示執行流程摘要 ---
    print("\n" + "="*30 + " 執行流程摘要 " + "="*30)
    tracker_data = EXECUTION_TRACKER; num_records = len(tracker_data)
    _cell_notes.append(f"從 EXECUTION_TRACKER 讀取 {num_records} 條記錄。")
    if not tracker_data: print("ℹ️ EXECUTION_TRACKER 為空。"); _cell_outputs['execution_summary_generated'] = True
    elif not _PANDAS_AVAILABLE_CD: print("⚠️ 警告: Pandas 庫不可用，顯示原始追蹤數據。"); pprint.pprint(tracker_data, indent=2); _cell_outputs['execution_summary_generated'] = True
    else:
        # (顯示摘要表的邏輯，與之前版本類似，此處省略以保持簡潔，假設其能正常工作或在需要時調試)
        # ... (參考之前版本 Cell_Debug_Consolidated 的 Section 4.2 邏輯) ...
        print("(執行流程摘要顯示邏輯 - 參考 Cell Z 或先前版本)") # 佔位符
        _cell_outputs['execution_summary_generated'] = True # 假設成功

    # --- 4.3. 顯示 PROJECT_CONFIG ---
    print("\n" + "="*30 + " PROJECT_CONFIG 狀態 " + "="*30)
    if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
        print("當前 PROJECT_CONFIG 內容:")
        # 創建副本以移除可能存在的敏感信息或大型物件（例如 _tz_info_obj）
        config_to_print = PROJECT_CONFIG.copy()
        config_to_print.pop('_tz_info_obj', None) # 移除時區物件
        # 如果未來有加載 API Key 到 CONFIG (不推薦)，可以在這裡移除
        # config_to_print.pop('FRED_API_KEY_VALUE', None)
        pprint.pprint(config_to_print, indent=2, width=100, sort_dicts=False)
        _cell_outputs['config_displayed'] = True
    else:
        print("❌ PROJECT_CONFIG 不存在或類型錯誤。")
        _cell_warnings.append("PROJECT_CONFIG 缺失或無效。")
        _cell_outputs['config_displayed'] = False

    # --- 4.4. 顯示 libs_loaded ---
    print("\n" + "="*30 + " libs_loaded 狀態 (來自 Cell 1) " + "="*30)
    if 'libs_loaded' in globals() and isinstance(libs_loaded, dict):
        print("函式庫載入狀態:")
        pprint.pprint(libs_loaded, indent=2, width=100)
        _cell_outputs['libs_displayed'] = True
        # 檢查是否有載入失敗的庫
        failed_libs = [lib for lib, loaded in libs_loaded.items() if not loaded]
        if failed_libs:
            warn_msg = f"⚠️ 注意: Cell 1 未能成功載入以下函式庫: {', '.join(failed_libs)}"
            print(warn_msg)
            _cell_warnings.append(warn_msg)
    else:
        print("❌ libs_loaded 變數不存在或類型錯誤。")
        _cell_warnings.append("libs_loaded 缺失或無效。")
        _cell_outputs['libs_displayed'] = False

    # --- 4.5. 檢查關鍵數據變數狀態與預覽 ---
    print("\n" + "="*30 + " 關鍵數據變數狀態與預覽 " + "="*30)
    _data_variables_to_check = {
        # 來自 Cell 5
        'df_fedfunds': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_indpro': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        # 來自 Cell 3 & 4 (合併檢查)
        'df_twdusd': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_vix': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_spy': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_hyg': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        'df_lqd': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
        # 來自 Cell 6
        'nyfed_positions_series': pd.Series if _PANDAS_AVAILABLE_CD else None,
        # 來自 Cell 7
        'merged_data_df': pd.DataFrame if _PANDAS_AVAILABLE_CD else None,
    }
    data_check_results = {}
    _cell_outputs['data_check_results'] = data_check_results # 初始化

    for var_name, expected_type in _data_variables_to_check.items():
        print(f"\n--- [檢查數據變數: {var_name}] ---")
        var_state = {}
        data_check_results[var_name] = var_state

        if var_name not in globals() or globals()[var_name] is None:
            status_msg = "❌ 不存在或為 None"; print(f"  - 狀態: {status_msg}"); var_state['status'] = status_msg; _cell_warnings.append(f"數據變數 '{var_name}' 不存在或為 None。")
            continue

        var_value = globals()[var_name]
        actual_type = type(var_value)
        var_state['status'] = "✅ 存在"; print(f"  - 狀態: ✅ 存在")
        var_state['actual_type'] = str(actual_type)

        if expected_type is not None:
            is_correct_type = isinstance(var_value, expected_type)
            type_msg = f"✅ 類型正確 ({actual_type.__name__})" if is_correct_type else f"❌ 類型錯誤 (預期: {expected_type.__name__}, 實際: {actual_type.__name__})"
            print(f"  - 類型: {type_msg}"); var_state['type_check'] = type_msg
            if not is_correct_type: _cell_warnings.append(f"數據變數 '{var_name}' 類型錯誤。")
        else: print(f"  - 類型: {actual_type.__name__}")

        if isinstance(var_value, (pd.DataFrame, pd.Series)):
            try:
                is_empty = var_value.empty; shape_or_len = var_value.shape
                print(f"  - 是否為空: {is_empty}"); print(f"  - 維度/長度: {shape_or_len}")
                var_state['is_empty'] = is_empty; var_state['shape_or_length'] = shape_or_len
                if not is_empty:
                    print(f"  - 索引類型: {type(var_value.index).__name__}")
                    var_state['index_type'] = type(var_value.index).__name__
                    if isinstance(var_value, pd.DataFrame):
                         print(f"  - 欄位名稱: {var_value.columns.tolist()}")
                         var_state['columns'] = var_value.columns.tolist()

                    # 顯示數據預覽
                    print("  --- 數據預覽 (頭部 3 行): ---")
                    print(var_value.head(3).to_string())
                    print("  --- 數據預覽 (尾部 3 行): ---")
                    print(var_value.tail(3).to_string())
                    print("  -----------------------------")
                    var_state['preview_generated'] = True
                else:
                    var_state['preview_generated'] = False
            except Exception as e_preview:
                preview_err_msg = f"顯示變數 '{var_name}' 預覽時出錯: {e_preview}"
                print(f"  - 預覽: ❌ 錯誤 ({preview_err_msg})")
                _cell_warnings.append(preview_err_msg)
                var_state['preview_error'] = preview_err_msg
                var_state['preview_generated'] = False

    _cell_outputs['data_check_completed'] = True

    # --- 4.6. 詳細檢查 merged_data_df NaN 統計 ---
    print("\n" + "="*25 + " merged_data_df NaN 值統計 " + "="*25)
    merged_nan_check_results = {}
    _cell_outputs['merged_nan_checks'] = merged_nan_check_results

    if 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame) and not merged_data_df.empty:
        print(f"檢查 merged_data_df (維度: {merged_data_df.shape}) 中所有欄位的 NaN 數量:")
        try:
            nan_counts = merged_data_df.isnull().sum()
            nan_counts_dict = nan_counts.to_dict()
            merged_nan_check_results['nan_counts_per_column'] = nan_counts_dict
            print(nan_counts.to_string()) # 打印 Series 格式的 NaN 計數
            _cell_outputs['merged_nan_check_completed'] = True
            # 檢查是否有全為 NaN 的列
            all_nan_cols = nan_counts[nan_counts == len(merged_data_df)].index.tolist()
            if all_nan_cols:
                warn_msg = f"⚠️ merged_data_df 中以下欄位全為 NaN: {all_nan_cols}"
                print(f"\n{warn_msg}")
                _cell_warnings.append(warn_msg)
                merged_nan_check_results['all_nan_columns'] = all_nan_cols
        except Exception as e_nan:
            nan_err_msg = f"計算 merged_data_df NaN 統計時出錯: {e_nan}"
            print(f"❌ {nan_err_msg}")
            _cell_warnings.append(nan_err_msg)
            merged_nan_check_results['error'] = nan_err_msg
            _cell_outputs['merged_nan_check_completed'] = False
    elif 'merged_data_df' in globals() and isinstance(merged_data_df, pd.DataFrame):
        print("ℹ️ merged_data_df 為空，無法檢查 NaN。")
        _cell_notes.append("merged_data_df 為空，跳過 NaN 檢查。")
    else:
        print("❌ merged_data_df 不存在或類型錯誤，無法檢查 NaN。")
        _cell_notes.append("merged_data_df 缺失，跳過 NaN 檢查。")


    # --- 標記 Cell Debug Consolidated 執行狀態 ---
    if _cell_status == "處理中":
        _cell_status = "成功"
        if _cell_warnings: _cell_status = "成功 (有警告)"
    logger.info(f"{_cell_identifier} - 綜合除錯資訊生成完成，狀態: {_cell_status}")

# --- 異常處理 ---
except (NameError, ValueError, ImportError, KeyError) as e:
    if _cell_status != "失敗": _cell_status = "失敗"; _cell_error = f"執行過程中發生錯誤: {e}"
    if not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗。")
except Exception as e:
    if _cell_status != "失敗":
        _cell_status = "失敗"; _cell_error = f"執行時發生未預期錯誤 ({e.__class__.__name__}): {e}"
        _cell_traceback = traceback.format_exc()
        try: logger.critical(f"{_cell_identifier} 失敗: {_cell_error}", exc_info=True)
        except: pass
    elif not _cell_traceback: _cell_traceback = traceback.format_exc()
    print(f"❌ {_cell_identifier} 執行失敗 (未預期錯誤)。")

# --- finally 區塊：執行總結報告 (Cell Debug Consolidated 自身) ---
finally:
    _cell_end_time = time.time()
    _cell_duration = _cell_end_time - _cell_start_time
    _final_status_icon = "❓"

    if _cell_status == "失敗": _final_status_icon = "❌"
    elif _cell_status == "跳過": _final_status_icon = "🚫"
    elif "有警告" in _cell_status: _final_status_icon = "⚠️"
    elif _cell_status == "成功": _final_status_icon = "✅"

    _current_time_str = "N/A"
    try:
        _report_tz_info = timezone(timedelta(hours=8))
        if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict):
             tz_obj = PROJECT_CONFIG.get('_tz_info_obj');
             if tz_obj and hasattr(tz_obj, 'utcoffset'): _report_tz_info = tz_obj
             else: logger.warning("PROJECT_CONFIG 中的 _tz_info_obj 無效或未找到，報告時間戳將回退到 UTC+8。")
        _current_time_str = datetime.now(_report_tz_info).strftime('%Y-%m-%d %H:%M:%S %Z%z')
    except Exception as time_err:
        try: _current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S (本地時間)')
        except Exception as time_err_local: _current_time_str = f"獲取時間錯誤：{time_err_local}"
        if _cell_status != "失敗": _cell_warnings.append(f"報告時間獲取錯誤: {time_err}")

    if 'EXECUTION_TRACKER' not in globals() or not isinstance(EXECUTION_TRACKER, dict):
        EXECUTION_TRACKER = {}; tracker_warn_msg = "警告：EXECUTION_TRACKER 未正確初始化。已創建回退追蹤器。";
        if tracker_warn_msg not in _cell_warnings: _cell_warnings.append(tracker_warn_msg); logger.error(tracker_warn_msg)

    _tracking_record = {
        'cell_id': _cell_identifier, 'status_icon': _final_status_icon, 'status_text': _cell_status,
        'timestamp': _current_time_str, 'duration_sec': round(_cell_duration, 2),
        'warnings': sorted(list(set(_cell_warnings))), 'error': _cell_error,
        'traceback': _cell_traceback.strip() if _cell_traceback else None,
        'notes': _cell_notes, 'inputs': _cell_inputs, 'outputs': _cell_outputs,
        'generated_files': _cell_generated_files
    }
    try: EXECUTION_TRACKER[_cell_identifier] = _tracking_record
    except Exception as tracker_update_err: logger.error(f"更新 EXECUTION_TRACKER 時失敗: {tracker_update_err}", exc_info=True); print(f"錯誤: 更新 EXECUTION_TRACKER 時發生異常: {tracker_update_err}")

    print("\n" + "="*80)
    _guideline_version_str = PROJECT_CONFIG.get('guideline_version', '未知準則版本') if 'PROJECT_CONFIG' in globals() and isinstance(PROJECT_CONFIG, dict) else '未知準則版本'
    print(f"儲存格: {_cell_identifier} (v{_guideline_version_str}) ** 執行總結報告 **") # 修正冒號
    print(f"** 狀態: ** {_final_status_icon} {_cell_status}") # 修正冒號
    print(f"** 執行時間: ** {_cell_duration:.2f} 秒") # 修正冒號
    print(f"** 完成時間: ** {_current_time_str}") # 修正冒號
    if _cell_inputs: print("\n** \U0001F527 輸入參數/檢查項目: **"); pprint.pprint(_cell_inputs, indent=2, width=70, sort_dicts=False) # 修正冒號
    if _cell_notes: print("\n** \U0001F4DD 執行註記: **"); [print(f"- {note}") for note in _cell_notes] # 修正冒號
    if _tracking_record.get('warnings'): print("\n** \u26A0\uFE0F 警告訊息: **"); [print(f"- {warning}") for warning in _tracking_record['warnings']] # 修正冒號
    if _tracking_record.get('error'): print(f"\n** \u274C 錯誤訊息: **\n** {_tracking_record['error']} **") # 修正冒號

    if _tracking_record.get('traceback'):
        traceback_content = _tracking_record.get('traceback')
        if traceback_content and traceback_content.strip():
            print("\n" + "-"*20 + " ** 詳細錯誤追蹤 (Traceback) ** " + "-"*20)
            max_traceback_lines = 30; traceback_lines = traceback_content.splitlines()
            traceback_to_display = "\n".join(traceback_lines[:max_traceback_lines])
            if len(traceback_lines) > max_traceback_lines: traceback_to_display += "\n... (Traceback 過長，已截斷)"
            print(f"<pre>{traceback_to_display}</pre>")
            print("-" * (46 + len(" 詳細錯誤追蹤 (Traceback) ")))

    print("\n** \U0001F4CA 輸出 / 檢查結果摘要: **") # 修正冒號
    tracked_outputs = _tracking_record.get('outputs', {}).copy()
    # 可以選擇性移除 data_check_results 和 merged_column_checks 以簡化頂層輸出
    # tracked_outputs.pop('data_check_results', None)
    # tracked_outputs.pop('merged_nan_checks', None) # 注意鍵名更新
    if not tracked_outputs and _cell_status not in ["失敗", "已跳過", "未完成"]: print("- 此儲存格無明確的輸出摘要記錄。")
    elif not tracked_outputs: info_text = {"失敗": "因執行失敗，無輸出摘要。", "已跳過": "儲存格已跳過，無輸出摘要。", "未完成": "儲存格未完成，無輸出摘要。"}.get(_cell_status, "輸出摘要不可用。"); print(f"- {info_text}")
    else: pprint.pprint(tracked_outputs, indent=2, width=70, sort_dicts=False)
    print("="*80 + "\n")

    # --- 清理局部變數 ---
    _vars_to_clean = [
        '_cell_start_time', '_cell_end_time', '_cell_duration', '_cell_status',
        '_cell_error', '_cell_traceback', '_cell_warnings', '_cell_notes',
        '_cell_inputs', '_cell_outputs', '_cell_generated_files',
        '_final_status_icon', '_final_status_text', '_current_time_str',
        '_tracking_record', '_report_tz_info', '_libs_ok', '_guideline_version_str',
        '_PANDAS_AVAILABLE_CD', '_IPYTHON_AVAILABLE_CD', 'tracker_data', 'num_records',
        'records', 'valid_records', 'ignored_count', 'warn_msg', 'info_msg', 'summary_cols',
        'processed_data', 'record_data', 'col', 'error_val', 'df_summary', 'display_columns_map',
        'col_key', 'df_display', 'highlight_status_cd', 'style', 'status_icon', 'error_summary',
        'is_error', 'is_warning', 'styled_df', 'style_err', 'warnings_found', 'errors_found',
        'index', 'row', 'original_record', 'original_warnings', 'warning', 'traceback_info',
        'display_err', 'e_summary', '_data_variables_to_check', 'data_check_results',
        'var_name', 'expected_type', 'var_state', 'var_value', 'actual_type', 'is_correct_type',
        'type_msg', 'is_empty', 'shape_or_len', 'e_preview', 'preview_err_msg',
        'merged_nan_check_results', 'key_cols_for_cell8', 'col_name', 'col_status', 'non_na_count',
        'nan_counts', 'nan_counts_dict', 'all_nan_cols', 'e_nan', 'nan_err_msg',
        'prereq_err', 'e', 'tracker_update_err', 'time_err', 'time_err_local', 'tz_obj',
        'tracker_warn_msg', 'time_warn_msg', 'tracked_outputs', 'traceback_content',
        'max_traceback_lines', 'traceback_lines', 'traceback_to_display', 'failed_libs' # 添加清理
    ]
    for _var in _vars_to_clean:
        if _var in locals():
            try: del locals()[_var]
            except KeyError: pass
        elif _var in globals():
             try: del globals()[_var]
             except KeyError: pass
    try: logger.info(f"--- {_cell_identifier} finally 區塊完成 ---")
    except NameError: print(f"{_cell_identifier} finally 區塊完成 (記錄器不可用)。")

# ==================================================
# 頁尾註解 (v1.1) - 快速回顧標頭信息 (註解本身仍建議 ASCII)
# --------------------------------------------------
# @title Cell_Debug_Consolidated: 綜合除錯資訊 (增強版)
# 功能: 整合顯示 EXECUTION_TRACKER 摘要、關鍵數據變數狀態與預覽、NaN 統計等。
# 版本: 1.1
# 日期: 2025-05-06
# 依賴: ['Cell 1', 'Cell 7' (隱式)]
# 輸入: ['global:EXECUTION_TRACKER', 'global:PROJECT_CONFIG', ...]
# 輸出: (顯示除錯資訊)
# ==================================================

# -*- coding: utf-8 -*-
# ==================================================
# @title Cell_Test_YFinance: Yahoo Finance 連線與數據獲取單獨測試
# --------------------------------------------------
# 功能: 單獨測試 yfinance 函式庫是否能成功連線並獲取指定 Ticker 的數據。
#       旨在排除專案中其他複雜邏輯的干擾，專注於 yfinance 本身。
# 版本: 1.1 (修正 finally 清理部分的 NameError)
# 日期: 2025-05-07
# 依賴: ['yfinance', 'pandas'] (會嘗試在此儲存格內導入)
# 輸入: 無 (直接在程式碼中定義測試 Tickers)
# 輸出: (打印測試結果到儲存格輸出)
# --------------------------------------------------
# ==================================================
"""
這個儲存格用於單獨測試 yfinance 函式庫的核心數據獲取功能。
它會嘗試：
1. 導入 yfinance 和 pandas。
2. 對預定義的 Ticker (例如 'TWD=X', '^VIX', 以及一個常見股票如 'AAPL') 執行 .history() 調用。
3. 打印每個 Ticker 的獲取狀態、返回數據的頭部、尾部和形狀。
4. 捕獲並打印任何發生的錯誤。
5. 修正了變數清理部分的 NameError。
"""

import time
import traceback
import pprint
import sys # 引入 sys 以便打印 Python 版本
from datetime import datetime, timedelta

_cell_identifier_test = "Cell_Test_YFinance_v1.1" # 更新版本
_test_start_time = time.time()
_test_status = "處理中"
_test_notes = []
_test_warnings = []
_test_error_details = {} # 存儲每個 ticker 的錯誤

print(f"--- {_cell_identifier_test} 開始執行 ---")
print(f"Python 版本: {sys.version}")

# --- 1. 嘗試導入必要函式庫 ---
_yf_lib = None
_pd_lib = None
try:
    import yfinance as yf
    _yf_lib = yf
    print(f"yfinance 函式庫導入成功。版本: {yf.__version__}")
    _test_notes.append(f"yfinance v{yf.__version__} 導入成功。")
except ImportError as e_yf:
    print(f"❌ 錯誤：導入 yfinance 失敗: {e_yf}")
    _test_warnings.append(f"導入 yfinance 失敗: {e_yf}")
except Exception as e_yf_other:
    print(f"❌ 錯誤：導入 yfinance 時發生意外錯誤: {e_yf_other}")
    _test_warnings.append(f"導入 yfinance 時意外錯誤: {e_yf_other}")

try:
    import pandas as pd
    _pd_lib = pd
    print(f"pandas 函式庫導入成功。版本: {pd.__version__}")
    _test_notes.append(f"pandas v{pd.__version__} 導入成功。")
except ImportError as e_pd:
    print(f"❌ 錯誤：導入 pandas 失敗: {e_pd}")
    _test_warnings.append(f"導入 pandas 失敗: {e_pd}")
except Exception as e_pd_other:
    print(f"❌ 錯誤：導入 pandas 時發生意外錯誤: {e_pd_other}")
    _test_warnings.append(f"導入 pandas 時意外錯誤: {e_pd_other}")

if not _yf_lib or not _pd_lib:
    _test_status = "失敗"
    print("❌ 由於核心函式庫 (yfinance 或 pandas) 導入失敗，測試無法繼續。")
    _test_error_details["Setup"] = "核心函式庫導入失敗。"
else:
    # --- 2. 定義測試參數 ---
    tickers_to_test = {
        "TWD=X": "美元兌新台幣匯率",
        "^VIX": "波動率指數 VIX",
        "AAPL": "蘋果公司股價 (測試常見股票)",
        "NONEXISTENT_TICKER_XYZ123": "一個不存在的 Ticker (測試錯誤處理)"
    }
    start_date_test = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
    interval_test = '1d'

    print(f"\n準備測試以下 Tickers (從 {start_date_test} 開始，間隔 {interval_test}):")
    for ticker, desc in tickers_to_test.items():
        print(f"  - {ticker} ({desc})")
    print("-" * 50)

    # --- 3. 執行測試 ---
    successful_fetches = 0
    # 初始化 history_data 以避免 NameError
    history_data = None
    ticker_obj = None
    description = None # 初始化 description
    ticker_symbol = None # 初始化 ticker_symbol

    for ticker_symbol_loop, description_loop in tickers_to_test.items(): # 使用不同的變數名避免覆蓋
        ticker_symbol = ticker_symbol_loop # 在循環內部賦值
        description = description_loop     # 在循環內部賦值
        print(f"\n>>> 正在測試 Ticker: {ticker_symbol} ({description})")
        _test_notes.append(f"開始測試 Ticker: {ticker_symbol}")
        try:
            ticker_obj = _yf_lib.Ticker(ticker_symbol)
            print(f"    調用 {ticker_symbol}.history(start='{start_date_test}', interval='{interval_test}')...")
            history_data = ticker_obj.history(start=start_date_test, interval=interval_test)

            if not history_data.empty:
                print(f"    ✅ 成功獲取 {ticker_symbol} 的數據。")
                print(f"       維度: {history_data.shape}")
                print(f"       欄位: {history_data.columns.tolist()}")
                print(f"       索引起始: {history_data.index.min()}, 索引結束: {history_data.index.max()}")
                print("       數據預覽 (頭部 3 行):")
                print(history_data.head(3).to_string())
                print("       數據預覽 (尾部 3 行):")
                print(history_data.tail(3).to_string())
                _test_notes.append(f"成功獲取 {ticker_symbol} ({history_data.shape})")
                successful_fetches +=1
            elif ticker_symbol == "NONEXISTENT_TICKER_XYZ123":
                print(f"    🤔 {ticker_symbol} (預期不存在的Ticker) 返回空 DataFrame，符合預期。")
                _test_notes.append(f"{ticker_symbol} 返回空 DataFrame，符合預期。")
            else:
                print(f"    ⚠️ 警告：獲取 {ticker_symbol} 數據成功，但返回的 DataFrame 為空。")
                _test_warnings.append(f"獲取 {ticker_symbol} 成功但 DataFrame 為空。")
                try:
                    info_data = ticker_obj.info
                    print(f"       {ticker_symbol} .info() 返回:")
                    pprint.pprint(info_data, depth=2)
                    if not info_data or (isinstance(info_data, dict) and info_data.get('regularMarketPrice') is None and info_data.get('previousClose') is None and not info_data.get('shortName')):
                         _test_warnings.append(f"{ticker_symbol} .info 看似無效。")
                except Exception as e_info_detail:
                    print(f"       獲取 {ticker_symbol} .info() 時也發生錯誤: {e_info_detail}")
                    _test_warnings.append(f"獲取 {ticker_symbol} .info() 失敗: {e_info_detail}")

        except Exception as e:
            error_type = e.__class__.__name__
            error_message = str(e)
            print(f"    ❌ 錯誤：獲取 {ticker_symbol} 數據時發生錯誤: {error_type}: {error_message}")
            _test_warnings.append(f"獲取 {ticker_symbol} 失敗: {error_type}: {error_message}")
            _test_error_details[ticker_symbol] = f"{error_type}: {error_message}"

    if successful_fetches > 0 and not _test_error_details:
         _test_status = "成功"
    elif successful_fetches > 0 and _test_error_details:
         _test_status = "成功 (有部分錯誤)"
    elif not _test_error_details and any("返回空 DataFrame" in note for note in _test_notes if "NONEXISTENT_TICKER" not in note): # 修正: 檢查 _test_notes
         _test_status = "成功 (有警告)"
    else:
         _test_status = "失敗"

# --- 4. 總結測試結果 ---
print("\n" + "="*50)
print(f"--- {_cell_identifier_test} 執行完畢 ---")
_test_duration = time.time() - _test_start_time
print(f"測試總耗時: {_test_duration:.2f} 秒")
print(f"最終測試狀態: {_test_status}")

if _test_notes:
    print("\n執行註記:")
    for note in _test_notes:
        print(f"  - {note}")
if _test_warnings:
    print("\n警告訊息:")
    for warning in _test_warnings:
        print(f"  - {warning}")
if _test_error_details:
    print("\n詳細錯誤 (針對特定 Ticker):")
    for ticker, error_str in _test_error_details.items(): # 修正: 使用 _test_error_details.items()
        print(f"  - Ticker '{ticker}': {error_str}")
elif _test_status == "失敗" and "Setup" in _test_error_details :
     pass
elif _test_status != "失敗":
    print("\n✅ 所有 Ticker (除預期失敗的外) 均未報告直接的獲取錯誤。")
print("="*50)

# --- 5. 清理局部變數 (修正 NameError) ---
_vars_to_clean_test = [
    '_cell_identifier_test', '_test_start_time', '_test_status', '_test_notes',
    '_test_warnings', '_test_error_details', '_yf_lib', '_pd_lib',
    'tickers_to_test', 'start_date_test', 'interval_test', 'successful_fetches',
    'ticker_symbol', 'description', 'ticker_obj', 'history_data',
    'e_yf', 'e_pd', 'e', 'error_type', 'error_message', 'info_data', 'e_info_detail',
    'e_yf_other', 'e_pd_other', 'ticker_symbol_loop', 'description_loop',
    '_test_duration', 'ticker', 'desc', 'error_str', 'note', 'warning' # 新增清理迭代變數
]

for _var_to_clean in _vars_to_clean_test:
    if _var_to_clean in locals():
        try:
            del locals()[_var_to_clean]
        except KeyError:
            pass # 變數可能在某些執行路徑下未被賦值，忽略 KeyError

