{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å…¨æ™¯å¸‚å ´åˆ†æå„€ - Colab åŸ·è¡Œå™¨\n",
    "\n",
    "**æŒ‡æ®å®˜ï¼Œé€™æ˜¯æ‚¨èˆ‡ã€Œå…¨æ™¯å¸‚å ´åˆ†æå„€ã€ç³»çµ±äº’å‹•çš„ä¸»è¦ä»‹é¢ã€‚**\n",
    "\n",
    "é€™å€‹ Colab Notebook éµå¾ªã€Œæ¥µåº¦ç°¡æ½”ã€UI å±¤åŸå‰‡ï¼Œä¸»è¦åˆ†ç‚ºå…©å€‹éƒ¨åˆ†ï¼š\n",
    "1.  **ç’°å¢ƒéƒ¨ç½²èˆ‡è¨­å®š**ï¼šè‡ªå‹•æ›è¼‰ Google Driveã€å¾ GitHub åŒæ­¥æœ€æ–°ç¨‹å¼ç¢¼ã€å®‰è£ä¾è³´ã€ä¸¦å°å…¥æ ¸å¿ƒæŒ‡æ®å®˜æ¨¡çµ„ã€‚\n",
    "2.  **åŸ·è¡Œåˆ†æä»»å‹™**ï¼šæ‚¨åªéœ€è¦åœ¨æ­¤è™•å®šç¾©è¦åˆ†æçš„è³‡ç”¢ã€æ™‚é–“ç¯„åœç­‰åƒæ•¸ï¼Œç„¶å¾Œå‘æŒ‡æ®å®˜ä¸‹é”æŒ‡ä»¤å³å¯ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 1: ç’°å¢ƒéƒ¨ç½²èˆ‡è¨­å®š\n",
    "# ===================================================================\n",
    "\n",
    "# 1.1 æ›è¼‰ Google Drive (å¦‚æœæ•¸æ“šåº«å’Œå¿«å–è¦æŒä¹…åŒ–æ–¼æ­¤)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"STEP 1.1: Mounting Google Drive...\")\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True) # force_remount å¯ç¢ºä¿æ¯æ¬¡éƒ½é‡æ–°æ›è¼‰\n",
    "    print(\"âœ… Google Drive mounted successfully at /content/drive.\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Not running in Google Colab environment. Skipping Drive mount.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error mounting Google Drive: {e}\")\n",
    "\n",
    "# 1.2 å®šç¾©å°ˆæ¡ˆè·¯å¾‘èˆ‡ GitHub è³‡è¨Š\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\nSTEP 1.2: Defining project paths and GitHub info...\")\n",
    "PROJECT_ROOT_PATH = \"/content/panoramic-market-analyzer\"\n",
    "GITHUB_USERNAME = \"YOUR_USERNAME\"  # <<<<< æŒ‡æ®å®˜ï¼Œè«‹åœ¨æ­¤å¡«å¯«æ‚¨çš„ GitHub ä½¿ç”¨è€…åç¨±\n",
    "GITHUB_REPO_NAME = \"YOUR_REPO_NAME\" # <<<<< æŒ‡æ®å®˜ï¼Œè«‹åœ¨æ­¤å¡«å¯«æ‚¨çš„ GitHub å„²å­˜åº«åç¨±\n",
    "GITHUB_REPO_URL = f\"https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO_NAME}.git\"\n",
    "\n",
    "print(f\"Project root will be: {PROJECT_ROOT_PATH}\")\n",
    "print(f\"GitHub repository: {GITHUB_REPO_URL}\")\n",
    "print(\"âœ… Project paths and GitHub info defined.\")\n",
    "\n",
    "# 1.3 å¾ GitHub åŒæ­¥æœ€æ–°ç¨‹å¼ç¢¼\n",
    "# -------------------------------------------------------------------\n",
    "import os\n",
    "print(\"\\nSTEP 1.3: Syncing with GitHub repository...\")\n",
    "if os.path.exists(PROJECT_ROOT_PATH):\n",
    "    print(f\"Project directory {PROJECT_ROOT_PATH} already exists. Removing it to ensure fresh clone.\")\n",
    "    # ä½¿ç”¨ shell å‘½ä»¤ rm -rfï¼Œç¢ºä¿èƒ½åˆªé™¤éç©ºç›®éŒ„\n",
    "    !rm -rf {PROJECT_ROOT_PATH}\n",
    "print(f\"Cloning repository {GITHUB_REPO_URL} into {PROJECT_ROOT_PATH}...\")\n",
    "!git clone {GITHUB_REPO_URL} {PROJECT_ROOT_PATH}\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æˆåŠŸ clone\n",
    "if not os.path.isdir(os.path.join(PROJECT_ROOT_PATH, '.git')):\n",
    "    print(f\"âŒ CRITICAL: Failed to clone repository from {GITHUB_REPO_URL}.\")\n",
    "    print(\"Please check the GITHUB_USERNAME and GITHUB_REPO_NAME variables, and ensure the repository is public or you have access.\")\n",
    "    # åœ¨æ­¤è™•å¯ä»¥é¸æ“‡åœæ­¢åŸ·è¡Œï¼Œæˆ–æ‹‹å‡ºéŒ¯èª¤\n",
    "    # raise RuntimeError(\"Failed to clone repository.\") \n",
    "else:\n",
    "    print(\"âœ… Repository cloned successfully.\")\n",
    "    %cd {PROJECT_ROOT_PATH}\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(\"Listing project root contents:\")\n",
    "    !ls -l\n",
    "\n",
    "# 1.4 å®‰è£/æ›´æ–°ä¾è³´\n",
    "# -------------------------------------------------------------------\n",
    "REQUIREMENTS_PATH = os.path.join(PROJECT_ROOT_PATH, \"requirements.txt\")\n",
    "print(\"\\nSTEP 1.4: Installing/updating dependencies...\")\n",
    "if os.path.exists(REQUIREMENTS_PATH):\n",
    "    print(f\"Found requirements.txt at {REQUIREMENTS_PATH}. Installing...\")\n",
    "    !pip install --upgrade -q -r {REQUIREMENTS_PATH}\n",
    "    print(\"âœ… Dependencies installation attempt finished.\")\n",
    "else:\n",
    "    print(f\"âš ï¸ WARNING: requirements.txt not found at {REQUIREMENTS_PATH}. Skipping dependency installation.\")\n",
    "    print(\"Ensure your repository contains a requirements.txt file at the root.\")\n",
    "\n",
    "# 1.5 è¨­å®š Python ç’°å¢ƒï¼Œå°‡å°ˆæ¡ˆåŠ å…¥ sys.path\n",
    "# -------------------------------------------------------------------\n",
    "import sys\n",
    "print(\"\\nSTEP 1.5: Updating Python sys.path...\")\n",
    "if PROJECT_ROOT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT_PATH)\n",
    "    print(f\"Added {PROJECT_ROOT_PATH} to sys.path.\")\n",
    "else:\n",
    "    print(f\"{PROJECT_ROOT_PATH} is already in sys.path.\")\n",
    "# print(f\"Current sys.path: {sys.path}\") # å¯é¸ï¼šæ‰“å°æŸ¥çœ‹ sys.path\n",
    "print(\"âœ… Python environment configured.\")\n",
    "\n",
    "# 1.6 å°å…¥æ‚¨çš„æ ¸å¿ƒæŒ‡æ®å®˜åŠå…¶ä»–å¿…è¦æ¨¡çµ„\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\nSTEP 1.6: Importing Commander and other modules...\")\n",
    "try:\n",
    "    from data_pipeline.commander import Commander\n",
    "    import pandas as pd # å¸¸ç”¨æ–¼æ•¸æ“šæŸ¥çœ‹\n",
    "    import logging # ç”¨æ–¼è¨­å®šæ—¥èªŒç´šåˆ¥\n",
    "\n",
    "    # è¨­å®šæ—¥èªŒç´šåˆ¥ï¼Œä»¥ä¾¿åœ¨ Colab ä¸­çœ‹åˆ° Commander çš„è©³ç´°è¼¸å‡º\n",
    "    # logging.basicConfig(level=logging.INFO, \n",
    "    #                     format='%(asctime)s - %(levelname)s - [%(name)s] - %(message)s', \n",
    "    #                     datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    #                     force=True) # force=True åœ¨ Colab ä¸­å¯èƒ½éœ€è¦ï¼Œä»¥è¦†è“‹é è¨­è¨­å®š\n",
    "    # logger = logging.getLogger('data_pipeline') # ç²å– data_pipeline å¥—ä»¶çš„ logger\n",
    "    # logger.setLevel(logging.INFO) # å¯ä»¥è¨­ç‚º DEBUG ä»¥ç²å¾—æ›´è©³ç´°çš„è¼¸å‡º\n",
    "    \n",
    "    print(\"ğŸš€ System ready. Commander imported successfully.\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ CRITICAL ERROR: Failed to import Commander or other modules: {e}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"1. Repository structure: Is 'data_pipeline/commander.py' present?\")\n",
    "    print(\"2. __init__.py files: Are they present in 'data_pipeline' and its subdirectories?\")\n",
    "    print(\"3. sys.path: Was the project directory correctly added?\")\n",
    "    print(\"4. Dependencies: Were all dependencies in requirements.txt installed successfully?\")\n",
    "    print(\"   (Check for any error messages during the !pip install step above)\")\n",
    "    # raise e # å¯ä»¥é¸æ“‡é‡æ–°æ‹‹å‡ºéŒ¯èª¤ä»¥åœæ­¢åŸ·è¡Œ\n",
    "except Exception as e_other:\n",
    "    print(f\"âŒ UNEXPECTED ERROR during module import: {e_other}\")\n",
    "    # raise e_other\n",
    "\n",
    "print(\"\\nğŸ‰ğŸ‰ğŸ‰ Environment Setup Complete! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "print(\"You can now proceed to Cell 2 to execute analysis tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Cell 2: åŸ·è¡Œåˆ†æä»»å‹™\n",
    "\n",
    "**æŒ‡æ®å®˜ï¼Œé€™æ˜¯æ‚¨èˆ‡ç³»çµ±äº’å‹•çš„å”¯ä¸€åœ°æ–¹ï¼**\n",
    "\n",
    "1.  **è¨­å®šä»»å‹™åƒæ•¸**ï¼š\n",
    "    *   `SYMBOLS_TO_ANALYZE`ï¼šå®šç¾©è¦åˆ†æçš„è³‡ç”¢ã€‚é€™æ˜¯ä¸€å€‹å­—å…¸ï¼Œéµç‚ºæ•¸æ“šæºé¡å‹ (`equity`, `macro`, `crypto`)ï¼Œå€¼ç‚ºå°æ‡‰çš„ç¬¦è™Ÿåˆ—è¡¨ã€‚\n",
    "    *   `START_DATE` å’Œ `END_DATE`ï¼šå®šç¾©åˆ†æçš„æ™‚é–“ç¯„åœã€‚\n",
    "    *   `DB_NAME_SUFFIX`ï¼šæ•¸æ“šåº«æª”æ¡ˆçš„å¾Œç¶´ï¼Œç”¨æ–¼å€åˆ†ä¸åŒçš„åˆ†æä»»å‹™æˆ–æ—¥æœŸã€‚\n",
    "    *   `FRED_API_KEY` (å¯é¸): å¦‚æœæ‚¨çš„ FRED API é‡‘é‘°æœªè¨­å®šç‚ºç’°å¢ƒè®Šæ•¸ï¼Œå¯ä»¥åœ¨æ­¤è™•æä¾›ã€‚\n",
    "\n",
    "2.  **å¯¦ä¾‹åŒ–æŒ‡æ®å®˜ (Commander)**ï¼šå‚³å…¥å¿…è¦çš„è·¯å¾‘å’Œè¨­å®šã€‚\n",
    "    *   æ•¸æ“šåº«å’Œå¿«å–æª”æ¡ˆå°‡å„²å­˜åœ¨æ‚¨çš„ Google Drive ä¸‹çš„ `MarketData/PanoramicAnalyzer/` ç›®éŒ„ä¸­ã€‚\n",
    "\n",
    "3.  **ä¸‹é”æŒ‡ä»¤çµ¦æŒ‡æ®å®˜**ï¼š\n",
    "    *   `run_batch_fetch_and_store`ï¼šç²å–ä¸¦å„²å­˜æŒ‡å®šè³‡ç”¢çš„æ•¸æ“šã€‚\n",
    "    *   `get_processed_data`ï¼šç²å–å·²å„²å­˜çš„æ•¸æ“šï¼Œä¸¦å¯é¸æ“‡æ€§åœ°é€²è¡Œè™•ç† (ä¾‹å¦‚è¨ˆç®—æŠ€è¡“æŒ‡æ¨™)ã€‚\n",
    "\n",
    "4.  **æŸ¥çœ‹çµæœ**ï¼šç²å–çš„æ•¸æ“šå°‡ä»¥ Pandas DataFrame çš„å½¢å¼è¿”å›ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨ Notebook ä¸­æŸ¥çœ‹æˆ–é€²ä¸€æ­¥åˆ†æã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 2: åŸ·è¡Œåˆ†æä»»å‹™\n",
    "# ===================================================================\n",
    "import os\n",
    "import pandas as pd # å†æ¬¡å°å…¥ä»¥ç¢ºä¿åœ¨æ­¤ cell å¯ç”¨\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1. è¨­å®šä»»å‹™åƒæ•¸ ---\n",
    "print(\"STEP 2.1: Defining task parameters...\")\n",
    "\n",
    "# è¦åˆ†æçš„è³‡ç”¢åˆ—è¡¨ (æŒ‰æ•¸æ“šæºåˆ†é¡)\n",
    "# æŒ‡æ®å®˜ï¼Œè«‹æ ¹æ“šæ‚¨çš„éœ€æ±‚ä¿®æ”¹æ­¤è™•çš„è³‡ç”¢åˆ—è¡¨ã€‚\n",
    "# yfinance: ä½¿ç”¨ Yahoo Finance çš„ Ticker, e.g., 'AAPL', 'SPY', 'BTC-USD'\n",
    "# fred: ä½¿ç”¨ FRED Series ID, e.g., 'DGS10', 'CPIAUCSL', 'VIXCLS'\n",
    "# coingecko: ä½¿ç”¨ CoinGecko Coin ID, e.g., 'bitcoin', 'ethereum', 'solana'\n",
    "SYMBOLS_TO_ANALYZE = {\n",
    "    'equity': ['SPY', 'QQQ', 'AAPL', 'NVDA', 'TSLA'],\n",
    "    'crypto': ['bitcoin', 'ethereum'],\n",
    "    'macro': ['DGS10', 'VIXCLS'] # 10-Year Treasury, VIX Index\n",
    "}\n",
    "\n",
    "START_DATE = \"2022-01-01\"\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d') # åˆ†æåˆ°ç•¶å‰æ—¥æœŸ\n",
    "\n",
    "# Google Drive ä¸­çš„æ•¸æ“šåº«å’Œå¿«å–æª”æ¡ˆåŸºç¤è·¯å¾‘\n",
    "DRIVE_DATA_BASE_PATH = '/content/drive/MyDrive/MarketData/PanoramicAnalyzer'\n",
    "# ç¢ºä¿æ­¤ç›®éŒ„å­˜åœ¨ (å¦‚æœ Drive å·²æ›è¼‰)\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    os.makedirs(DRIVE_DATA_BASE_PATH, exist_ok=True)\n",
    "    print(f\"Ensured base data directory exists: {DRIVE_DATA_BASE_PATH}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Google Drive not mounted or accessible. Data will be stored locally in Colab session: {DRIVE_DATA_BASE_PATH.replace('/content/drive/MyDrive', './local_colab_data')}\")\n",
    "    DRIVE_DATA_BASE_PATH = './local_colab_data/MarketData/PanoramicAnalyzer' # æœ¬åœ°è·¯å¾‘å‚™æ´\n",
    "    os.makedirs(DRIVE_DATA_BASE_PATH, exist_ok=True)\n",
    "\n",
    "# æ•¸æ“šåº«æª”æ¡ˆåç¨± (å¯ä»¥åŠ å…¥æ—¥æœŸæˆ–ä»»å‹™æ¨™è­˜)\n",
    "DB_NAME_SUFFIX = datetime.now().strftime('%Y%m%d') # ä¾‹å¦‚ï¼Œä½¿ç”¨ç•¶å¤©æ—¥æœŸä½œç‚ºå¾Œç¶´\n",
    "DATABASE_FILE_NAME = f'panoramic_market_data_{DB_NAME_SUFFIX}.duckdb'\n",
    "DATABASE_PATH = os.path.join(DRIVE_DATA_BASE_PATH, DATABASE_FILE_NAME)\n",
    "\n",
    "# API å¿«å–æª”æ¡ˆåç¨±\n",
    "CACHE_FILE_NAME = 'api_requests_cache.sqlite'\n",
    "CACHE_PATH = os.path.join(DRIVE_DATA_BASE_PATH, CACHE_FILE_NAME)\n",
    "\n",
    "# FRED API é‡‘é‘° (å¯é¸)\n",
    "# å¦‚æœæ‚¨å·²å°‡ FRED_API_KEY è¨­å®šç‚º Colab çš„ Secrets æˆ–ç’°å¢ƒè®Šæ•¸ï¼Œå‰‡æ­¤è™•å¯ç•™ç©º (None)\n",
    "# å¦å‰‡ï¼Œè«‹åœ¨æ­¤è™•ç›´æ¥æä¾›æ‚¨çš„é‡‘é‘°å­—ä¸²ã€‚\n",
    "FRED_API_KEY = None # ä¾‹å¦‚: \"your_actual_fred_api_key_here\" \n",
    "# å˜—è©¦å¾ Colab Secrets è®€å– (å¦‚æœå­˜åœ¨)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    fred_key_secret = userdata.get('FRED_API_KEY') # å‡è¨­æ‚¨åœ¨ Colab Secrets ä¸­è¨­å®šäº†åç‚º FRED_API_KEY çš„å¯†é‘°\n",
    "    if fred_key_secret:\n",
    "        FRED_API_KEY = fred_key_secret\n",
    "        print(\"Found FRED_API_KEY in Colab Secrets.\")\n",
    "except ImportError:\n",
    "    pass # ä¸æ˜¯åœ¨ Colab ç’°å¢ƒæˆ– userdata ä¸å¯ç”¨\n",
    "except Exception:\n",
    "    print(\"No FRED_API_KEY found in Colab Secrets, or error accessing it. Will rely on environment variable or direct input.\")\n",
    "\n",
    "print(f\"Task Parameters:\")\n",
    "print(f\"  Symbols: {SYMBOLS_TO_ANALYZE}\")\n",
    "print(f\"  Start Date: {START_DATE}\")\n",
    "print(f\"  End Date: {END_DATE}\")\n",
    "print(f\"  Database Path: {DATABASE_PATH}\")\n",
    "print(f\"  Cache Path: {CACHE_PATH}\")\n",
    "print(f\"  FRED API Key Provided: {'Yes' if FRED_API_KEY else 'No (will try env var or default)'}\")\n",
    "print(\"âœ… Task parameters defined.\")\n",
    "\n",
    "# --- 2. å¯¦ä¾‹åŒ–æŒ‡æ®å®˜ (Commander) ---\n",
    "print(\"\\nSTEP 2.2: Initializing Commander...\")\n",
    "commander_instance = None # åˆå§‹åŒ–ä»¥å‚™ finally å€å¡Šä½¿ç”¨\n",
    "try:\n",
    "    # è¨­å®šæª” config.yaml æ‡‰ä½æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹\n",
    "    config_file_path = os.path.join(PROJECT_ROOT_PATH, 'config.yaml')\n",
    "    if not os.path.exists(config_file_path):\n",
    "        raise FileNotFoundError(f\"CRITICAL: config.yaml not found at {config_file_path}. Ensure it's in the project root.\")\n",
    "\n",
    "    # é‡æ–°è¨­å®šæ—¥èªŒ (ç¢ºä¿ Commander çš„æ—¥èªŒå¯è¦‹)\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO, \n",
    "                        format='%(asctime)s - %(levelname)s - [%(name)s] - %(message)s', \n",
    "                        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                        force=True) # force=True åœ¨ Colab ä¸­å¯èƒ½éœ€è¦\n",
    "    logging.getLogger('data_pipeline').setLevel(logging.INFO) # è¨­å®š data_pipeline å¥—ä»¶çš„æ—¥èªŒç´šåˆ¥\n",
    "    logging.getLogger('duckdb').setLevel(logging.WARNING) # DuckDB çš„æ—¥èªŒè¼ƒå¤šï¼Œè¨­ç‚º WARNING\n",
    "    logging.getLogger('yfinance').setLevel(logging.WARNING) # yfinance çš„æ—¥èªŒä¹Ÿè¼ƒå¤š\n",
    "\n",
    "    commander_instance = Commander(\n",
    "        config_path=config_file_path,\n",
    "        db_path=DATABASE_PATH,\n",
    "        cache_path=CACHE_PATH,\n",
    "        fred_api_key=FRED_API_KEY\n",
    "    )\n",
    "    print(\"âœ… Commander initialized successfully.\")\n",
    "except FileNotFoundError as fnf_err:\n",
    "    print(fnf_err)\n",
    "    # åœæ­¢åŸ·è¡Œï¼Œå› ç‚ºæ²’æœ‰è¨­å®šæª”ï¼ŒCommander ç„¡æ³•å·¥ä½œ\n",
    "    raise\n",
    "except Exception as e_init:\n",
    "    print(f\"âŒ ERROR: Failed to initialize Commander: {e_init}\")\n",
    "    print(\"Please check error messages above, ensure config.yaml is correct, and paths are valid.\")\n",
    "    # raise e_init # å¯ä»¥é¸æ“‡é‡æ–°æ‹‹å‡ºéŒ¯èª¤\n",
    "\n",
    "# --- 3. å‘æŒ‡æ®å®˜ä¸‹é”æŒ‡ä»¤ --- \n",
    "if commander_instance:\n",
    "    try:\n",
    "        # 3.1 åŸ·è¡Œæ‰¹æ¬¡æ•¸æ“šç²å–èˆ‡å„²å­˜\n",
    "        print(\"\\nSTEP 2.3.1: Running batch data fetch and store...\")\n",
    "        db_table_name = 'ohlcv_daily_master' # ä¸»æ•¸æ“šè¡¨å\n",
    "        commander_instance.run_batch_fetch_and_store(\n",
    "            symbols_map=SYMBOLS_TO_ANALYZE,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            table_name=db_table_name\n",
    "        )\n",
    "        print(f\"âœ… Batch data fetch and store process completed. Data should be in table '{db_table_name}' in {DATABASE_PATH}.\")\n",
    "\n",
    "        # 3.2 ç¤ºä¾‹ï¼šç²å– SPY çš„è™•ç†å¾Œæ•¸æ“šä¸¦è¨ˆç®—ä¸€äº›æŒ‡æ¨™\n",
    "        print(\"\\nSTEP 2.3.2: Example - Getting processed data for SPY with indicators...\")\n",
    "        target_symbol_example = 'SPY' # å¾ SYMBOLS_TO_ANALYZE ä¸­é¸ä¸€å€‹è‚¡ç¥¨ä»£ç¢¼\n",
    "        if target_symbol_example in SYMBOLS_TO_ANALYZE.get('equity', []):\n",
    "            indicators_to_calculate = [\n",
    "                {'name': 'sma', 'window': 20, 'price_col': 'close'},\n",
    "                {'name': 'sma', 'window': 50, 'price_col': 'close'},\n",
    "                {'name': 'ema', 'window': 12, 'price_col': 'close'},\n",
    "                {'name': 'rsi', 'window': 14, 'price_col': 'close'}\n",
    "            ]\n",
    "            spy_data_processed = commander_instance.get_processed_data(\n",
    "                symbol=target_symbol_example,\n",
    "                table_name=db_table_name,\n",
    "                start_date=START_DATE,\n",
    "                end_date=END_DATE,\n",
    "                indicators=indicators_to_calculate\n",
    "            )\n",
    "\n",
    "            if spy_data_processed is not None and not spy_data_processed.empty:\n",
    "                print(f\"\\nSuccessfully retrieved and processed data for {target_symbol_example}:\")\n",
    "                print(f\"Shape of processed data: {spy_data_processed.shape}\")\n",
    "                print(f\"Columns: {spy_data_processed.columns.tolist()}\")\n",
    "                print(\"Last 5 rows of processed data for SPY:\")\n",
    "                # ä½¿ç”¨ display å‡½æ•¸åœ¨ Colab ä¸­ç²å¾—æ›´å¥½çš„ DataFrame è¼¸å‡º\n",
    "                from IPython.display import display \n",
    "                display(spy_data_processed.tail())\n",
    "            else:\n",
    "                print(f\"âš ï¸ Could not retrieve or process data for {target_symbol_example}. It might not have been fetched or period is too short.\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ Example symbol '{target_symbol_example}' not in the 'equity' list to analyze. Skipping processed data example.\")\n",
    "\n",
    "    except Exception as e_runtime:\n",
    "        print(f\"âŒ RUNTIME ERROR during Commander operations: {e_runtime}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # æ‰“å°è©³ç´°çš„éŒ¯èª¤è¿½è¹¤\n",
    "    finally:\n",
    "        # --- 4. ç¢ºä¿è³‡æºè¢«é‡‹æ”¾ ---\n",
    "        print(\"\\nSTEP 2.4: Closing Commander to release resources...\")\n",
    "        if commander_instance:\n",
    "            commander_instance.close()\n",
    "        print(\"âœ… Commander closed.\")\n",
    "else:\n",
    "    print(\"Commander was not initialized. Skipping execution of tasks.\")\n",
    "\n",
    "print(\"\\nğŸğŸğŸ æŒ‡æ®å®˜ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼ğŸğŸğŸ\")\n",
    "print(f\"è«‹æª¢æŸ¥æ‚¨çš„ Google Drive (å¦‚æœå·²æ›è¼‰) ä¸­çš„æ•¸æ“šåº«æª”æ¡ˆ: {DATABASE_PATH}\")\n",
    "print(f\"ä»¥åŠå¿«å–æª”æ¡ˆ: {CACHE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
